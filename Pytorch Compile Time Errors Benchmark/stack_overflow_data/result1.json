[
    {
        "question_id": "59013109",
        "accepted_answer_id": "59013131",
        "question_title": "RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same",
        "question_markdown": "This:\r\n\r\n```\r\ndevice = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\r\nmodel.to(device)\r\n\r\nfor data in dataloader:\r\n    inputs, labels = data\r\n    outputs = model(inputs)\r\n```\r\nGives the error: \r\n&gt;RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\r\n",
        "accepted_answer_markdown": "You get this error because your model is on the GPU, but your data is on the CPU. So, you need to send your input tensors to the GPU.\r\n```python\r\ninputs, labels = data                         # this is what you had\r\ninputs, labels = inputs.cuda(), labels.cuda() # add this line\r\n```\r\nOr like this, to stay consistent with the rest of your code:\r\n```python\r\ndevice = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\r\n\r\ninputs, labels = inputs.to(device), labels.to(device)\r\n``` \r\nThe __same error__ will be raised if your input tensors are on the GPU but your model weights aren&#39;t. In this case, you need to send your model weights to the GPU.\r\n```\r\nmodel = MyModel()\r\n\r\nif torch.cuda.is_available():\r\n    model.cuda()\r\n```\r\nSee the documentation for [`cuda()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.cuda), and its opposite, [`cpu()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.cpu)."
    },
    {
        "question_id": "59115888",
        "accepted_answer_id": "59115958",
        "question_title": "transforms.Normalize() between 0 and 1 when using Lab",
        "question_markdown": "which mean, std should I use when I want to normalize a tensor to a range of 0 to 1? But I work with images with 2 channels (a, b channel -&gt; -128 to 127) only instead of 3 channels. Thus, the usual `mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]` will not do the job. \n\n    transform = transforms.Compose([\n       transforms.ToTensor(),\n       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225])\n    ])\n\nThis leads to this error message:\n\n&gt; tensor.sub_(mean[:, None, None]).div_(std[:, None, None])\n&gt;\n&gt; RuntimeError: The size of tensor a (2) must match the size of tensor b\n&gt; (3) at non-singleton dimension 0",
        "accepted_answer_markdown": "As you can see, PyTorch complains about the Tensor size, since you lack a channel.\r\n\r\nAdditionally, the &quot;usual&quot; mean and std values are computed on ImageNet dataset, and are useful if the statistics of your data match the ones of that dataset.\r\n\r\nAs you work with two channels only, I assume that your domain might be fairly different from 3-channels natural images. In that case I would simply use `0.5` for both `mean` and `std`, such that the minimum value 0 will be converted to `(0 - 0.5) / 0.5 = -1` and the maximum value of 1 to `(1 - 0.5) / 0.5 = 1`.\r\n\r\n```python\r\ntransform = transforms.Compose([\r\n   transforms.ToTensor(),\r\n   transforms.Normalize(mean=[0.5, 0.5],\r\n                        std=[0.5, 0.5])\r\n])\r\n```\r\n\r\n---\r\n\r\nEdit: I would recommend zero-centering of the input. \r\n\r\nHowever, if for some reason you must have it in range [0, 1], calling only `ToTensor()` would suffice.\r\n\r\nIn this case, a word of caution. I think `ToTensor()` [assumes your input to lie in range [0, 255]][1] prior to the transform, so it basically divides it by 255. If that is not the case in your domain (e.g. your input is always in range [1, 50] for some reason) I would simply create a [custom transform][2] to divide for the actual upper bound for your data.\r\n\r\n\r\n  [1]: https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor\r\n  [2]: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms"
    },
    {
        "question_id": "59125208",
        "accepted_answer_id": "59125406",
        "question_title": "How to properly implement 1D CNN for numerical data in PyTorch?",
        "question_markdown": "I have a 500x2000 matrix, where each row represents an individual and each column is a measurement of some particular quality about that individual. I&#39;m using a batch size of 64, so the input for each cycle of the network is actually a 64x2000 matrix. I&#39;m trying to build a CNN in PyTorch to classify individuals given a set of these measurements. However, I&#39;ve stumbled on the parameters for the convolutional layer.\r\n\r\nBelow is my current definition for a simple convolutional neural network.\r\n```\r\nclass CNNnet(nn.Module)\r\n    def __init__(self):\r\n        self.conv1 = nn.Conv1d(2000, 200, (1,2), stride=10)\r\n        self.pool = nn.MaxPool1d(kernel_size = (1, 2), stride = 2)\r\n\r\n        self.fc1 = nn.Linear(64, 30)\r\n        self.fc2 = nn.Linear(30, 7)\r\n\r\n    def forward(self, x):\r\n        x = x.view(64, 2000, 1)\r\n        x = F.relu(self.conv1(x))\r\n        x = self.pool(x)\r\n        x = F.relu(self.fc1(x))\r\n        x = self.fc2(x)\r\n        return x\r\n```\r\n\r\nAttempting to train this model produces the following error:\r\n\r\n&gt; &quot;RuntimeError: Expected 4-dimensional input for 4-dimensional weight\r\n&gt; 200 2000 1 2, but got 3-dimensional input of size [64, 2000, 1]\r\n&gt; instead&quot;.\r\n\r\n \r\n\r\nI&#39;m confused on why it&#39;s expecting a 4D *200x2000x1x2* matrix (shouldn&#39;t the number of output channels be irrelevant to the input? And why is there a 2 at the end?).\r\n\r\nMy question is what would be the proper syntax or approach for writing a CNN (specifically the convolutional layer) when dealing with 1D data. Any help is greatly appreciated.",
        "accepted_answer_markdown": "So the kernel size in the 1 dimensional case is simply a vector. So if you\u2019ll want a kernel of size \u20181X2\u2019 you need to specify the \u20182\u2019 \r\nIn the 2 dimensional case 2 will mean a \u20182X2\u2019 kernel size.\r\n\r\nYou gave a tuple of 2 values so you use 2 kernel types each will create its own channel"
    },
    {
        "question_id": "59177430",
        "accepted_answer_id": "59179498",
        "question_title": "Multi-class for sentence classification with pytorch (Using nn.LSTM)",
        "question_markdown": "I have this network, that I took from [this][1] tutorial, and I want to have sentences as input (Which is already done) and just a one line tensor as a result.\r\n\r\nFrom the tutorial, this sentence \u201cJohn\u2019s dog likes food\u201d, gets a 1 column tensor returned:\r\n\r\n    tensor([[-3.0462, -4.0106, -0.6096],\r\n    [-4.8205, -0.0286, -3.9045],\r\n    [-3.7876, -4.1355, -0.0394],\r\n    [-0.0185, -4.7874, -4.6013]])\r\n\r\n...and class list: \r\n    \r\n    tag_list[ \u201cname\u201d, \u201cverb\u201d, \u201cnoun\u201d]\r\nEach line has the probability of a tag being associated with the word. (The first word has **[-3.0462, -4.0106, *-0.6096*]** vector where the last element corresponds to the maximum scoring tag, &quot;noun&quot;)\r\n\r\nThe tutorial\u2019s dataset looks like this:\r\n\r\n    training_data = [\r\n        (&quot;The dog ate the apple&quot;.split(), [&quot;DET&quot;, &quot;NN&quot;, &quot;V&quot;, &quot;DET&quot;, &quot;NN&quot;]),\r\n        (&quot;Everybody read that book&quot;.split(), [&quot;NN&quot;, &quot;V&quot;, &quot;DET&quot;, &quot;NN&quot;])\r\n    ]\r\n\r\nAnd I want mine to be of this format:\r\n\r\n    training_data = [\r\n        (&quot;Hello world&quot;.split(), [&quot;ONE&quot;]),\r\n        (&quot;I am dog&quot;.split(), [&quot;TWO&quot;]),\r\n        (&quot;It&#39;s Britney glitch&quot;.split(), [&quot;THREE&quot;])\r\n    ]\r\n\r\nThe parameters are defined as:\r\n\r\n    class LSTMTagger(nn.Module):\r\n        def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\r\n            super(LSTMTagger, self).__init__()\r\n            self.hidden_dim = hidden_dim\r\n            self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\r\n            self.lstm = nn.LSTM(embedding_dim, hidden_dim)\r\n            self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\r\n    \r\n        def forward(self, sentence):\r\n            embeds \t\t= self.word_embeddings(sentence)\r\n            lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\r\n            tag_space\t= self.hidden2tag(lstm_out.view(len(sentence), -1))\r\n            tag_scores \t= F.log_softmax(tag_space, dim=1)\r\n            return tag_scores\r\n        \r\n\r\nAs of now, the sizes from input and output are not matching and i get:\r\nValueError: Expected input batch_size (2) to match target batch_size (1).\r\n\r\n\r\nThe criterion function doesn&#39;t accept the input due to size missmatch it seems:\r\n\r\n    loss\t\t= criterion(tag_scores, targets)\r\n\r\nI&#39;ve read the last layer could be defined as nn.Linear in order to squash the outputs but i can&#39;t seem to get any results. Tried other loss functions \r\n\r\n**How can I change it in order for the model to classify the sentence , and not each word, as in the original tutorial?**\r\n\r\n\r\n  [1]: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html",
        "accepted_answer_markdown": "I solved this issue, by simply getting the hidden states of the last \r\n\r\n    tag_space\t= self.hidden2tag(lstm_out[-1])\r\n\r\n"
    },
    {
        "question_id": "59215086",
        "accepted_answer_id": "59725067",
        "question_title": "Proper dataloader setup to train fasterrcnn-resnet50 for object detection with pytorch",
        "question_markdown": "I am trying to train pytorches `torchvision.models.detection.fasterrcnn_resnet50_fpn` to detect objects in my own images.\r\n\r\nAccording to the [documentation][2], this model expects a list of images and a list of dictionaries with \r\n&#39;boxes&#39; and &#39;labels&#39; as keys. So my dataloaders `__getitem__()` looks like this:\r\n```python\r\ndef __getitem__(self, idx):\r\n    # load images\r\n    _, img = self.images[idx].getImage()\r\n    img = Image.fromarray(img, mode=&#39;RGB&#39;)\r\n    objects = self.images[idx].objects\r\n\r\n    boxes = []\r\n    labels = []\r\n    for o in objects:\r\n        # append bbox to boxes\r\n        boxes.append([o.x, o.y, o.x+o.width, o.y+o.height])\r\n        # append the 4th char of class_id, the number of lights (1-4)\r\n        labels.append(int(str(o.class_id)[3]))\r\n\r\n    # convert everything into a torch.Tensor\r\n    boxes = torch.as_tensor(boxes, dtype=torch.float32)\r\n    labels = torch.as_tensor(labels, dtype=torch.int64)\r\n\r\n    target = {}\r\n    target[&quot;boxes&quot;] = boxes\r\n    target[&quot;labels&quot;] = labels\r\n\r\n    # transforms consists only of transforms.Compose([transforms.ToTensor()]) for the time being\r\n    if self.transforms is not None:\r\n        img = self.transforms(img)\r\n\r\n    return img, target\r\n```\r\nTo my best knowledge, it returns exactly what&#39;s asked. My dataloader looks like this\r\n```python\r\ndata_loader = torch.utils.data.DataLoader(\r\n    dataset, batch_size=4, shuffle=False, num_workers=2)\r\n```\r\nhowever, when it get&#39;s to this stage:\r\n`for images, targets in dataloaders[phase]:`\r\nit raises\r\n\r\n&gt; RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 12 and 7 in dimension 1 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:689\r\n\r\nCan someone point me in the right direction?\r\n\r\n  [1]: https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html#finetuning-from-a-pretrained-model\r\n  [2]: https://pytorch.org/docs/stable/torchvision/models.html#faster-r-cnn",
        "accepted_answer_markdown": "@jodag was right, I had to write a seperate collate function in order for the net to receive the data like it was supposed to. In my case I only needed to bypass the default function."
    },
    {
        "question_id": "59510603",
        "accepted_answer_id": "59518059",
        "question_title": "RuntimeError: Expected 4-dimensional input for 4-dimensional weight [32, 4, 8, 8], but got 2-dimensional input of size [1, 4] instead",
        "question_markdown": "I am initializing a Convolutional DQN with the following code:\r\n```\r\nclass ConvDQN(nn.Module):\r\n    \r\n    def __init__(self, input_dim, output_dim):\r\n        super(ConvDQN, self).__init__()\r\n        self.input_dim = input_dim\r\n        self.output_dim = output_dim\r\n        self.conv = nn.Sequential(\r\n            nn.Conv2d(self.input_dim, 32, kernel_size=8, stride=4),\r\n            nn.ReLU(),\r\n            nn.Conv2d(32, 64, kernel_size=4, stride=2),\r\n            nn.ReLU(),\r\n            nn.Conv2d(64, 64, kernel_size=3, stride=1),\r\n            nn.ReLU()\r\n        )\r\n\r\n        self.fc_input_dim = self.feature_size()\r\n\r\n        self.fc = nn.Sequential(\r\n            nn.Linear(self.fc_input_dim, 128),\r\n            nn.ReLU(),\r\n            nn.Linear(128, 256),\r\n            nn.ReLU(),\r\n            nn.Linear(256, self.output_dim)\r\n        )\r\n        \r\n    def forward(self, state):\r\n        features = self.conv(state)\r\n        features = features.view(features.size(0), -1)\r\n        qvals = self.fc(features)\r\n        return qvals\r\n\r\n    def feature_size(self):\r\n        return self.conv(autograd.Variable(torch.zeros(1, *self.input_dim))).view(1, -1).size(1)\r\n\r\n```\r\nAnd it gives me the error:\r\n\r\n```\r\n  File &quot;dqn.py&quot;, line 86, in __init__\r\n    self.fc_input_dim = self.feature_size()\r\n  File &quot;dqn.py&quot;, line 105, in feature_size\r\n    return self.conv(autograd.Variable(torch.zeros(32, *self.input_dim))).view(1, -1).size(1)\r\n  File &quot;C:\\Users\\ariji\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 489, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File &quot;C:\\Users\\ariji\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\container.py&quot;, line 92, in forward\r\n    input = module(input)\r\n  File &quot;C:\\Users\\ariji\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 489, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File &quot;C:\\Users\\ariji\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py&quot;, line 320, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Expected 4-dimensional input for 4-dimensional weight [32, 4, 8, 8], but got 2-dimensional input of size [1, 4] instead\r\n```\r\nSo I get the fact that the input that I am passing to the convolutional network is of incorrect dimensions. What I do not understand is how I am supposed to add the required dimensions to my input? Or should I change something in my convolutional network?",
        "accepted_answer_markdown": "You pass the conv layer `torch.zeros(1, *self.input_dim)` which is `torch.Size([1, 4])`, but you initialize the conv layer as,\r\n```\r\nnn.Sequential(\r\n            nn.Conv2d(self.input_dim, 32, kernel_size=8, stride=4),\r\n            nn.ReLU(),\r\n            nn.Conv2d(32, 64, kernel_size=4, stride=2),\r\n            nn.ReLU(),\r\n            nn.Conv2d(64, 64, kernel_size=3, stride=1),\r\n            nn.ReLU()\r\n        )\r\n```\r\nSo `self.conv` is expecting a tensor of that size but you pass it `torch.Size([1, 4])`"
    },
    {
        "question_id": "59582663",
        "accepted_answer_id": "59583898",
        "question_title": "CNN Pytorch Error : Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same",
        "question_markdown": "I&#39;m receiving the error,\r\n&gt; Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same\r\n\r\nFollowing is my code,\r\n\r\n    device    = torch.device(&#39;cuda:0&#39;)\r\n    \r\n    trainData = torchvision.datasets.FashionMNIST(&#39;/content/&#39;, train=True, transform=None, target_transform=None, download=True)\r\n    testData  = torchvision.datasets.FashionMNIST(&#39;/content/&#39;, train=False, transform=None, target_transform=None, download=True)\r\n    \r\n    class Net(nn.Module):\r\n      def __init__(self):\r\n        super().__init__()\r\n    \r\n        &#39;&#39;&#39;\r\n        Network Structure:\r\n    \r\n        input &gt; \r\n        (1)Conv2D &gt; (2)MaxPool2D &gt; \r\n        (3)Conv2D &gt; (4)MaxPool2D &gt; \r\n        (5)Conv2D &gt; (6)MaxPool2D &gt; \r\n        (7)Linear &gt; (8)LinearOut\r\n    \r\n        &#39;&#39;&#39;\r\n    \r\n        # Creating the convulutional Layers\r\n        self.conv1 = nn.Conv2d(in_channels=CHANNELS, out_channels=32, kernel_size=3)\r\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\r\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\r\n    \r\n        self.flatten = None\r\n        # Creating a Random dummy sample to get the Flattened Dimensions\r\n        x = torch.randn(CHANNELS, DIM, DIM).view(-1, CHANNELS, DIM, DIM)\r\n        x = self.convs(x)\r\n    \r\n        # Creating the Linear Layers\r\n        self.fc1   = nn.Linear(self.flatten, 512)\r\n        self.fc2   = nn.Linear(512, CLASSES)\r\n    \r\n      def convs(self, x):\r\n    \r\n        # Creating the MaxPooling Layers\r\n        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2))\r\n        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=(2, 2))\r\n        x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=(2, 2))\r\n    \r\n        if not self.flatten:\r\n          self.flatten = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\r\n        return x\r\n    \r\n      # FORWARD PASS\r\n      def forward(self, x):\r\n        x = self.convs(x)\r\n        x = x.view(-1, self.flatten)\r\n        sm = F.relu(self.fc1(x))\r\n        x = F.softmax(self.fc2(sm), dim=1)\r\n        return x, sm\r\n    \r\n    \r\n      x_train, y_train = training_set\r\n      x_train, y_train = x_train.to(device), y_train.to(device)\r\n      optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\r\n      loss_func = nn.MSELoss()\r\n      loss_log  = []\r\n    \r\n      for epoch in range(EPOCHS):\r\n        for i in tqdm(range(0, len(x_train), BATCH_SIZE)):\r\n            x_batch = x_train[i:i+BATCH_SIZE].view(-1, CHANNELS, DIM, DIM).to(device)\r\n            y_batch = y_train[i:i+BATCH_SIZE].to(device)\r\n    \r\n            net.zero_grad()\r\n            output, sm = net(x_batch)\r\n            loss = loss_func(output, y_batch.float())\r\n            loss.backward()\r\n            optimizer.step()\r\n        loss_log.append(loss)\r\n        # print(f&quot;Epoch : {epoch} || Loss : {loss}&quot;)\r\n    \r\n      return loss_log\r\n    \r\n    \r\n    train_set = (trainData.train_data, trainData.train_labels)\r\n    test_set  = (testData.test_data, testData.test_labels)\r\n    \r\n    EPOCHS        = 5\r\n    LEARNING_RATE = 0.001\r\n    BATCH_SIZE    = 32\r\n    \r\n    net = Net().to(device)\r\n    \r\n    loss_log = train(net, train_set, EPOCHS, LEARNING_RATE, BATCH_SIZE)\r\n\r\n**And this is the Error that I&#39;m getting,**\r\n\r\n    RuntimeError                              Traceback (most recent call last)\r\n    &lt;ipython-input-8-0db1a1b4e37d&gt; in &lt;module&gt;()\r\n          5 net = Net().to(device)\r\n          6 \r\n    ----&gt; 7 loss_log = train(net, train_set, EPOCHS, LEARNING_RATE, BATCH_SIZE)\r\n    \r\n    6 frames\r\n    &lt;ipython-input-6-7de4a78e3736&gt; in train(net, training_set, EPOCHS, LEARNING_RATE, BATCH_SIZE)\r\n         13 \r\n         14         net.zero_grad()\r\n    ---&gt; 15         output, sm = net(x_batch)\r\n         16         loss = loss_func(output, y_batch.float())\r\n         17         loss.backward()\r\n    \r\n    /usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n        539             result = self._slow_forward(*input, **kwargs)\r\n        540         else:\r\n    --&gt; 541             result = self.forward(*input, **kwargs)\r\n        542         for hook in self._forward_hooks.values():\r\n        543             hook_result = hook(self, input, result)\r\n    \r\n    &lt;ipython-input-5-4fddc427892a&gt; in forward(self, x)\r\n         41   # FORWARD PASS\r\n         42   def forward(self, x):\r\n    ---&gt; 43     x = self.convs(x)\r\n         44     x = x.view(-1, self.flatten)\r\n         45     sm = F.relu(self.fc1(x))\r\n    \r\n    &lt;ipython-input-5-4fddc427892a&gt; in convs(self, x)\r\n         31 \r\n         32     # Creating the MaxPooling Layers\r\n    ---&gt; 33     x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2))\r\n         34     x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=(2, 2))\r\n         35     x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=(2, 2))\r\n    \r\n    /usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n        539             result = self._slow_forward(*input, **kwargs)\r\n        540         else:\r\n    --&gt; 541             result = self.forward(*input, **kwargs)\r\n        542         for hook in self._forward_hooks.values():\r\n        543             hook_result = hook(self, input, result)\r\n    \r\n    /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py in forward(self, input)\r\n        343 \r\n        344     def forward(self, input):\r\n    --&gt; 345         return self.conv2d_forward(input, self.weight)\r\n        346 \r\n        347 class Conv3d(_ConvNd):\r\n    \r\n    /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py in conv2d_forward(self, input, weight)\r\n        340                             _pair(0), self.dilation, self.groups)\r\n        341         return F.conv2d(input, weight, self.bias, self.stride,\r\n    --&gt; 342                         self.padding, self.dilation, self.groups)\r\n        343 \r\n        344     def forward(self, input):\r\n    \r\n    RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same\r\n\r\nI double-checked that my Neural Net and my Inputs both are in GPU. I&#39;m still getting this error and I don&#39;t understand why!\r\n\r\nSomebody, please help me to get out of this error.\r\n",
        "accepted_answer_markdown": "Cast your input `x_batch` to float. Use `x_batch = x_batch.float()` before you pass it through your model. "
    },
    {
        "question_id": "59648324",
        "accepted_answer_id": "59648484",
        "question_title": "Pytorch tensor, how to switch channel position - Runtime error",
        "question_markdown": "I have my training dataset as below, where X_train is 3D with 3 channels\r\n\r\nShape of X_Train:  (708, 256, 3)\r\nShape of Y_Train:  (708, 4)\r\n\r\nThen I convert them into a tensor and input into the dataloader:\r\n```\r\nX_train=torch.from_numpy(X_data)\r\ny_train=torch.from_numpy(y_data)\r\ntraining_dataset = torch.utils.data.TensorDataset(X_train, y_train)\r\ntrain_loader = torch.utils.data.DataLoader(training_dataset, batch_size=50, shuffle=False)\r\n```\r\n\r\nHowever when training the model, I get the following error:\r\nRuntimeError: Given groups=1, weight of size 24 3 5, expected input[708, 256, 3] to have 3 channels, but got 256 channels instead\r\n\r\nI suppose this is due to the position of the channel? In Tensorflow, the channel position is at the end, but in PyTorch the format is &quot;Batch Size x Channel x Height x Width&quot;? So how do I swap the positions in the x_train tensor to match the expected format in the dataloader?\r\n\r\n```\r\nclass TwoLayerNet(torch.nn.Module):\r\n    def __init__(self):\r\n        super(TwoLayerNet,self).__init__()\r\n        self.conv1 = nn.Sequential(\r\n            nn.Conv1d(3, 3*8, kernel_size=5, stride=1),  \r\n            nn.Sigmoid(),\r\n            nn.AvgPool1d(kernel_size=2, stride=0))\r\n        self.conv2 = nn.Sequential(\r\n            nn.Conv1d(3*8, 12, kernel_size=5, stride=1),\r\n            nn.Sigmoid(),\r\n            nn.AvgPool1d(kernel_size=2, stride = 0))\r\n        #self.drop_out = nn.Dropout()\r\n\r\n        self.fc1 = nn.Linear(708, 732) \r\n        self.fc2 = nn.Linear(732, 4)\r\n\r\n    def forward(self, x):\r\n        out = self.conv1(x)\r\n        out = self.conv2(out)\r\n        out = out.reshape(out.size(0), -1)\r\n        out = self.drop_out(out)\r\n        out = self.fc1(out)\r\n        out = self.fc2(out)\r\n        return out\r\n```",
        "accepted_answer_markdown": "Use [`permute`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute). \r\n\r\n    X_train = torch.rand(708, 256, 3)\r\n    X_train = X_train.permute(2, 0, 1)\r\n    X_train.shape\r\n    # =&gt; torch.Size([3, 708, 256])\r\n\r\n"
    },
    {
        "question_id": "59718130",
        "accepted_answer_id": "59719680",
        "question_title": "What are C classes for a NLLLoss loss function in Pytorch?",
        "question_markdown": "I&#39;m asking about C classes for a [NLLLoss][1] loss function.\r\n\r\nThe documentation states:\r\n\r\n&gt; The negative log likelihood loss. It is useful to train a classification problem with C classes.\r\n\r\nBasically everything after that point depends upon you knowing what a C class is, and I thought I knew what a C class was but the documentation doesn&#39;t make much sense to me. Especially when it describes the expected inputs of `(N, C) where C = number of classes`. That&#39;s where I&#39;m confused, because I thought a C class refers to the *output* only. My understanding was that the C class was a one hot vector of classifications. I&#39;ve often found in tutorials that the `NLLLoss` was often paired with a `LogSoftmax` to solve classification problems.\r\n\r\nI was expecting to use `NLLLoss` in the following example:\r\n\r\n```python\r\n# Some random training data\r\ninput = torch.randn(5, requires_grad=True)\r\nprint(input)  # tensor([-1.3533, -1.3074, -1.7906,  0.3113,  0.7982], requires_grad=True)\r\n# Build my NN (here it&#39;s just a LogSoftmax)\r\nm = nn.LogSoftmax(dim=0)\r\n# Train my NN with the data\r\noutput = m(input)\r\nprint(output)  # tensor([-2.8079, -2.7619, -3.2451, -1.1432, -0.6564], grad_fn=&lt;LogSoftmaxBackward&gt;)\r\nloss = nn.NLLLoss()\r\nprint(loss(output, torch.tensor([1, 0, 0])))\r\n```\r\n\r\nThe above raises the following error on the last line:\r\n\r\n&gt; ValueError: Expected 2 or more dimensions (got 1)\r\n\r\nWe can ignore the error, because clearly I don&#39;t understand what I&#39;m doing. Here I&#39;ll explain my intentions of the above source code.\r\n\r\n```python\r\ninput = torch.randn(5, requires_grad=True)\r\n```\r\n\r\nRandom 1D array to pair with one hot vector of `[1, 0, 0]` for training. I&#39;m trying to do a binary bits to one hot vector of decimal numbers.\r\n\r\n```python\r\nm = nn.LogSoftmax(dim=0)\r\n```\r\n\r\nThe documentation for `LogSoftmax` says that the output will be the same shape as the input, but I&#39;ve only seen examples of `LogSoftmax(dim=1)` and therefore I&#39;ve been stuck trying to make this work because I can&#39;t find a relative example.\r\n\r\n```python\r\nprint(loss(output, torch.tensor([1, 0, 0])))\r\n```\r\n\r\nSo now I have the output of the NN, and I want to know the loss from my classification `[1, 0, 0]`. It doesn&#39;t really matter in this example what any of the data is. I just want a loss for a one hot vector that represents classification.\r\n\r\nAt this point I get stuck trying to resolve errors from the loss function relating to expected output and input structures. I&#39;ve tried using `view(...)` on the output and input to fix the shape, but that just gets me other errors.\r\n\r\nSo this goes back to my original question and I&#39;ll show the example from the documentation to explain my confusion:\r\n\r\n```python\r\nm = nn.LogSoftmax(dim=1)\r\nloss = nn.NLLLoss()\r\ninput = torch.randn(3, 5, requires_grad=True)\r\ntrain = torch.tensor([1, 0, 4])\r\nprint(&#39;input&#39;, input)  # input tensor([[...],[...],[...]], requires_grad=True)\r\noutput = m(input)\r\nprint(&#39;train&#39;, output, train)  # tensor([[...],[...],[...]],grad_fn=&lt;LogSoftmaxBackward&gt;) tensor([1, 0, 4])\r\nx = loss(output, train)\r\n```\r\n\r\nAgain, we have `dim=1` on `LogSoftmax` which confuses me now, because look at the `input` data. It&#39;s a `3x5` tensor and I&#39;m lost.\r\n\r\nHere&#39;s the documentation on the first input for the `NLLLoss` function:\r\n\r\n&gt; Input: (N, C)(N,C) where C = number of classes\r\n\r\nThe inputs are *grouped* by the number of classes?\r\n\r\nSo each *row* of the tensor input is associated with each *element* of the training tensor?\r\n\r\nIf I change the second dimension of the input tensor, then *nothing breaks* and I don&#39;t understand what is going on.\r\n\r\n```python\r\ninput = torch.randn(3, 100, requires_grad=True)\r\n# 3 x 100 still works?\r\n```\r\n\r\nSo I don&#39;t understand what a C class is here, and I thought a C class was a classification (like a label) and meaningful only on the outputs of the NN.\r\n\r\nI hope you understand my confusion, because shouldn&#39;t the shape of the inputs for the NN be independent from the shape of the one hot vector used for classification?\r\n\r\nBoth the code examples and documentations say that the shape of the inputs is defined by the number of classifications, and I don&#39;t really understand why.\r\n\r\nI have tried to study the documentations and tutorials to understand what I&#39;m missing, but after several days of not being able to get past this point I&#39;ve decided to ask this question. It&#39;s been humbling because I thought this was going to be one of the easier things to learn.\r\n\r\n\r\n  [1]: https://pytorch.org/docs/stable/nn.html?highlight=nllloss#torch.nn.NLLLoss",
        "accepted_answer_markdown": "Basically you are missing a concept of `batch`.\r\n\r\nLong story short, every input to loss (and the one passed through the network) requires `batch` dimension (i.e. how many samples are used).\r\n\r\nBreaking it up, step by step:\r\n\r\n# Your example vs documentation\r\n\r\nEach step will be each step compared to make it clearer (documentation on top, your example below)\r\n\r\n## Inputs\r\n\r\n    input = torch.randn(3, 5, requires_grad=True)\r\n    input = torch.randn(5, requires_grad=True)\r\n\r\nIn the first case (docs), input with `5` features is created and `3` samples are used. In your case there is only `batch` dimension (`5` samples), you have no features __which are required__. If you meant to have one sample with `5` features you should do:\r\n\r\n    input = torch.randn(5, requires_grad=True)\r\n\r\n## LogSoftmax\r\n\r\n`LogSoftmax` is done across features dimension, you are doing it across batch.\r\n\r\nm = nn.LogSoftmax(dim=1) # apply over features\r\nm = nn.LogSoftmax(dim=0) # apply over batch\r\n\r\nIt makes no sense usually for this operation as samples are independent of each other.\r\n\r\n## Targets\r\n\r\nAs this is multiclass classification and each element in vector represents a sample, one can pass as many numbers as one wants (as long as it&#39;s smaller than number of features, in case of documentation example it&#39;s `5`, hence `[0-4]` is fine ).\r\n\r\n    train = torch.tensor([1, 0, 4])\r\n    train = torch.tensor([1, 0, 0])\r\n\r\nI assume, you wanted to pass one-hot vector as target as well. PyTorch doesn&#39;t work that way as it&#39;s __memory inefficient__ (why store everything as one-hot encoded when you can just pinpoint exactly the class, in your case it would be `0`).\r\n\r\nOnly outputs of neural network are one hot encoded in order to backpropagate error through all output nodes, it&#39;s not needed for targets.\r\n\r\n# Final\r\n\r\n__You shouldn&#39;t__ use `torch.nn.LogSoftmax` __at all__ for this task. Just use `torch.nn.Linear` as last layer and use `torch.nn.CrossEntropyLoss` with your targets.\r\n\r\n\r\n"
    },
    {
        "question_id": "60022388",
        "accepted_answer_id": "60097284",
        "question_title": "Pytorch: RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered",
        "question_markdown": "I am running into the following error when trying to train [this][1] on [this dataset][2].\r\n\r\nSince this is the configuration published in the paper, I am assuming I am doing something incredibly wrong.\r\n\r\nThis error arrives on a different image every time I try to run training.\r\n\r\n    C:/w/1/s/windows/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:106: block: [0,0,0], thread: [6,0,0] Assertion `t &gt;= 0 &amp;&amp; t &lt; n_classes` failed.\r\n    Traceback (most recent call last):\r\n      File &quot;C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.1.1\\helpers\\pydev\\pydevd.py&quot;, line 1741, in &lt;module&gt;\r\n        main()\r\n      File &quot;C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.1.1\\helpers\\pydev\\pydevd.py&quot;, line 1735, in main\r\n        globals = debugger.run(setup[&#39;file&#39;], None, None, is_module)\r\n      File &quot;C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.1.1\\helpers\\pydev\\pydevd.py&quot;, line 1135, in run\r\n        pydev_imports.execfile(file, globals, locals)  # execute the script\r\n      File &quot;C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.1.1\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py&quot;, line 18, in execfile\r\n        exec(compile(contents+&quot;\\n&quot;, file, &#39;exec&#39;), glob, loc)\r\n      File &quot;C:/Noam/Code/vision_course/hopenet/deep-head-pose/code/original_code_augmented/train_hopenet_with_validation_holdout.py&quot;, line 187, in &lt;module&gt;\r\n        loss_reg_yaw = reg_criterion(yaw_predicted, label_yaw_cont)\r\n      File &quot;C:\\Noam\\Code\\vision_course\\hopenet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 541, in __call__\r\n        result = self.forward(*input, **kwargs)\r\n      File &quot;C:\\Noam\\Code\\vision_course\\hopenet\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py&quot;, line 431, in forward\r\n        return F.mse_loss(input, target, reduction=self.reduction)\r\n      File &quot;C:\\Noam\\Code\\vision_course\\hopenet\\venv\\lib\\site-packages\\torch\\nn\\functional.py&quot;, line 2204, in mse_loss\r\n        ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\r\n    RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered\r\n\r\n\r\n___\r\n\r\nAny ideas?\r\n\r\n  [1]: https://github.com/natanielruiz/deep-head-pose/blob/master/code/test_hopenet.py\r\n  [2]: https://drive.google.com/file/d/0B7OEHD3T4eCkVGs0TkhUWFN6N1k/view",
        "accepted_answer_markdown": "This kind of error generally occurs when using `NLLLoss` or `CrossEntropyLoss`, and when your dataset has negative labels (or labels greater than the number of classes). That is also the exact error you are getting Assertion `t &gt;= 0 &amp;&amp; t &lt; n_classes` failed. \r\n\r\nThis won&#39;t occur for `MSELoss`, but OP mentions that there is a `CrossEntropyLoss` somewhere and thus the error occurs (the program crashes asynchronously on some other line). The solution is to clean the dataset and ensure that `t &gt;= 0 &amp;&amp; t &lt; n_classes` is satisfied (where `t` represents the label).\r\n\r\nAlso, ensure that your network output is in the range 0 to 1 in case you use `NLLLoss` or `BCELoss` (then you require `softmax` or `sigmoid` activation respectively). Note that this is not required for `CrossEntropyLoss` or `BCEWithLogitsLoss` because they implement the activation function inside the loss function. (Thanks to @PouyaB for pointing out)."
    },
    {
        "question_id": "60121107",
        "accepted_answer_id": "60162037",
        "question_title": "pytorch nllloss function target shape mismatch",
        "question_markdown": "I&#39;m training a LSTM model using pytorch with batch size of 256 and NLLLoss() as loss function.\r\nThe loss function is having problem with the data shape.\r\n\r\nThe softmax output from the forward passing has shape of `torch.Size([256, 4, 1181])` where 256 is batch size, 4 is sequence length, and 1181 is vocab size.\r\n\r\nThe target is in the shape of ```torch.Size([256, 4])``` where 256 is batch size and 4 is the output sequence length.\r\n\r\nWhen I was testing earlier with batch size of 1, the model works fine but when I add batch size, it is breaking. I read that NLLLoss() can take class target as input instead of one hot encoded target.\r\n\r\nAm I misunderstanding it? Or did I not format the shape of the target correctly?\r\n\r\n```\r\nclass LSTM(nn.Module):\r\n\r\n    def __init__(self, embed_size=100, hidden_size=100, vocab_size=1181, embedding_matrix=...):\r\n        super(LSTM, self).__init__()\r\n        self.hidden_size = hidden_size\r\n        self.word_embeddings = nn.Embedding(vocab_size, embed_size)\r\n        self.word_embeddings.load_state_dict({&#39;weight&#39;: torch.Tensor(embedding_matrix)})\r\n        self.word_embeddings.weight.requires_grad = False\r\n        self.lstm = nn.LSTM(embed_size, hidden_size)\r\n        self.hidden2out = nn.Linear(hidden_size, vocab_size)\r\n        \r\n\r\n    def forward(self, tokens):\r\n        batch_size, num_steps = tokens.shape\r\n        embeds = self.word_embeddings(tokens)\r\n        lstm_out, _ = self.lstm(embeds.view(batch_size, num_steps, -1))\r\n        out_space = self.hidden2out(lstm_out.view(batch_size, num_steps, -1))\r\n        out_scores = F.log_softmax(out_space, dim=1)\r\n        return out_scores\r\n\r\nmodel = LSTM(self.config.embed_size, self.config.hidden_size, self.config.vocab_size, self.embedding_matrix)\r\nloss_function = nn.NLLLoss()\r\noptimizer = optim.Adam(model.parameters(), lr=self.config.lr)\r\n```\r\n\r\nError:\r\n\r\n    ~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)\r\n       1846         if target.size()[1:] != input.size()[2:]:\r\n       1847             raise ValueError(&#39;Expected target size {}, got {}&#39;.format(\r\n    -&gt; 1848                 out_size, target.size()))\r\n       1849         input = input.contiguous().view(n, c, 1, -1)\r\n       1850         target = target.contiguous().view(n, 1, -1)\r\n    \r\n    ValueError: Expected target size (256, 554), got torch.Size([256, 4])",
        "accepted_answer_markdown": "Your input shape to the loss function is `(N, d, C) = (256, 4, 1181)` and your target shape is `(N, d) = (256, 4)`, however, according to the docs on [NLLLoss](https://pytorch.org/docs/stable/nn.html?highlight=nllloss#torch.nn.NLLLoss) the input should be `(N, C, d)` for a target of `(N, d)`.\r\n\r\nSupposing `x` is your network output and `y` is the target then you can compute loss by transposing the incorrect dimensions of `x` as follows:\r\n\r\n    loss = loss_function(x.transpose(1, 2), y)\r\n\r\nAlternatively, since NLLLoss is just averaging all the responses anyway, you can reshape `x` and `y` to be `(N*d, C)` and `(N*d)`. This gives the same result without creating temporary copies of your tensors.\r\n\r\n    loss = loss_function(x.reshape(N*d, C), y.reshape(N*d))"
    },
    {
        "question_id": "60173417",
        "accepted_answer_id": "60176057",
        "question_title": "Pytorch default dataloader gets stuck for large image classification training set",
        "question_markdown": "I am training image classification models in Pytorch and using their [default data loader][1] to load my training data. I have a very large training dataset, so usually a couple thousand sample images per class. I&#39;ve trained models with about 200k images total without issues in the past. However I&#39;ve found that when have over a million images in total, the Pytorch data loader get stuck.\r\n\r\nI believe the code is hanging when I call `datasets.ImageFolder(...)`. When I Ctrl-C, this is consistently the output:\r\n\r\n```                                                               \u2502\r\nTraceback (most recent call last):                                                                                                 \u2502\r\n  File &quot;main.py&quot;, line 412, in &lt;module&gt;                                                                                            \u2502\r\n    main()                                                                                                                         \u2502\r\n  File &quot;main.py&quot;, line 122, in main                                                                                                \u2502\r\n    run_training(args.group, args.num_classes)                                                                                     \u2502\r\n  File &quot;main.py&quot;, line 203, in run_training                                                                                        \u2502\r\n    train_loader = create_dataloader(traindir, tfm.train_trans, shuffle=True)                                                      \u2502\r\n  File &quot;main.py&quot;, line 236, in create_dataloader                                                                                   \u2502\r\n    dataset = datasets.ImageFolder(directory, trans)                                                                               \u2502\r\n  File &quot;/home/username/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py&quot;, line 209, in __init__     \u2502\r\n    is_valid_file=is_valid_file)                                                                                                   \u2502\r\n  File &quot;/home/username/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py&quot;, line 94, in __init__      \u2502\r\n    samples = make_dataset(self.root, class_to_idx, extensions, is_valid_file)                                                     \u2502\r\n  File &quot;/home/username/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py&quot;, line 47, in make_dataset  \u2502\r\n    for root, _, fnames in sorted(os.walk(d)):                                                                                     \u2502\r\n  File &quot;/usr/lib/python3.5/os.py&quot;, line 380, in walk                                                                               \u2502\r\n    is_dir = entry.is_dir()                                                                                                        \u2502\r\nKeyboard Interrupt                                                                                                                       \r\n```\r\n\r\n\r\n\r\nI thought there might be a deadlock somewhere, however based off the stack output from Ctrl-C it doesn&#39;t look like its waiting on a lock. So then I thought that the dataloader was just slow because I was trying to load a lot more data. I let it run for about 2 days and it didn&#39;t make any progress, and in the last 2 hours of loading I checked the amount of RAM usage stayed the same.  I also have been able to load training datasets with over 200k images in less than a couple hours in the past. I also tried upgrading my GCP machine to have 32 cores, 4 GPUs, and over 100GB in RAM, however it seems to be that after a certain amount of memory is loaded the data loader just gets stuck. \r\n\r\nI&#39;m confused how the data loader could be getting stuck while looping through the directory, and I&#39;m still unsure if its stuck or just extremely slow. Is there some way I can change the Pytortch dataloader to be able to handle 1million+ images for training? Any debugging suggestions are also appreciated! \r\n\r\nThank you!\r\n \r\n\r\n\r\n  [1]: https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder",
        "accepted_answer_markdown": "It&#39;s not a problem with `DataLoader`, it&#39;s a problem with `torchvision.datasets.ImageFolder` and how it works (and why it works much much worse the more data you have).\r\n\r\nIt hangs on this line, as indicated by your error:\r\n\r\n    for root, _, fnames in sorted(os.walk(d)): \r\n\r\nSource can be found [here](https://pytorch.org/docs/stable/_modules/torchvision/datasets/folder.html#ImageFolder).\r\n\r\nUnderlying problem is it keeps each `path` and corresponding `label` in giant `list`, see the code below (a few things removed for brevity):\r\n\r\n    def make_dataset(dir, class_to_idx, extensions=None, is_valid_file=None):\r\n        images = []\r\n        dir = os.path.expanduser(dir)\r\n        # Iterate over all subfolders which were found previously\r\n        for target in sorted(class_to_idx.keys()):\r\n            d = os.path.join(dir, target) # Create path to this subfolder\r\n            # Assuming it is directory (which usually is the case)\r\n            for root, _, fnames in sorted(os.walk(d, followlinks=True)):\r\n                # Iterate over ALL files in this subdirectory\r\n                for fname in sorted(fnames):\r\n                    path = os.path.join(root, fname)\r\n                    # Assuming it is correctly recognized as image file\r\n                    item = (path, class_to_idx[target])\r\n                    # Add to path with all images\r\n                    images.append(item)\r\n    \r\n        return images\r\n\r\nObviously images will contain 1 million strings (quite lengthy as well) and corresponding `int` for the classes which definitely is a lot and depends on RAM and CPU.\r\n\r\nYou can create your own datasets though (provided you change names of your images beforehand) so __no memory will be occupied__ by the `dataset`.\r\n\r\n## Setup data structure\r\n\r\nYour folder structure should look like this:\r\n\r\n    root\r\n        class1\r\n        class2\r\n        class3\r\n        ...\r\n\r\nUse how many classes you have/need.\r\n\r\nNow each `class` should have the following data:\r\n\r\n    class1\r\n        0.png\r\n        1.png\r\n        2.png\r\n        ...\r\n\r\nGiven that you can move on to creating datasets.\r\n\r\n## Create Datasets\r\n\r\nBelow `torch.utils.data.Dataset` uses `PIL` to open images, you could do it in another way though:\r\n\r\n    import os\r\n    import pathlib\r\n\r\n    import torch\r\n    from PIL import Image\r\n    \r\n    \r\n    class ImageDataset(torch.utils.data.Dataset):\r\n        def __init__(self, root: str, folder: str, klass: int, extension: str = &quot;png&quot;):\r\n            self._data = pathlib.Path(root) / folder\r\n            self.klass = klass\r\n            self.extension = extension\r\n            # Only calculate once how many files are in this folder\r\n            # Could be passed as argument if you precalculate it somehow\r\n            # e.g. ls | wc -l on Linux\r\n            self._length = sum(1 for entry in os.listdir(self._data))\r\n    \r\n        def __len__(self):\r\n            # No need to recalculate this value every time\r\n            return self._length\r\n    \r\n        def __getitem__(self, index):\r\n            # images always follow [0, n-1], so you access them directly\r\n            return Image.open(self._data / &quot;{}.{}&quot;.format(str(index), self.extension))\r\n\r\n\r\nNow you can create your datasets easily (folder structure assumed like the one above:\r\n\r\n    root = &quot;/path/to/root/with/images&quot;\r\n    dataset = (\r\n        ImageDataset(root, &quot;class0&quot;, 0)\r\n        + ImageDataset(root, &quot;class1&quot;, 1)\r\n        + ImageDataset(root, &quot;class2&quot;, 2)\r\n    )\r\n\r\nYou could add as many `datasets` with specified classes as you wish, do it in loop or whatever.\r\n\r\nFinally, use `torch.utils.data.DataLoader` as per usual, e.g.:\r\n\r\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\r\n\r\n"
    },
    {
        "question_id": "68477345",
        "accepted_answer_id": "68477618",
        "question_title": "CPU only pytorch is crashing with error AssertionError: Torch not compiled with CUDA enabled",
        "question_markdown": "I&#39;m trying to run the code from [this repository][1] and I need to use Pytorch 1.4.0. I&#39;ve installed the CPU only version of pytorch with `pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html`.\r\n\r\nI ran the program by doing `py -m train_Kfold_CV --device 0 --fold_id 10 --np_data_dir &quot;C:\\Users\\username\\OneDrive\\Desktop\\emadeldeen\\AttnSleep\\prepare_datasets\\edf_20_npz&quot;` but I&#39;m getting this error:\r\n\r\n```\r\n  File &quot;C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py&quot;, line 193, in _run_module_as_main\r\n    &quot;__main__&quot;, mod_spec)\r\n  File &quot;C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py&quot;, line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File &quot;C:\\Users\\username\\OneDrive\\Desktop\\emadeldeen\\AttnSleep\\train_Kfold_CV.py&quot;, line 94, in &lt;module&gt;\r\n    main(config, fold_id)\r\n  File &quot;C:\\Users\\username\\OneDrive\\Desktop\\emadeldeen\\AttnSleep\\train_Kfold_CV.py&quot;, line 65, in main\r\n    trainer.train()\r\n  File &quot;C:\\Users\\username\\OneDrive\\Desktop\\emadeldeen\\AttnSleep\\base\\base_trainer.py&quot;, line 66, in train\r\n    result, epoch_outs, epoch_trgs = self._train_epoch(epoch, self.epochs)\r\n  File &quot;C:\\Users\\username\\OneDrive\\Desktop\\emadeldeen\\AttnSleep\\trainer\\trainer.py&quot;, line 49, in _train_epoch\r\n    loss = self.criterion(output, target, self.class_weights)\r\n  File &quot;C:\\Users\\username\\OneDrive\\Desktop\\emadeldeen\\AttnSleep\\model\\loss.py&quot;, line 6, in weighted_CrossEntropyLoss\r\n    cr = nn.CrossEntropyLoss(weight=torch.tensor(classes_weights).cuda())\r\n  File &quot;C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\__init__.py&quot;, line 196, in _lazy_init\r\n    _check_driver()\r\n  File &quot;C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\__init__.py&quot;, line 94, in _check_driver\r\n    raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)\r\nAssertionError: Torch not compiled with CUDA enabled\r\n```\r\nI&#39;ve changed the number of GPU in the config to 0 and tried adding `device = torch.device(&#39;cpu&#39;)` at the begining of the program, but it&#39;s not doing anything. How can I fix this error? I&#39;m using windows 10 with python 3.7.9 if it helps\r\n\r\nThanks\r\n\r\n\r\n  [1]: https://github.com/emadeldeen24/AttnSleep",
        "accepted_answer_markdown": "You are using CPU only pytorch, but your code has statement like `cr = nn.CrossEntropyLoss(weight=torch.tensor(classes_weights).cuda())` which is trying to move the tensor to GPU. \r\n\r\nTo fix it,\r\n remove all the `.cuda()` operations. "
    },
    {
        "question_id": "69006025",
        "accepted_answer_id": "69170934",
        "question_title": "Adding a simple attention layer to a custom resnet 18 architecture causes error in forward pass",
        "question_markdown": "I am adding the following code in resnet18 custom code \r\n\r\n    self.layer1 = self._make_layer(block, 64, layers[0]) ## code existed before\r\n    self.layer2 = self._make_layer(block, 128, layers[1], stride=2) ## code existed before\r\n    self.layer_attend1 =  nn.Sequential(nn.Conv2d(layers[0], layers[0], stride=2, padding=1, kernel_size=3),\r\n                                         nn.AdaptiveAvgPool2d(1),\r\n                                         nn.Softmax(1)) ## code added by me\r\n\r\nand also the following in its forward pass (`def forward(self, x)`) in the same resnet18 custom code:\r\n\r\n    x = self.layer1(x) ## the code existed before\r\n    x = self.layer_attend1(x)*x ## I added this code\r\n    x = self.layer2(x) ## the code existed before\r\n\r\nand I get the following error. I had no error before adding this attention layer. Any idea how I could fix it?\r\n\r\n    =&gt; loading checkpoint &#39;runs/nondisjoint_l2norm/model_best.pth.tar&#39;\r\n    =&gt; loaded checkpoint &#39;runs/nondisjoint_l2norm/model_best.pth.tar&#39; (epoch 5)\r\n    /scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\r\n      return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n    Traceback (most recent call last):\r\n      File &quot;main.py&quot;, line 352, in &lt;module&gt;\r\n        main()    \r\n      File &quot;main.py&quot;, line 153, in main\r\n        test_acc = test(test_loader, tnet)\r\n      File &quot;main.py&quot;, line 248, in test\r\n        embeddings.append(tnet.embeddingnet(images).data)\r\n      File &quot;/scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1051, in _call_impl\r\n        return forward_call(*input, **kwargs)\r\n      File &quot;/scratch3/research/code/fashion/fashion-compatibility/type_specific_network.py&quot;, line 101, in forward\r\n        embedded_x = self.embeddingnet(x)\r\n      File &quot;/scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1051, in _call_impl\r\n        return forward_call(*input, **kwargs)\r\n      File &quot;/scratch3/research/code/fashion/fashion-compatibility/Resnet_18.py&quot;, line 110, in forward\r\n        x = self.layer_attend1(x)*x #so we don;t use name x1\r\n      File &quot;/scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1051, in _call_impl\r\n        return forward_call(*input, **kwargs)\r\n      File &quot;/scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/modules/container.py&quot;, line 139, in forward\r\n        input = module(input)\r\n      File &quot;/scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1051, in _call_impl\r\n        return forward_call(*input, **kwargs)\r\n      File &quot;/scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/modules/conv.py&quot;, line 443, in forward\r\n        return self._conv_forward(input, self.weight, self.bias)\r\n      File &quot;/scratch3/venv/fashcomp/lib/python3.8/site-packages/torch/nn/modules/conv.py&quot;, line 439, in _conv_forward\r\n        return F.conv2d(input, weight, bias, self.stride,\r\n    RuntimeError: Given groups=1, weight of size [2, 2, 3, 3], expected input[256, 64, 28, 28] to have 2 channels, but got 64 channels instead\r\n\r\n\r\nIn VSCode even though I added a checkpoint before the problematic layer, it didn&#39;t even go to the checkpoint\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.sstatic.net/1ZiiE.png",
        "accepted_answer_markdown": "The problem comes from a confusion: `layers[0]` is not the number of output channels, as you probably expected, but the number of blocks that layer will have. What you actually need is to use the `64`, which is the number of output channels of the `layer1` that precede your custom code:\r\n\r\n```python\r\nself.layer_attend1 =  nn.Sequential(nn.Conv2d(64, 64, stride=2, padding=1, kernel_size=3),\r\n                                    nn.AdaptiveAvgPool2d(1),\r\n                                    nn.Softmax(1)) ## code added by me\r\n```"
    },
    {
        "question_id": "69151052",
        "accepted_answer_id": "69151273",
        "question_title": "using ImageFolder with albumentations in pytorch",
        "question_markdown": "I have a situation where I need to use ImageFolder with the albumentations lib to make the augmentations in pytorch - custom dataloader is not an option.\r\n\r\nTo this end, I am stumped and I am not able to get ImageFolder to work with albumenations. I have tried something along these lines:\r\n\r\n```\r\nclass Transforms:\r\n    def __init__(self, transforms: A.Compose):\r\n        self.transforms = transforms\r\n\r\n    def __call__(self, img, *args, **kwargs):\r\n        return self.transforms(image=np.array(img))[&#39;image&#39;]\r\n```\r\n\r\nand then:\r\n\r\n```\r\n    trainset = datasets.ImageFolder(traindir,transform=Transforms(transforms=A.Resize(32 , 32)))\r\n```\r\n\r\nwhere `traindir` is some dir with images. I however get thrown a weird error:\r\n\r\n```\r\nRuntimeError: Given groups=1, weight of size [16, 3, 3, 3], expected input[1024, 32, 32, 3] to have 3 channels, but got 32 channels instead\r\n```\r\n\r\nand I cant seem to find a reproducible example to make a simple aug pipleline work with imagefolder.\r\n\r\n\r\n*UPDATE*\r\nOn the recommendation of @Shai, I have done this now:\r\n\r\n```\r\nclass Transforms:\r\n    def __init__(self):\r\n        self.transforms = A.Compose([A.Resize(224,224),ToTensorV2()])\r\n\r\n    def __call__(self, img, *args, **kwargs):\r\n        return self.transforms(image=np.array(img))[&#39;image&#39;]\r\n```\r\n\r\n```\r\ntrainset = datasets.ImageFolder(traindir,transform=Transforms())\r\n```\r\n\r\nbut I get thrown:\r\n\r\n```\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same\r\n```\r\n\r\n",
        "accepted_answer_markdown": "You need to use [`ToTensorV2`][1] transformation as the final one:\r\n\r\n```python\r\ntrainset = datasets.ImageFolder(traindir,transform=Transforms(transforms=A.Compose([A.Resize(32 , 32), ToTensorV2()]))\r\n```\r\n\r\n\r\n [1]: https://albumentations.ai/docs/api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2"
    },
    {
        "question_id": "69234232",
        "accepted_answer_id": "69234343",
        "question_title": "How can I solve the problem that method is not iterable?",
        "question_markdown": "I have this Variational autoencoder and I want to use Adam for its optimizer but it has this error I don&#39;t know what is wrong here\r\n```\r\nclass VAE(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n        #encoder\r\n        self.enc = nn.Sequential(\r\n            nn.Linear(1200, 786),\r\n            nn.ReLU(),\r\n            nn.Flatten()\r\n        )\r\n        self.mean = nn.Linear(1200, 2)\r\n        self.log = nn.Linear(1200, 2)\r\n        #decoder\r\n        self.dec = nn.Sequential(\r\n            nn.Linear(2, 1200),\r\n            nn.ReLU(),\r\n        )\r\n\r\n    def param(self, mu, Log):\r\n        eps = torch.randn(2, 1200)\r\n        z = mu + (eps * torch.exp(Log * 0.5))\r\n        return z\r\n\r\n    def forward(self, x):\r\n        x = self.enc(x)\r\n        mu , log = self.mean(x), self.log(x)\r\n        z = self.param(mu, log)\r\n        x = self.dec(z)\r\n        return x, mu, log\r\n\r\nmodel = VAE()\r\noptim = torch.optim.Adam(model.param, lr=0.01)\r\ncriterion = nn.CrossEntropyLoss()\r\n```\r\nand here is the error\r\n ```\r\nTraceback (most recent call last):\r\n  File &quot;C:\\Users\\khashayar\\PycharmProjects\\pythonProject2\\VAE.py&quot;, line 40, in &lt;module&gt;\r\n    optim = torch.optim.Adam(model.param, lr=0.01)\r\n  File &quot;C:\\Users\\khashayar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\optim\\adam.py&quot;, line 48, in __init__\r\n    super(Adam, self).__init__(params, defaults)\r\n  File &quot;C:\\Users\\khashayar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\optim\\optimizer.py&quot;, line 47, in __init__\r\n    param_groups = list(params)\r\nTypeError: &#39;method&#39; object is not iterable\r\n```\r\nhow I can solve this?",
        "accepted_answer_markdown": "The problem is probably in ```model.param```.\r\nparam is a method, and as write in the error : &quot;&#39;method&#39; object is not iterable&quot;. The optimizer should receive the model parameters, and not the method &quot;param&quot; of the model class.\r\n\r\nTry convert ```optim = torch.optim.Adam(model.param, lr=0.01)\r\n``` To ```optim = torch.optim.Adam(model.parameters(), lr=0.01)```"
    },
    {
        "question_id": "69239925",
        "accepted_answer_id": "69240001",
        "question_title": "TypeError in torch.argmax() when want to find the tokens with the highest `start` score",
        "question_markdown": "I want to run this code for question answering using hugging face transformers.\r\n\r\n    import torch\r\n    from transformers import BertForQuestionAnswering\r\n    from transformers import BertTokenizer\r\n    \r\n    #Model\r\n    model = BertForQuestionAnswering.from_pretrained(&#39;bert-large-uncased-whole-word-masking-finetuned-squad&#39;)\r\n    \r\n    #Tokenizer\r\n    tokenizer = BertTokenizer.from_pretrained(&#39;bert-large-uncased-whole-word-masking-finetuned-squad&#39;)\r\n    \r\n    question = &#39;&#39;&#39;Why was the student group called &quot;the Methodists?&quot;&#39;&#39;&#39;\r\n    \r\n    paragraph = &#39;&#39;&#39; The movement which would become The United Methodist Church began in the mid-18th century within the Church of England.\r\n                A small group of students, including John Wesley, Charles Wesley and George Whitefield, met on the Oxford University campus.\r\n                They focused on Bible study, methodical study of scripture and living a holy life.\r\n                Other students mocked them, saying they were the &quot;Holy Club&quot; and &quot;the Methodists&quot;, being methodical and exceptionally detailed in their Bible study, opinions and disciplined lifestyle.\r\n                Eventually, the so-called Methodists started individual societies or classes for members of the Church of England who wanted to live a more religious life. &#39;&#39;&#39;\r\n                \r\n    encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\r\n    \r\n    inputs = encoding[&#39;input_ids&#39;]  #Token embeddings\r\n    sentence_embedding = encoding[&#39;token_type_ids&#39;]  #Segment embeddings\r\n    tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\r\n    \r\n    start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\r\n    \r\n    start_index = torch.argmax(start_scores)\r\n\r\n\r\n but I get this error at the last line:\r\n\r\n    Exception has occurred: TypeError\r\n    argmax(): argument &#39;input&#39; (position 1) must be Tensor, not str\r\n      File &quot;D:\\bert\\QuestionAnswering.py&quot;, line 33, in &lt;module&gt;\r\n        start_index = torch.argmax(start_scores)\r\n\r\nI don&#39;t know what&#39;s wrong. can anyone help me?",
        "accepted_answer_markdown": "`BertForQuestionAnswering` returns a [`QuestionAnsweringModelOutput`][1] object. \r\n\r\nSince you set the output of `BertForQuestionAnswering` to `start_scores, end_scores`, the return `QuestionAnsweringModelOutput` object is forced convert to a tuple of strings `(&#39;start_logits&#39;, &#39;end_logits&#39;)` causing the type mismatch error.\r\n\r\nThe following should work:\r\n\r\n    outputs = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\r\n\r\n    start_index = torch.argmax(outputs.start_logits)\r\n\r\n\r\n  [1]: https://huggingface.co/transformers/_modules/transformers/modeling_outputs.html#QuestionAnsweringModelOutput"
    },
    {
        "question_id": "48274929",
        "accepted_answer_id": "48278089",
        "question_title": "Pytorch - RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed",
        "question_markdown": "I keep running into this error:\r\n\r\n&gt; RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.\r\n\r\nI had searched in Pytorch forum, but still can\u2019t find out what I have done wrong in my custom loss function. My model is nn.GRU, and here is my custom loss function:\r\n\r\n    def _loss(outputs, session, items):  # `items` is a dict() contains embedding of all items\r\n        def f(output, target):\r\n            pos = torch.from_numpy(np.array([items[target[&quot;click&quot;]]])).float()\r\n            neg = torch.from_numpy(np.array([items[idx] for idx in target[&quot;suggest_list&quot;] if idx != target[&quot;click&quot;]])).float()\r\n            if USE_CUDA:\r\n                pos, neg = pos.cuda(), neg.cuda()\r\n            pos, neg = Variable(pos), Variable(neg)\r\n    \r\n            pos = F.cosine_similarity(output, pos)\r\n            if neg.size()[0] == 0:\r\n                return torch.mean(F.logsigmoid(pos))\r\n            neg = F.cosine_similarity(output.expand_as(neg), neg)\r\n    \r\n            return torch.mean(F.logsigmoid(pos - neg))\r\n    \r\n        loss = map(f, outputs, session)\r\n        return -torch.mean(torch.cat(loss))\r\n\r\n\r\nTraining code:\r\n\r\n        # zero the parameter gradients\r\n        model.zero_grad()\r\n\r\n        # forward + backward + optimize\r\n        outputs, hidden = model(inputs, hidden)\r\n        loss = _loss(outputs, session, items)\r\n        acc_loss += loss.data[0]\r\n\r\n        loss.backward()\r\n        # Add parameters&#39; gradients to their values, multiplied by learning rate\r\n        for p in model.parameters():\r\n            p.data.add_(-learning_rate, p.grad.data)",
        "accepted_answer_markdown": "The problem is from my training loop: it doesn\u2019t detach or repackage the hidden state in between batches? If so, then `loss.backward()` is trying to back-propagate all the way through to the start of time, which works for the first batch but not for the second because the graph for the first batch has been discarded.\r\n\r\nthere are two possible solutions.\r\n\r\n 1) detach/repackage the hidden state in between batches. There are (at\r\n    least) three ways to do this (and I chose this solution):\r\n\r\n     hidden.detach_()\r\n     \r\n    (or equivalently hidden = hidden.detach()).\r\n     \r\n    \r\n\r\n2) replace loss.backward() with `loss.backward(retain_graph=True)` but know that each successive batch will take more time than the previous one because it will have to back-propagate all the way through to the start of the first batch.\r\n\r\n[Example][1]\r\n\r\n\r\n  [1]: https://github.com/pytorch/examples/blob/e11e0796fc02cc2cd5b6ec2ad7cea21f77e25402/word_language_model/main.py#L155"
    },
    {
        "question_id": "69393214",
        "accepted_answer_id": "69414268",
        "question_title": "PyTorch: &quot;KeyError: Caught KeyError in DataLoader worker process 0.&quot;",
        "question_markdown": "### Problem Description\r\n\r\nI tried to load image data using a PyTorch custom dataset, however, I received the error message listed below. After its occurrence, I checked the data and found that my image set consists of 2 types of shape (512,512,3) and (1024,1024). My assumption is that the error is related to this.\r\n\r\nNote: The code is able to read some of the images but throws the error message for others.\r\n\r\n### Questions\r\n\r\n 1. How should one preprocess such image data for training? \r\n\r\n 2. Are there any other reasons for the error message?\r\n\r\n### Error message\r\n\r\n    KeyError                                  Traceback (most recent call last)\r\n    &lt;ipython-input-163-aa3385de8026&gt; in &lt;module&gt;\r\n    ----&gt; 1 train_features, train_labels = next(iter(train_dataloader))\r\n      2 print(f&quot;Feature batch shape: {train_features.size()}&quot;)\r\n      3 print(f&quot;Labels batch shape: {train_labels.size()}&quot;)\r\n      4 img = train_features[0].squeeze()\r\n      5 label = train_labels[0]\r\n\r\n     ~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils  /data/dataloader.py in __next__(self)\r\n    519             if self._sampler_iter is None:\r\n    520                 self._reset()\r\n    521             data = self._next_data()\r\n    522             self._num_yielded += 1\r\n    523             if self._dataset_kind == _DatasetKind.Iterable and \\\r\n\r\n    ~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _next_data(self)\r\n    1201             else:\r\n    1202                 del self._task_info[idx]\r\n    1203                 return self._process_data(data)\r\n    1204 \r\n    1205     def _try_put_index(self):\r\n\r\n    ~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _process_data(self, data)\r\n    1227         self._try_put_index()\r\n    1228         if isinstance(data, ExceptionWrapper):\r\n    1229             data.reraise()\r\n    1230         return data\r\n    1231 \r\n\r\n    ~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/_utils.py in reraise(self)\r\n    423             # have message field\r\n    424             raise self.exc_type(message=msg)\r\n    425         raise self.exc_type(msg)\r\n    426 \r\n    427 \r\n\r\n    KeyError: Caught KeyError in DataLoader worker process 0.\r\n    Original Traceback (most recent call last):\r\n    File &quot;/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas  /core/indexes/base.py&quot;, line 2898, in get_loc\r\n    return self._engine.get_loc(casted_key)\r\n    File &quot;pandas/_libs/index.pyx&quot;, line 70, in pandas._libs.index.IndexEngine.get_loc\r\n    File &quot;pandas/_libs/index.pyx&quot;, line 101, in pandas._libs.index.IndexEngine.get_loc\r\n    File &quot;pandas/_libs/hashtable_class_helper.pxi&quot;, line 1032, in    pandas._libs.hashtable.Int64HashTable.get_item\r\n    File &quot;pandas/_libs/hashtable_class_helper.pxi&quot;, line 1039, in   pandas._libs.hashtable.Int64HashTable.get_item\r\n    KeyError: 16481\r\n\r\n    The above exception was the direct cause of the following exception:\r\n\r\n    Traceback (most recent call last):\r\n    File &quot;/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py&quot;, line 287, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n    File &quot;/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py&quot;, line 44, in fetch\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n    File &quot;/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py&quot;, line 44, in &lt;listcomp&gt;\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n    File &quot;&lt;ipython-input-161-f38b78d77dcb&gt;&quot;, line 19, in __getitem__\r\n    img_path =os.path.join(self.img_dir,self.image_ids[idx])\r\n    File &quot;/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/series.py&quot;, line 882, in __getitem__\r\n    return self._get_value(key)\r\n    File &quot;/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/series.py&quot;, line 990, in _get_value\r\n    loc = self.index.get_loc(label)\r\n    File &quot;/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/indexes/base.py&quot;, line 2900, in get_loc\r\n    raise KeyError(key) from err\r\n    KeyError: 16481\r\n\r\n### Code\r\n```python\r\nfrom torchvision.io import read_image\r\nimport torch\r\nfrom torchvision import transforms\r\nfrom sklearn.model_selection import train_test_split\r\nfrom torch.utils.data import Dataset\r\n\r\nclass CustomImageDataset(Dataset):\r\n    def __init__(self, dataset, transforms=None, target_transforms=None):\r\n        #self.train_data = pd.read_csv(&quot;Data/train_data.csv&quot;)\r\n        self.image_ids = dataset.image_id\r\n        self.image_labels = dataset.label\r\n        self.img_dir = &#39;Data/images&#39;\r\n        self.transforms = transforms\r\n        self.target_transforms = target_transforms\r\n\r\n    def __len__(self):\r\n        return len(self.image_ids)\r\n\r\n    def __getitem__(self,idx):\r\n        # image path\r\n        img_path =os.path.join(self.img_dir,self.image_ids[idx])\r\n        # image\r\n        image = read_image(img_path)\r\n        label = self.image_labels[idx]\r\n        # transform image\r\n        if self.transforms:\r\n             image = self.transforms(image)\r\n        # transform target\r\n        if self.target_transforms:\r\n             label = self.target_transforms(label)\r\n\r\n    return image, label\r\n```\r\n\r\n`train_data` is the pandas object of the csv file which has the image id and label information.\r\n\r\n```python\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nX_train, X_test = train_test_split(train_data, test_size=0.1, random_state=42)\r\ntrain_df = CustomImageDataset(X_train)\r\ntrain_dataloader = torch.utils.data.DataLoader(\r\n    train_df,\r\n    batch_size=64,\r\n    num_workers=1,\r\n    shuffle=True)",
        "accepted_answer_markdown": "found the issue with the code.\r\n\r\nPytorch Custom Dataloader function &quot;__getitem__&quot; uses idx to retrieve data and my guess is, it know the range of idx from __len__ function, ex: 0, till len(rows in dataset). \r\n\r\nIn my case, I already had a panda dataset (train_data) with idx as one of the column. When I randomly split it into X_train and X_test, few of the data rows were moved to X_test along with the idx.\r\n\r\nNow, when I send X_train to the custom dataloader, it is trying to get row&#39;s image_id with an idx and that idx just happens to be in X_test dataset. This lead to error as keyerror: 16481 i.e row with idx=16481 is not present in the X_train dataset. It was moved to X_test during split.\r\n\r\nphew...\r\n\r\n\r\n"
    },
    {
        "question_id": "69683898",
        "accepted_answer_id": "69685084",
        "question_title": "PyTorch: Checking Model Accuracy Results in &quot;TypeError: &#39;bool&#39; object is not iterable.&quot;",
        "question_markdown": "I am training a neural network and would like to check its accuracy. I&#39;ve used Librosa and SciKitLearn to represent audio in the form of 1D Numpy arrays. Thus `x_train, x_test, y_train, `and `y_test` are all 1D Numpy arrays with the x_* arrays containing floats and the y_* arrays containing strings corresponding to classes of data. For example: \r\n\r\n    x_train = [0.235, 1.101, 3.497]\r\n    y_train = [&#39;happy&#39;, &#39;angry&#39;, &#39;neutral&#39;] \r\n\r\nI&#39;ve written a dictionary to represent these classes (strings) as integers: \r\n\r\n    emotions = {\r\n    &#39;01&#39; : &#39;neutral&#39;,\r\n    &#39;02&#39; : &#39;calm&#39;,\r\n    &#39;03&#39; : &#39;happy&#39;,\r\n    &#39;04&#39; : &#39;sad&#39;,\r\n    &#39;05&#39; : &#39;angry&#39;,\r\n    &#39;06&#39; : &#39;fearful&#39;,\r\n    &#39;07&#39; : &#39;disgust&#39;,\r\n    &#39;08&#39; : &#39;surprised&#39;}\r\n\r\n    emotion_list = list(emotions.values())\r\n\r\n\r\nNext I&#39;ve defined a class to transform this data such that it can be passed to torch.utils.data.DataLoader(): \r\n\r\n    class MakeDataset(Dataset):\r\n        def __init__(self, x_train, y_train):\r\n            self.x_train = torch.FloatTensor(x_train)\r\n            self.y_train = torch.FloatTensor([emotion_list.index(each) for each in y_train])\r\n        def __len__(self):\r\n            return self.x_train.shape[0]\r\n        def __getitem__(self, ind):\r\n            x = self.x_train[ind]\r\n            y = emotion_list.index(y_train[ind])\r\n            return x, y\r\n\r\nI define a training set, testing set, batch size, and load the data: \r\n\r\n    train_set = MakeDataset(x_train, y_train)\r\n    test_set = MakeDataset(x_test, y_test)\r\n    \r\n    batch_size = 512\r\n    \r\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\r\n    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\r\n\r\nI define the model, train, and test as follows: \r\n\r\n  \r\n\r\n    class TwoLayerMLP(torch.nn.Module):\r\n        def __init__(self, D_in, H, D_out):\r\n            super(TwoLayerMLP, self).__init__()\r\n            self.linear1 = torch.nn.Linear(D_in, H)\r\n            self.linear2 = torch.nn.Linear(H, D_out)\r\n    \r\n        def forward(self, x):\r\n            h_relu = self.linear1(x).clamp(min=0)\r\n            y_pred = self.linear2(h_relu)\r\n            return y_pred\r\n    \r\n    \r\n    model = TwoLayerMLP(180, 90, 8)\r\n    optimizer = torch.optim.Adam(model.parameters())\r\n    criterion = nn.CrossEntropyLoss()\r\n    \r\n    epochs = 5000\r\n    \r\n    total_train = 0\r\n    correct_train = 0\r\n    for epoch in range(epochs):\r\n        model.train()\r\n        running_loss = 0.0\r\n        for batch_num, data in enumerate(train_loader):\r\n            audio , label = data\r\n            optimizer.zero_grad()\r\n            outputs = model(audio.float())\r\n            loss = criterion(outputs, label)\r\n            loss.backward()\r\n            optimizer.step()\r\n            \r\n            predicted = torch.max(outputs.data,1)\r\n            total_train += float(label.size(0))\r\n            \r\n            # Code runs with line below commented \r\n            # Else returns &quot;TypeError: &#39;bool&#39; object not iterable.&quot;\r\n            correct_train += sum(predicted == label)\r\n\r\n\r\nNote that this code has been updated, formerly the problematic line was: \r\n\r\n    correct_train += float((predicted == label)).sum()\r\n\r\nCan anyone explain why this boolean object cannot be iterated as expected? \r\n\r\n## SOLVED ##\r\nPlease see the comments in abhiskk&#39;s answer below, but for clarity and brevity the following changes solved the problem: \r\n\r\n    pred_values, pred_indices = torch.max(outputs.data,1)\r\n    total_train += float(label.size(0))\r\n    correct_train += (sum(pred_indices == label)).item()",
        "accepted_answer_markdown": "The predicted variable contains both values and indices, you need to do `pred_vals, pred_inds = torch.max(outputs.data, 1)` and then you can do `correct_train += (sum(pred_inds == label)).item()`\r\n\r\nAlso you don&#39;t need to convert to float before summing, you can use:\r\n\r\n`(predicted == label).sum().item()`\r\n\r\n`(predicted == label)` returns a `BoolTensor` which can be summed to obtain a float value."
    },
    {
        "question_id": "45693586",
        "accepted_answer_id": "45695712",
        "question_title": "PyTorch: How to get around the RuntimeError: in-place operations can be only used on variables that don&#39;t share storage with any other variables",
        "question_markdown": "With PyTorch I&#39;m having a problem doing an operation with two Variables:\r\n\r\n    sub_patch  : [torch.FloatTensor of size 9x9x32]\r\n\r\n    pred_patch : [torch.FloatTensor of size 5x5x32]\r\n\r\nsub_patch is a Variable made by torch.zeros\r\npred_patch is a Variable of which I index each of the 25 nodes with a nested for-loop, and that I multiply with its corresponding unique filter (sub_filt_patch) of size [5,5,32]. The result is added to its respective place in sub_patch.\r\n\r\nThis is a piece of my code:\r\n\r\n    for i in range(filter_sz):\r\n        for j in range(filter_sz):\r\n\r\n            # index correct filter from filter tensor\r\n            sub_filt_col = (patch_col + j) * filter_sz\r\n            sub_filt_row = (patch_row + i) * filter_sz\r\n\r\n            sub_filt_patch = sub_filt[sub_filt_row:(sub_filt_row + filter_sz), sub_filt_col:(sub_filt_col+filter_sz), :]\r\n\r\n            # multiply filter and pred_patch and sum onto sub patch\r\n            sub_patch[i:(i + filter_sz), j:(j + filter_sz), :] += (sub_filt_patch * pred_patch[i,j]).sum(dim=3)\r\n\r\nThe error I get from the bottom line of the piece of code here is\r\n\r\n    RuntimeError: in-place operations can be only used on variables that don&#39;t share storage with any other variables, but detected that there are 2 objects sharing it\r\n\r\nI get why it happens, since sub_patch is a Variable, and pred_patch is a Variable too, but how can I get around this error? Any help would be greatly appreciated!\r\n\r\nThank you!\r\n\r\n\r\n",
        "accepted_answer_markdown": "I&#39;ve found the problem to be in \r\n\r\n            sub_patch[i:(i + filter_sz), j:(j + filter_sz), :] += (sub_filt_patch * pred_patch[i,j]).sum(dim=3)\r\n\r\nWhen separating this line into this:\r\n\r\n    sub_patch[i:(i + filter_sz), j:(j + filter_sz), :] = sub_patch[i:(i + filter_sz), j:(j + filter_sz), :] + (sub_filt_patch * pred_patch[i,j]).sum(dim=3)\r\n    \r\n\r\nThen it worked!\r\n\r\nThe difference between a += b and a = a + b is that in the first case, b is added in a inplace (so the content of a is changed to now contain a+b). In the second case, a brand new tensor is created that contains a+b and then you assign this new tensor to the name a.\r\nTo be able to compute gradients, you sometimes need to keep the original value of a, and so we prevent inplace operation from being done because otherwise, we won&#39;t be able to compute gradients."
    },
    {
        "question_id": "46546217",
        "accepted_answer_id": "46575124",
        "question_title": "expected Double tensor (got Float tensor) in Pytorch",
        "question_markdown": "I want to create `nn.Module` in [Pytorch][1]. I used following code for text related problem (In fact I use `Glove` 300d pre-trained embedding and weighted average of words in a sentence to do classification).\r\n\r\n    class Net(nn.Module):\r\n        def __init__(self):\r\n            super(Net, self).__init__()\r\n            self.conv1 = nn.Conv1d(300, 128, kernel_size=5)\r\n            self.conv2 = nn.Conv1d(128, 64, kernel_size=2)\r\n            self.conv2_drop = nn.Dropout()\r\n            self.fc1 = nn.Linear(64, 20)\r\n            self.fc2 = nn.Linear(20, 2)\r\n    \r\n        def forward(self, x):\r\n            x = F.relu(F.avg_pool1d(self.conv1(x), 2))\r\n            x = F.relu(F.avg_pool1d(self.conv2_drop(self.conv2(x)), 2))\r\n            x = x.view(-1, 1)\r\n            x = F.relu(self.fc1(x))\r\n            x = F.dropout(x, training=self.training)\r\n            return self.fc2(x)\r\n\r\n But it gives me following error:\r\n\r\n    Traceback (most recent call last):\r\n        x = F.relu(F.avg_pool1d(self.conv1(x), 2))\r\n      File &quot;/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/modules/module.py&quot;, line 224, in __call__\r\n        result = self.forward(*input, **kwargs)\r\n      File &quot;/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/modules/conv.py&quot;, line 154, in forward\r\n        self.padding, self.dilation, self.groups)\r\n      File &quot;/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/functional.py&quot;, line 83, in conv1d\r\n        return f(input, weight, bias)\r\n    RuntimeError: expected Double tensor (got Float tensor)\r\n\r\nI fairly new to `Conv1d`, and most of tutorial used `Conv1d` for image problems. Can anybody give me some idea what&#39;s the problem?\r\n\r\nI also added `model.double()` inside forward method but gives me another error:\r\n\r\n    RuntimeError: Given input size: (300 x 1 x 1). Calculated output size: (128 x 1 x -3). Output size is too small\r\n\r\n  [1]: http://pytorch.org\r\n",
        "accepted_answer_markdown": "&lt;!-- language-all: python --&gt;\r\n\r\n&lt;h1&gt;Error 1&lt;/h1&gt;\r\n\r\n&gt; RuntimeError: expected Double tensor (got Float tensor)\r\n\r\nThis happens when you pass a double tensor to the first `conv1d` function. `Conv1d` only works with float tensor. \r\nEither do,\r\n\r\n 1. `conv1.double()` , or\r\n 2. `model.double()`.\r\n\r\nWhich is what you have done, and that is correct.\r\n\r\n&lt;h1&gt;Error 2&lt;/h1&gt;\r\n\r\n &gt; RuntimeError: Given input size: (300 x 1 x 1). Calculated output size: (128 x 1 x -3). Output size is too small\r\n\r\nThis is because you are passing an input to which a convolution with a window size of 5 is not valid. You will have to add padding to your `Conv1d`s for this to work, like so:\r\n\r\n    self.conv1 = nn.Conv1d(300, 128, kernel_size=5, padding=2)\r\n\r\nIf you dont wish to add padding, then given (batch_size, in_channels, inp_size) as the size of the input tensor, you have to make sure that your inp_size is greater than 5.\r\n\r\n&lt;h1&gt; All fixes combined &lt;/h1&gt;\r\n\r\nMake sure that your sizes are correct for the rest of your network. Like so:\r\n\r\n    class Net(nn.Module):\r\n        def __init__(self):\r\n            super(Net, self).__init__()\r\n            self.conv1 = nn.Conv1d(300, 128, kernel_size=5, padding=2)\r\n            self.conv2 = nn.Conv1d(128, 64, kernel_size=2, padding=1)\r\n            self.conv2_drop = nn.Dropout()\r\n            self.fc1 = nn.Linear(64, 20)\r\n            self.fc2 = nn.Linear(20, 2)\r\n\r\n        def forward(self, x):\r\n            x = F.relu(F.avg_pool1d(self.conv1(x), 2, padding=1))\r\n            x = F.relu(F.avg_pool1d(self.conv2_drop(self.conv2(x)), 2))\r\n            x = x.view(1, -1) # bonus fix, Linear needs (batch_size, in_features) and not (in_features, batch_size) as input.\r\n            x = F.relu(self.fc1(x))\r\n            x = F.dropout(x, training=self.training)\r\n            return self.fc2(x)\r\n\r\n    if __name__ == &#39;__main__&#39;:\r\n\r\n        t = Variable(torch.randn((1, 300, 1))).double() # t is a double tensor\r\n        model = Net()\r\n        model.double() # this will make sure that conv1d will process double tensor\r\n        out = model(t)\r\n\r\n\r\n    \r\n\r\n\r\n"
    },
    {
        "question_id": "46704352",
        "accepted_answer_id": "50496721",
        "question_title": "Porting PyTorch code from CPU to GPU",
        "question_markdown": "Following the tutorial from https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb\r\n\r\nThere is a `USE_CUDA` flag that is used to control the variable and tensor types between CPU (when False) to GPU (when True) types.\r\n\r\nUsing the data from [en-fr.tsv][1] and converting the sentences to variables:\r\n\r\n    import unicodedata\r\n    import string\r\n    import re\r\n    import random\r\n    import time\r\n    import math\r\n    \r\n    from gensim.corpora.dictionary import Dictionary\r\n    \r\n    import torch\r\n    import torch.nn as nn\r\n    from torch.autograd import Variable\r\n    from torch import LongTensor, FloatTensor\r\n    from torch import optim\r\n    import torch.nn.functional as F\r\n    \r\n    import numpy as np\r\n    \r\n    MAX_LENGTH = 10\r\n    USE_CUDA = False\r\n    \r\n    # Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\r\n    def unicode_to_ascii(s):\r\n        return &#39;&#39;.join(\r\n            c for c in unicodedata.normalize(&#39;NFD&#39;, s)\r\n            if unicodedata.category(c) != &#39;Mn&#39;\r\n        )\r\n    \r\n    # Lowercase, trim, and remove non-letter characters\r\n    def normalize_string(s):\r\n        s = unicode_to_ascii(s.lower().strip())\r\n        s = re.sub(r&quot;([.!?])&quot;, r&quot; \\1&quot;, s)\r\n        s = re.sub(r&quot;[^a-zA-Z.!?]+&quot;, r&quot; &quot;, s)\r\n        return s\r\n    \r\n    SOS_IDX, SOS_TOKEN = 0, &#39;&lt;s&gt;&#39;\r\n    EOS_IDX, EOS_TOKEN = 1, &#39;&lt;/s&gt;&#39;\r\n    UNK_IDX, UNK_TOKEN = 2, &#39;&lt;unk&gt;&#39;\r\n    PAD_IDX, PAD_TOKEN = 3, &#39;&lt;blank&gt;&#39;\r\n    \r\n    lines = open(&#39;en-fr.tsv&#39;).read().strip().split(&#39;\\n&#39;)\r\n    pairs = [[normalize_string(s).split() for s in l.split(&#39;\\t&#39;)] for l in lines]\r\n    src_sents, trg_sents = zip(*pairs)\r\n    \r\n    src_dict = Dictionary([[SOS_TOKEN, EOS_TOKEN, UNK_TOKEN, PAD_TOKEN]])\r\n    src_dict.add_documents(src_sents)\r\n    \r\n    trg_dict = Dictionary([[SOS_TOKEN, EOS_TOKEN, UNK_TOKEN, PAD_TOKEN]])\r\n    trg_dict.add_documents(trg_sents)\r\n    \r\n    def variablize_sentences(sentence, dictionary):\r\n        indices = [dictionary.token2id[tok] for tok in sentence] + [dictionary.token2id[EOS_TOKEN]]\r\n        var = Variable(LongTensor(indices).view(-1, 1))\r\n        return var.cuda() if USE_CUDA else var\r\n    \r\n    input_variables = [variablize_sentences(sent, src_dict) for sent in src_sents]\r\n    output_variables = [variablize_sentences(sent, trg_dict) for sent in trg_sents]\r\n\r\nAnd using a Encoder-Attn-Decoder network:\r\n\r\n    class EncoderRNN(nn.Module):\r\n        def __init__(self, input_size, hidden_size, n_layers=1):\r\n            super(EncoderRNN, self).__init__()\r\n    \r\n            self.input_size = input_size\r\n            self.hidden_size = hidden_size\r\n            self.n_layers = n_layers\r\n            \r\n            self.embedding = nn.Embedding(input_size, hidden_size)    \r\n            self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\r\n            \r\n            self.embedding = self.embedding.cuda() if USE_CUDA else self.embedding\r\n            self.gru = self.gru.cuda() if USE_CUDA else self.gru\r\n            \r\n        def forward(self, word_inputs, hidden):\r\n            seq_len = len(word_inputs)\r\n            \r\n            embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\r\n            embedded = embedded.cuda() if USE_CUDA else embedded\r\n            \r\n            output, hidden = self.gru(embedded, hidden)\r\n            output = output.cuda() if USE_CUDA else output\r\n            hiddne = hidden.cuda() if USE_CUDA else hidden\r\n            \r\n            return output, hidden\r\n    \r\n        def init_hidden(self):\r\n            hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\r\n            return hidden.cuda() if USE_CUDA else hidden\r\n\r\n    class Attn(nn.Module):\r\n        def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\r\n            super(Attn, self).__init__()\r\n            \r\n            self.method = method\r\n            self.hidden_size = hidden_size\r\n            \r\n            if self.method == &#39;general&#39;:\r\n                self.attn = nn.Linear(self.hidden_size, hidden_size)\r\n    \r\n            elif self.method == &#39;concat&#39;:\r\n                self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\r\n                self.other = nn.Parameter(FloatTensor(1, hidden_size))\r\n    \r\n        def forward(self, hidden, encoder_outputs):\r\n            seq_len = len(encoder_outputs)\r\n    \r\n            # Create variable to store attention energies\r\n            attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\r\n            attn_energies = attn_energies.cuda() if USE_CUDA else attn_energies\r\n            # Calculate energies for each encoder output\r\n            for i in range(seq_len):\r\n                attn_energies[i] = self.score(hidden, encoder_outputs[i])\r\n    \r\n            # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\r\n            return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\r\n        \r\n        def score(self, hidden, encoder_output):\r\n            if self.method == &#39;dot&#39;:\r\n                energy =torch.dot(hidden.view(-1), encoder_output.view(-1))\r\n            elif self.method == &#39;general&#39;:\r\n                energy = self.attn(encoder_output)\r\n                energy = torch.dot(hidden.view(-1), energy.view(-1))\r\n            elif self.method == &#39;concat&#39;:\r\n                energy = self.attn(torch.cat((hidden, encoder_output), 1))\r\n                energy = torch.dot(self.v.view(-1), energy.view(-1))\r\n            return energy\r\n\r\n    class AttnDecoderRNN(nn.Module):\r\n        def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\r\n            super(AttnDecoderRNN, self).__init__()\r\n            \r\n            # Keep parameters for reference\r\n            self.attn_model = attn_model\r\n            self.hidden_size = hidden_size\r\n            self.output_size = output_size\r\n            self.n_layers = n_layers\r\n            self.dropout_p = dropout_p\r\n            \r\n            # Define layers\r\n            self.embedding = nn.Embedding(output_size, hidden_size)\r\n            self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\r\n            self.out = nn.Linear(hidden_size * 2, output_size)\r\n            \r\n            self.embedding = self.embedding.cuda() if USE_CUDA else self.embedding\r\n            self.gru = self.gru.cuda() if USE_CUDA else self.gru\r\n            self.out = self.out.cuda() if USE_CUDA else self.out\r\n            \r\n            \r\n            # Choose attention model\r\n            if attn_model != &#39;none&#39;:\r\n                self.attn = Attn(attn_model, hidden_size)\r\n                self.attn = self.attn.cuda() if USE_CUDA else self.attn\r\n        \r\n        def forward(self, word_input, last_context, last_hidden, encoder_outputs):\r\n            # Note: we run this one step at a time\r\n            \r\n            # Get the embedding of the current input word (last output word)\r\n            word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\r\n            \r\n            # Combine embedded input word and last context, run through RNN\r\n            rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\r\n            rnn_output, hidden = self.gru(rnn_input, last_hidden)\r\n    \r\n            # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\r\n            attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\r\n            context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\r\n            \r\n            # Final output layer (next word prediction) using the RNN hidden state and context vector\r\n            rnn_output = rnn_output.squeeze(0) # S=1 x B x N -&gt; B x N\r\n            context = context.squeeze(1)       # B x S=1 x N -&gt; B x N\r\n            output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\r\n            \r\n            if USE_CUDA:\r\n                return output.cuda(), context.cuda(), hidden.cuda(), attn_weights.cuda()\r\n            else:\r\n                return output, context, hidden, attn_weights\r\n\r\n\r\nAnd testing the network:\r\n\r\n    encoder_test = EncoderRNN(10, 10, 2) # I, H , L\r\n    decoder_test = AttnDecoderRNN(&#39;general&#39;, 10, 10, 2) # A, H, O, L\r\n    \r\n    encoder_hidden = encoder_test.init_hidden()\r\n    if USE_CUDA:\r\n        word_inputs = Variable(torch.LongTensor([1, 2, 3]).cuda())\r\n    else:\r\n        word_inputs = Variable(torch.LongTensor([1, 2, 3]))\r\n    encoder_outputs, encoder_hidden = encoder_test(word_inputs, encoder_hidden)\r\n    decoder_attns = torch.zeros(1, 3, 3)\r\n    decoder_hidden = encoder_hidden\r\n    decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\r\n    \r\n    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[0], decoder_context, decoder_hidden, encoder_outputs)\r\n    print(decoder_output)\r\n    print(decoder_hidden)\r\n    print(decoder_attn)\r\n\r\nThe code works fine on CPU, \r\n\r\n[out]:\r\n\r\n    EncoderRNN (\r\n      (embedding): Embedding(10, 10)\r\n      (gru): GRU(10, 10, num_layers=2)\r\n    )\r\n    AttnDecoderRNN (\r\n      (embedding): Embedding(10, 10)\r\n      (gru): GRU(20, 10, num_layers=2, dropout=0.1)\r\n      (out): Linear (20 -&gt; 10)\r\n      (attn): Attn (\r\n        (attn): Linear (10 -&gt; 10)\r\n      )\r\n    )\r\n    Variable containing:\r\n    -2.4378 -2.3556 -2.3391 -2.5070 -2.3439 -2.3415 -2.3976 -2.1832 -1.9976 -2.2213\r\n    [torch.FloatTensor of size 1x10]\r\n    \r\n    Variable containing:\r\n    (0 ,.,.) = \r\n    \r\n    Columns 0 to 8 \r\n      -0.2325  0.0775  0.5415  0.4876 -0.5771 -0.0687  0.1832 -0.5285  0.2508\r\n    \r\n    Columns 9 to 9 \r\n      -0.1837\r\n    \r\n    (1 ,.,.) = \r\n    \r\n    Columns 0 to 8 \r\n      -0.1389 -0.2605 -0.0518  0.3405  0.0774  0.1815  0.0297 -0.1304 -0.1015\r\n    \r\n    Columns 9 to 9 \r\n       0.2602\r\n    [torch.FloatTensor of size 2x1x10]\r\n    \r\n    Variable containing:\r\n    (0 ,.,.) = \r\n      0.3334  0.3291  0.3374\r\n    [torch.FloatTensor of size 1x1x3]\r\n\r\nbut when changing the flag to `USE_GPU=True`, it throws the error when initializing the `decoder_test` object, it throws a `TypeError`:\r\n\r\n    ---------------------------------------------------------------------------\r\n    TypeError                                 Traceback (most recent call last)\r\n    &lt;ipython-input-76-b3c660013934&gt; in &lt;module&gt;()\r\n         12 decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\r\n         13 \r\n    ---&gt; 14 decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[0], decoder_context, decoder_hidden, encoder_outputs)\r\n         15 print(decoder_output)\r\n         16 print(decoder_hidden)\r\n    \r\n    ~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n        222         for hook in self._forward_pre_hooks.values():\r\n        223             hook(self, input)\r\n    --&gt; 224         result = self.forward(*input, **kwargs)\r\n        225         for hook in self._forward_hooks.values():\r\n        226             hook_result = hook(self, input, result)\r\n    \r\n    &lt;ipython-input-75-34ecfe9b3112&gt; in forward(self, word_input, last_context, last_hidden, encoder_outputs)\r\n         32 \r\n         33         # Combine embedded input word and last context, run through RNN\r\n    ---&gt; 34         rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\r\n         35         rnn_output, hidden = self.gru(rnn_input, last_hidden)\r\n         36 \r\n    \r\n    ~/.local/lib/python3.5/site-packages/torch/autograd/variable.py in cat(iterable, dim)\r\n        895         @staticmethod\r\n        896         def cat(iterable, dim=0):\r\n    --&gt; 897             return Concat.apply(dim, *iterable)\r\n        898 \r\n        899         @staticmethod\r\n    \r\n    ~/.local/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py in forward(ctx, dim, *inputs)\r\n        315         ctx.dim = dim\r\n        316         ctx.input_sizes = [i.size(dim) for i in inputs]\r\n    --&gt; 317         return torch.cat(inputs, dim)\r\n        318 \r\n        319     @staticmethod\r\n    \r\n    TypeError: cat received an invalid combination of arguments - got (tuple, int), but expected one of:\r\n     * (sequence[torch.cuda.FloatTensor] seq)\r\n     * (sequence[torch.cuda.FloatTensor] seq, int dim)\r\n          didn&#39;t match because some of the arguments have invalid types: (tuple, int)\r\n\r\nThe question is **why are that types not matching in CUDA but it works on CPU and how to resolve this?**\r\n\r\n**Does PyTorch have a global flag to just change all types to CUDA types and not mess around with CPU/GPU types?**\r\n\r\n  [1]: https://gist.githubusercontent.com/alvations/c82884f5137c63ded867da55915da31d/raw/08dbfb2b537c923deeed38afd8bd58f2a61d4a6b/en-fr.tsv\r\n\r\n",
        "accepted_answer_markdown": "You can also try:\r\n\r\n    net = YouNetworkClass()\r\n    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\r\n    net.to(device)\r\n\r\nAfter that, you have to send the `word_inputs`, `encoder_hidden` and `decoder_context` to the GPU too:\r\n\r\n    word_inputs, encoder_hidden, decoder_context = word_inputs.to(device), encoder_hidden.to(device), decoder_context.to(device)\r\n\r\nLook here: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu"
    },
    {
        "question_id": "47065172",
        "accepted_answer_id": "47100245",
        "question_title": "Cross entropy loss in pytorch nn.CrossEntropyLoss()",
        "question_markdown": "maybe someone is able to help me here. I am trying to compute the cross entropy loss of a given output of my network\r\n    \r\n    print output\r\n    Variable containing:\r\n    1.00000e-02 *\r\n    -2.2739  2.9964 -7.8353  7.4667  4.6921  0.1391  0.6118  5.2227  6.2540     \r\n    -7.3584\r\n    [torch.FloatTensor of size 1x10]\r\n\r\nand the desired label, which is of the form\r\n\r\n    print lab\r\n    Variable containing:\r\n    x\r\n    [torch.FloatTensor of size 1]\r\nwhere x is an integer between 0 and 9.\r\nAccording to the pytorch documentation (http://pytorch.org/docs/master/nn.html)\r\n\r\n    criterion = nn.CrossEntropyLoss()\r\n    loss = criterion(output, lab)\r\n\r\nthis should work, but unfortunately I get a weird error \r\n    \r\n    TypeError: FloatClassNLLCriterion_updateOutput received an invalid combination of arguments - got (int, torch.FloatTensor, !torch.FloatTensor!, torch.FloatTensor, bool, NoneType, torch.FloatTensor, int), but expected (int state, torch.FloatTensor input, torch.LongTensor target, torch.FloatTensor output, bool sizeAverage, [torch.FloatTensor weights or None], torch.FloatTensor total_weight, int ignore_index)\r\n\r\nCan anyone help me? I am really confused and tried almost everything I could imagined to be helpful.\r\n\r\nBest",
        "accepted_answer_markdown": "Please check this code\r\n\r\n&lt;!-- language-all: lang-py --&gt;\r\n  \r\n    import torch\r\n    import torch.nn as nn\r\n    from torch.autograd import Variable\r\n\r\n    output = Variable(torch.rand(1,10))\r\n    target = Variable(torch.LongTensor([1]))\r\n\r\n    criterion = nn.CrossEntropyLoss()\r\n    loss = criterion(output, target)\r\n    print(loss)\r\n\r\nThis will print out the loss nicely:\r\n\r\n    Variable containing:\r\n     2.4498\r\n    [torch.FloatTensor of size 1]\r\n"
    },
    {
        "question_id": "47120126",
        "accepted_answer_id": "47159699",
        "question_title": "how to calculate loss over a number of images and then back propagate the average loss and update network weight",
        "question_markdown": "I am doing a task where the batch size is 1, i.e, each batch contains only 1 image. So I have to do manual batching: when the the number of accumulated losses reach a number, average the loss and then do back propagation.\r\nMy original code is:\r\n\r\n&lt;!-- language: lang-py --&gt;\r\n\r\n    real_batchsize = 200\r\n    \r\n    for epoch in range(1, 5):\r\n        net.train()\r\n    \r\n        total_loss = Variable(torch.zeros(1).cuda(), requires_grad=True)\r\n    \r\n        iter_count = 0\r\n        for batch_idx, (input, target) in enumerate(train_loader):\r\n    \r\n            input, target = Variable(input.cuda()), Variable(target.cuda())\r\n            output = net(input)\r\n    \r\n            loss = F.nll_loss(output, target)\r\n    \r\n            total_loss = total_loss + loss\r\n    \r\n            if batch_idx % real_batchsize == 0:\r\n                iter_count += 1\r\n    \r\n                ave_loss = total_loss/real_batchsize\r\n                ave_loss.backward()\r\n                optimizer.step()\r\n    \r\n                if iter_count % 10 == 0:\r\n                    print(&quot;Epoch:{}, iteration:{}, loss:{}&quot;.format(epoch,\r\n                                                               iter_count,\r\n                                                               ave_loss.data[0]))\r\n                total_loss.data.zero_() \r\n                optimizer.zero_grad()\r\n\r\nThis code will give the error message \r\n&gt;RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.\r\n\r\nI have tried the following way,\r\n### First way (failed)\r\nI read some post about this error message, but can not understand it fully. Change `ave_loss.backward()` to `ave_loss.backward(retain_graph=True)` prevent the error message, but the loss doesn&#39;t improve the soon becomes `nan`. \r\n\r\n### Second way (failed)\r\nI also tried to change `total_loss = total_loss + loss.data[0]`, this will also prevent the error message. But the loss are always the same. So there must be something wrong.\r\n\r\n### Third way (success)\r\nFollowing the instruction in [this post](https://discuss.pytorch.org/t/pytorch-gradients/884/2), for each image&#39;s loss,I divide the loss by `real_batchsize` and backprop it. When the number of input image reach the `real_batchsize`, I do one update of parameter using `optimizer.step()`.  The loss is slowly decreasing as the training process goes. But the training speed is really slow, because we backprop for each image.\r\n\r\n### My question\r\nWhat does the error message mean in my case? Also, why doesn&#39;t first way and second way work?  How to write the code correctly so that we can backprop gradient every `real_batchsize` images and update gradient once so that the training speed a faster?  I know my code is nearly correct, but I just do not know how to change it.",
        "accepted_answer_markdown": "&lt;!-- language-all: Python --&gt;\r\nThe problem you encounter here is related to how PyTorch accumulates gradients over different passes. (see [here][1] for another post on a similar question)\r\nSo let&#39;s have a look at what happens when you have code of the following form:\r\n\r\n    loss_total = Variable(torch.zeros(1).cuda(), requires_grad=True)\r\n    for l in (loss_func(x1,y1), loss_func(x2, y2), loss_func(x3, y3), loss_func(x4, y4)):\r\n        loss_total = loss_total + l\r\n        loss_total.backward()\r\n\r\nHere, we do a backward pass when `loss_total` has the following values over the different iterations:\r\n\r\n    total_loss = loss(x1, y1)\r\n    total_loss = loss(x1, y1) + loss(x2, y2)\r\n    total_loss = loss(x1, y1) + loss(x2, y2) + loss(x3, y3)\r\n    total_loss = loss(x1, y1) + loss(x2, y2) + loss(x3, y3) + loss(x4, y4)\r\n\r\nso when you call `.backward()` on `total_loss` each time, you actually call `.backward()` on `loss(x1, y1)` *four times!* (and on `loss(x2, y2)` three times, etc).\r\n\r\nCombine that with what is discussed in the other post, namely that to optimize memory usage, PyTorch will free the graph attached to a Variable when calling `.backward()` (and thereby destroying the gradients connecting `x1` to `y1`, `x2` to `y2`, etc), you can see what the error message means - you try to do backward passes over a loss for several times, but the underlying graph was freed up after the first pass. (unless to specify `retain_graph=True`, of course)\r\n\r\nAs for the specific variations you have tried:\r\nFirst way: here, you will accumulate (i.e. sum up - again, see the other post) gradients forever, with them (potentially) adding up to `inf`.\r\nSecond way: here, you convert `loss` to a tensor by doing `loss.data`, removing the `Variable` wrapper, and thereby deleting the gradient information (since only Variables hold gradients).\r\nThird way: here, you only do one pass through each `xk, yk` tuple, since you immediately do a backprop step, avoiding the above problem alltogether. \r\n\r\nSOLUTION: I have not tested it, but from what I gather, the solution should be pretty straightforward: create a new `total_loss` object at the beginning of each batch, then sum all of the losses into that object, and then do *one* final backprop step at the end. \r\n\r\n\r\n  [1]: https://stackoverflow.com/questions/46774641/neural-transfer-with-pytorch-retain-graph-on-backward-pass/46854276#46854276"
    },
    {
        "question_id": "47312396",
        "accepted_answer_id": "47341747",
        "question_title": "Pytorch AssertionError: Torch not compiled with CUDA enabled",
        "question_markdown": "I am trying to run code from [this repo](https://github.com/eladhoffer/captionGen). I have disabled cuda by changing lines 39/40 in main.py from\r\n\r\n    parser.add_argument(&#39;--type&#39;, default=&#39;torch.cuda.FloatTensor&#39;, help=&#39;type of tensor - e.g torch.cuda.HalfTensor&#39;)\r\n\r\nto \r\n\r\n    parser.add_argument(&#39;--type&#39;, default=&#39;torch.FloatTensor&#39;, help=&#39;type of tensor - e.g torch.HalfTensor&#39;)\r\n\r\nDespite this, running the code gives me the following exception:\r\n\r\n    Traceback (most recent call last):\r\n      File &quot;main.py&quot;, line 190, in &lt;module&gt;\r\n        main()\r\n      File &quot;main.py&quot;, line 178, in main\r\n        model, train_data, training=True, optimizer=optimizer)\r\n      File &quot;main.py&quot;, line 135, in forward\r\n        for i, (imgs, (captions, lengths)) in enumerate(data):\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py&quot;, line 201, in __next__\r\n        return self._process_next_batch(batch)\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py&quot;, line 221, in _process_next_batch\r\n        raise batch.exc_type(batch.exc_msg)\r\n    AssertionError: Traceback (most recent call last):\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py&quot;, line 62, in _pin_memory_loop\r\n        batch = pin_memory_batch(batch)\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py&quot;, line 123, in pin_memory_batch\r\n        return [pin_memory_batch(sample) for sample in batch]\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py&quot;, line 123, in &lt;listcomp&gt;\r\n        return [pin_memory_batch(sample) for sample in batch]\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py&quot;, line 117, in pin_memory_batch\r\n        return batch.pin_memory()\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/tensor.py&quot;, line 82, in pin_memory\r\n        return type(self)().set_(storage.pin_memory()).view_as(self)\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/storage.py&quot;, line 83, in pin_memory\r\n        allocator = torch.cuda._host_allocator()\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/cuda/__init__.py&quot;, line 220, in _host_allocator\r\n        _lazy_init()\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/cuda/__init__.py&quot;, line 84, in _lazy_init\r\n        _check_driver()\r\n      File &quot;/Users/lakshay/anaconda/lib/python3.6/site-packages/torch/cuda/__init__.py&quot;, line 51, in _check_driver\r\n        raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)\r\n    AssertionError: Torch not compiled with CUDA enabled\r\n\r\nSpent some time looking through the issues in the Pytorch github, to no avail. Help, please?",
        "accepted_answer_markdown": "If you look into the [data.py][1] file, you can see the function:\r\n\r\n    def get_iterator(data, batch_size=32, max_length=30, shuffle=True, num_workers=4, pin_memory=True):\r\n        cap, vocab = data\r\n        return torch.utils.data.DataLoader(\r\n            cap,\r\n            batch_size=batch_size, shuffle=shuffle,\r\n            collate_fn=create_batches(vocab, max_length),\r\n            num_workers=num_workers, pin_memory=pin_memory)\r\n\r\nwhich is called twice in [main.py][2] file to get an iterator for the train and dev data. If you see the [DataLoader][3] class in pytorch, there is a parameter called:\r\n\r\n&gt; pin_memory (bool, optional) \u2013 If True, the data loader will copy tensors into CUDA pinned memory before returning them.\r\n\r\nwhich is by default `True` in the `get_iterator` function. And as a result you are getting this error. You can simply pass the `pin_memory` param value as `False` when you are calling `get_iterator` function as follows.\r\n\r\n    train_data = get_iterator(get_coco_data(vocab, train=True),\r\n                              batch_size=args.batch_size,\r\n                              ...,\r\n                              ...,\r\n                              ...,\r\n                              pin_memory=False)\r\n\r\n\r\n  [1]: https://github.com/eladhoffer/captionGen/blob/master/data.py\r\n  [2]: https://github.com/eladhoffer/captionGen/blob/master/main.py#L96-L105\r\n  [3]: http://pytorch.org/docs/master/data.html?highlight=dataloader#torch.utils.data.DataLoader"
    },
    {
        "question_id": "47318871",
        "accepted_answer_id": "47319205",
        "question_title": "ValueError: Floating point image RGB values must be in the 0..1 range. while using matplotlib",
        "question_markdown": "I want to visualize weights of the layer of a neural network. I&#39;m using pytorch.\r\n\r\n\r\n    import torch\r\n    import torchvision.models as models\r\n    from matplotlib import pyplot as plt\r\n    \r\n    def plot_kernels(tensor, num_cols=6):\r\n        if not tensor.ndim==4:\r\n            raise Exception(&quot;assumes a 4D tensor&quot;)\r\n        if not tensor.shape[-1]==3:\r\n            raise Exception(&quot;last dim needs to be 3 to plot&quot;)\r\n        num_kernels = tensor.shape[0]\r\n        num_rows = 1+ num_kernels // num_cols\r\n        fig = plt.figure(figsize=(num_cols,num_rows))\r\n        for i in range(tensor.shape[0]):\r\n            ax1 = fig.add_subplot(num_rows,num_cols,i+1)\r\n            ax1.imshow(tensor[i])\r\n            ax1.axis(&#39;off&#39;)\r\n            ax1.set_xticklabels([])\r\n            ax1.set_yticklabels([])\r\n    \r\n        plt.subplots_adjust(wspace=0.1, hspace=0.1)\r\n        plt.show()\r\n    vgg = models.vgg16(pretrained=True)\r\n    mm = vgg.double()\r\n    filters = mm.modules\r\n    body_model = [i for i in mm.children()][0]\r\n    layer1 = body_model[0]\r\n    tensor = layer1.weight.data.numpy()\r\n    plot_kernels(tensor)\r\n\r\nThe above gives this error `ValueError: Floating point image RGB values must be in the 0..1 range.` \r\n\r\nMy question is should I normalize and take absolute value of the weights to overcome this error or is there anyother way ? \r\nIf I normalize and use absolute value I think the meaning of the graphs change. \r\n\r\n    [[[[ 0.02240197 -1.22057354 -0.55051649]\r\n       [-0.50310904  0.00891289  0.15427093]\r\n       [ 0.42360783 -0.23392732 -0.56789106]]\r\n    \r\n      [[ 1.12248898  0.99013627  1.6526649 ]\r\n       [ 1.09936976  2.39608836  1.83921957]\r\n       [ 1.64557672  1.4093554   0.76332706]]\r\n    \r\n      [[ 0.26969245 -1.2997849  -0.64577204]\r\n       [-1.88377869 -2.0100112  -1.43068039]\r\n       [-0.44531786 -1.67845118 -1.33723605]]]\r\n    \r\n    \r\n     [[[ 0.71286005  1.45265901  0.64986968]\r\n       [ 0.75984162  1.8061738   1.06934202]\r\n       [-0.08650422  0.83452386 -0.04468433]]\r\n    \r\n      [[-1.36591709 -2.01630116 -1.54488969]\r\n       [-1.46221244 -2.5365622  -1.91758668]\r\n       [-0.88827479 -1.59151018 -1.47308767]]\r\n    \r\n      [[ 0.93600738  0.98174071  1.12213969]\r\n       [ 1.03908169  0.83749604  1.09565806]\r\n       [ 0.71188802  0.85773659  0.86840987]]]\r\n    \r\n    \r\n     [[[-0.48592842  0.2971966   1.3365227 ]\r\n       [ 0.47920835 -0.18186836  0.59673625]\r\n       [-0.81358945  1.23862112  0.13635623]]\r\n    \r\n      [[-0.75361633 -1.074965    0.70477796]\r\n       [ 1.24439156 -1.53563368 -1.03012812]\r\n       [ 0.97597247  0.83084011 -1.81764793]]\r\n    \r\n      [[-0.80762428 -0.62829626  1.37428832]\r\n       [ 1.01448071 -0.81775147 -0.41943246]\r\n       [ 1.02848887  1.39178836 -1.36779451]]]\r\n    \r\n    \r\n     ..., \r\n     [[[ 1.28134537 -0.00482408  0.71610934]\r\n       [ 0.95264435 -0.09291686 -0.28001019]\r\n       [ 1.34494913  0.64477581  0.96984017]]\r\n    \r\n      [[-0.34442815 -1.40002513  1.66856039]\r\n       [-2.21281362 -3.24513769 -1.17751861]\r\n       [-0.93520379 -1.99811196  0.72937071]]\r\n    \r\n      [[ 0.63388056 -0.17022935  2.06905985]\r\n       [-0.7285465  -1.24722099  0.30488953]\r\n       [ 0.24900314 -0.19559766  1.45432627]]]\r\n    \r\n    \r\n     [[[-0.80684513  2.1764245  -0.73765725]\r\n       [-1.35886598  1.71875226 -1.73327696]\r\n       [-0.75233924  2.14700699 -0.71064663]]\r\n    \r\n      [[-0.79627383  2.21598244 -0.57396138]\r\n       [-1.81044972  1.88310981 -1.63758397]\r\n       [-0.6589964   2.013237   -0.48532376]]\r\n    \r\n      [[-0.3710472   1.4949851  -0.30245575]\r\n       [-1.25448656  1.20453358 -1.29454732]\r\n       [-0.56755757  1.30994892 -0.39370224]]]\r\n    \r\n    \r\n     [[[-0.67361742 -3.69201088 -1.23768616]\r\n       [ 3.12674141  1.70414758 -1.76272404]\r\n       [-0.22565465  1.66484773  1.38172317]]\r\n    \r\n      [[ 0.28095332 -2.03035069  0.69989491]\r\n       [ 1.97936332  1.76992691 -1.09842575]\r\n       [-2.22433758  0.52577412  0.18292744]]\r\n    \r\n      [[ 0.48471382 -1.1984663   1.57565165]\r\n       [ 1.09911084  1.31910467 -0.51982772]\r\n       [-2.76202297 -0.47073677  0.03936549]]]]",
        "accepted_answer_markdown": "It sounds as if you already know your values are not in that range.  Yes, you must re-scale them to the range 0.0 - 1.0.  I suggest that you want to retain visibility of negative vs positive, but that you let 0.5 be your new &quot;neutral&quot; point.  Scale such that current 0.0 values map to 0.5, and your most extreme value (largest magnitude) scale to 0.0 (if negative) or 1.0 (if positive).\r\n\r\n------------------------------\r\n\r\nThanks for the vectors.  It looks like your values are in the range -2.25 to +2.0.  I suggest a rescaling `new = (1/(2*2.25)) * old + 0.5`"
    },
    {
        "question_id": "47403634",
        "accepted_answer_id": "47411454",
        "question_title": "transfer learning [resnet18] using PyTorch. Dataset: Dog-Breed-Identification",
        "question_markdown": "I am trying to implement a transfer learning approach in PyTorch. This is the dataset that I am using: [Dog-Breed][1]\r\n\r\nHere&#39;s the step that I am following.\r\n\r\n    1. Load the data and read csv using pandas.\r\n    2. Resize (60, 60) the train images and store them as numpy array.\r\n    3. Apply stratification and split the train data into 7:1:2 (train:validation:test)\r\n    4. use the resnet18 model and train. \r\n\r\nLocation of dataset\r\n\r\n    LABELS_LOCATION = &#39;./dataset/labels.csv&#39;\r\n    TRAIN_LOCATION = &#39;./dataset/train/&#39;\r\n    TEST_LOCATION = &#39;./dataset/test/&#39;\r\n    ROOT_PATH = &#39;./dataset/&#39;\r\n\r\nReading CSV (labels.csv)\r\n\r\n    def read_csv(csvf):\r\n        # print(pandas.read_csv(csvf).values)\r\n        data=pandas.read_csv(csvf).values\r\n        labels_dict = dict(data)\r\n        idz=list(labels_dict.keys())\r\n        clazz=list(labels_dict.values())\r\n        return labels_dict,idz,clazz\r\n\r\nI did this because of a constraint which I will mention next when I am loading the data using DataLoader.\r\n\r\n    def class_hashmap(class_arr):\r\n        uniq_clazz = Counter(class_arr)\r\n        class_dict = {}\r\n        for i, j in enumerate(uniq_clazz):\r\n            class_dict[j] = i\r\n        return class_dict\r\n\r\n    labels, ids, class_names = read_csv(LABELS_LOCATION)\r\n    train_images = os.listdir(TRAIN_LOCATION)\r\n    class_numbers = class_hashmap(class_names)\r\n\r\nNext, I resize the image to 60,60 using `opencv`, and store the result as numpy array. \r\n\r\n    \r\n    resize = []\r\n    indexed_labels = []\r\n    for t_i in train_images:\r\n        # resize.append(transform.resize(io.imread(TRAIN_LOCATION+t_i), (60, 60, 3)))  # (60,60) is the height and widht; 3 is the number of channels\r\n        resize.append(cv2.resize(cv2.imread(TRAIN_LOCATION+t_i), (60, 60)).reshape(3, 60, 60))\r\n        indexed_labels.append(class_numbers[labels[t_i.split(&#39;.&#39;)[0]]])\r\n    \r\n    resize = np.asarray(resize)\r\n    print(resize.shape)\r\n\r\nHere in indexed_labels, I give each label a number.\r\n\r\n\r\nNext, I split the data into 7:1:2 part\r\n\r\n    X = resize  # numpy array of images [training data]\r\n    y = np.array(indexed_labels)  # indexed labels for images [training labels]\r\n    \r\n    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\r\n    sss.get_n_splits(X, y)\r\n    \r\n    \r\n    for train_index, test_index in sss.split(X, y):\r\n        X_temp, X_test = X[train_index], X[test_index]  # split train into train and test [data]\r\n        y_temp, y_test = y[train_index], y[test_index]  # labels\r\n    \r\n    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.123, random_state=0)\r\n    sss.get_n_splits(X_temp, y_temp)\r\n    \r\n    for train_index, test_index in sss.split(X_temp, y_temp):\r\n        print(&quot;TRAIN:&quot;, train_index, &quot;VAL:&quot;, test_index)\r\n        X_train, X_val = X[train_index], X[test_index]  # training and validation data\r\n        y_train, y_val = y[train_index], y[test_index]  # training and validation labels\r\n\r\n\r\nNext, I loaded the data from the previous step into torch DataLoaders\r\n\r\n    batch_size = 500\r\n    learning_rate = 0.001\r\n\r\n    train = torch.utils.data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\r\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\r\n    \r\n    val = torch.utils.data.TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\r\n    val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=False)\r\n    \r\n    test = torch.utils.data.TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\r\n    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\r\n    \r\n    # print(train_loader.size)\r\n    \r\n    dataloaders = {\r\n        &#39;train&#39;: train_loader,\r\n        &#39;val&#39;: val_loader\r\n    }\r\n\r\nNext, I load the pretrained rensnet model. \r\n\r\n    model_ft = models.resnet18(pretrained=True)\r\n    \r\n    # freeze all model parameters\r\n    # for param in model_ft.parameters():\r\n    #     param.requires_grad = False\r\n    \r\n    num_ftrs = model_ft.fc.in_features\r\n    model_ft.fc = nn.Linear(num_ftrs, len(class_numbers))\r\n    \r\n    if use_gpu:\r\n        model_ft = model_ft.cuda()\r\n        model_ft.fc = model_ft.fc.cuda()\r\n    \r\n    criterion = nn.CrossEntropyLoss()\r\n    \r\n    # Observe that all parameters are being optimized\r\n    optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=0.001, momentum=0.9)\r\n    \r\n    # Decay LR by a factor of 0.1 every 7 epochs\r\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\r\n    \r\n    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\r\n                           num_epochs=25)\r\n\r\n\r\nAnd then I use the train_model, a method described [here][2] in PyTorch&#39;s docs. \r\n\r\nHowever, when I run this I get an error.\r\n\r\n    Traceback (most recent call last):\r\n      File &quot;/Users/nirvair/Sites/pyTorch/TL.py&quot;,\r\n        line 244, in &lt;module&gt;\r\n            num_epochs=25)\r\n          File &quot;/Users/nirvair/Sites/pyTorch/TL.py&quot;, line 176, in train_model\r\n            outputs = model(inputs)\r\n          File &quot;/Library/Python/2.7/site-packages/torch/nn/modules/module.py&quot;, line 224, in __call__\r\n            result = self.forward(*input, **kwargs)\r\n          File &quot;/Library/Python/2.7/site-packages/torchvision/models/resnet.py&quot;, line 149, in forward\r\n            x = self.avgpool(x)\r\n          File &quot;/Library/Python/2.7/site-packages/torch/nn/modules/module.py&quot;, line 224, in __call__\r\n            result = self.forward(*input, **kwargs)\r\n          File &quot;/Library/Python/2.7/site-packages/torch/nn/modules/pooling.py&quot;, line 505, in forward\r\n            self.padding, self.ceil_mode, self.count_include_pad)\r\n          File &quot;/Library/Python/2.7/site-packages/torch/nn/functional.py&quot;, line 264, in avg_pool2d\r\n            ceil_mode, count_include_pad)\r\n          File &quot;/Library/Python/2.7/site-packages/torch/nn/_functions/thnn/pooling.py&quot;, line 360, in forward\r\n            ctx.ceil_mode, ctx.count_include_pad)\r\n        RuntimeError: Given input size: (512x2x2). Calculated output size: (512x0x0). Output size is too small at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/THNN/generic/SpatialAveragePooling.c:64\r\n\r\nI can&#39;t seem to figure out what&#39;s going wrong here.\r\n\r\n\r\n  [1]: https://www.kaggle.com/c/dog-breed-identification/data\r\n  [2]: http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#training-the-model\r\n\r\n",
        "accepted_answer_markdown": "Your network is too deep for the size of images you are using (60x60). As you know, the CNN layers do produce smaller and smaller feature maps as the input image propagate through the layers. This is because you are not using padding. \r\n\r\nThe error you have simply says that the next layer is expecting 512 feature maps with a size of 2 pixels by 2 pixels. The actual feature map produced from the forward pass was 512 maps of size 0x0. This mismatch is what triggered the error.\r\n\r\nGenerally, all stock networks, such as RESNET-18, Inception, etc, require the input images to be of the size 224x224 (at least). You can do this easier using the ```torchvision transforms```[1]. You can also use larger image sizes with one exception for the AlexNet which has the size of feature vector hardcoded as explained in my answer in [2].\r\n\r\nBonus Tip: If you are using the network in pre-tained mode, you will need to whiten the data using the parameters in the pytorch documentation at [3]. \r\n\r\n**Links**\r\n\r\n 1. http://pytorch.org/docs/master/torchvision/transforms.html\r\n 2. https://stackoverflow.com/a/46865203/7387369\r\n 3. http://pytorch.org/docs/master/torchvision/models.html"
    },
    {
        "question_id": "48070505",
        "accepted_answer_id": "48088160",
        "question_title": "PyTorch Softmax Dimensions error",
        "question_markdown": "I&#39;m attempting to write a simple NN module, with 2 layers, first layer ReLU activation, output softmax with 3 classes (one-hot encoded). It seems theres something wrong with the way I&#39;m using the softmax function, but I&#39;m not sure what&#39;s going on. \r\n\r\nX is 178x13\r\nY is 178x3\r\n\r\nDataset I&#39;m using is fairly simple, and can be found [here][1]. \r\n\r\nI keep getting the error:\r\n\r\n    RuntimeError: dimension out of range (expected to be in range of [-2, 1], but got 3) . \r\n.\r\n\r\n    import pandas as pd\r\n    import numpy as np\r\n    import torch\r\n    from torch.autograd import Variable\r\n    from sklearn.preprocessing import LabelBinarizer\r\n    \r\n    # Read in dataset, specifying that this set didn&#39;t come with column headers\r\n    x = pd.read_csv(&#39;Datasets/wine.data&#39;, header=None)\r\n    \r\n    # Rename columns\r\n    x.columns = [&#39;Class&#39;, &#39;A1&#39;, &#39;A2&#39;, &#39;A3&#39;, &#39;A4&#39;, &#39;A5&#39;, &#39;A6&#39;, &#39;A7&#39;, &#39;A8&#39;, &#39;A9&#39;, &#39;A10&#39;, &#39;A11&#39;, &#39;A12&#39;, &#39;A13&#39;]\r\n    \r\n    y = x[[&#39;Class&#39;]].values\r\n    \r\n    #turn class labels into one-hot encoding\r\n    one_hot = LabelBinarizer()\r\n    y = Variable(torch.from_numpy(one_hot.fit_transform(y)), )\r\n    \r\n    x = Variable(torch.from_numpy(x.iloc[:, 1:14].values).float())\r\n    \r\n    \r\n    N, D_in, H, D_out = y.shape[0], x.shape[1], 20, 3\r\n    \r\n    # Implement neural net with nn module\r\n    \r\n    model = torch.nn.Sequential(\r\n        torch.nn.Linear(D_in, H),\r\n        torch.nn.ReLU(),\r\n        torch.nn.Linear(H, D_out),\r\n        torch.nn.LogSoftmax(dim=3)\r\n    )\r\n    \r\n    loss_fn = torch.nn.NLLLoss\r\n    \r\n    learning_rate = 1e-4\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n    \r\n    for t in range(500):\r\n        y_pred = model(x)\r\n    \r\n        loss = loss_fn(y_pred, y)\r\n        print(&quot;Iteration: %d | Loss: %.3f&quot; % (t, loss))\r\n    \r\n        optimizer.zero_grad()\r\n    \r\n        loss.backward()\r\n    \r\n        optimizer.step()\r\n\r\n\r\n  [1]: https://archive.ics.uci.edu/ml/datasets/Wine",
        "accepted_answer_markdown": "This was a problem because for NLLLoss:\r\n\r\n    The target that this loss expects is a class index (0 to N-1, where N = number of classes)\r\n\r\nAnd I had been trying to give it the one-hot encoded vector. I solved my issue by doing:\r\n\r\n    loss = loss_fn(y_pred, torch.max(y, 1)[1])\r\n\r\nWhere torch.max found the maximum values and their respective index. "
    },
    {
        "question_id": "48274929",
        "accepted_answer_id": "48278089",
        "question_title": "Pytorch - RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed",
        "question_markdown": "I keep running into this error:\r\n\r\n&gt; RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.\r\n\r\nI had searched in Pytorch forum, but still can\u2019t find out what I have done wrong in my custom loss function. My model is nn.GRU, and here is my custom loss function:\r\n\r\n    def _loss(outputs, session, items):  # `items` is a dict() contains embedding of all items\r\n        def f(output, target):\r\n            pos = torch.from_numpy(np.array([items[target[&quot;click&quot;]]])).float()\r\n            neg = torch.from_numpy(np.array([items[idx] for idx in target[&quot;suggest_list&quot;] if idx != target[&quot;click&quot;]])).float()\r\n            if USE_CUDA:\r\n                pos, neg = pos.cuda(), neg.cuda()\r\n            pos, neg = Variable(pos), Variable(neg)\r\n    \r\n            pos = F.cosine_similarity(output, pos)\r\n            if neg.size()[0] == 0:\r\n                return torch.mean(F.logsigmoid(pos))\r\n            neg = F.cosine_similarity(output.expand_as(neg), neg)\r\n    \r\n            return torch.mean(F.logsigmoid(pos - neg))\r\n    \r\n        loss = map(f, outputs, session)\r\n        return -torch.mean(torch.cat(loss))\r\n\r\n\r\nTraining code:\r\n\r\n        # zero the parameter gradients\r\n        model.zero_grad()\r\n\r\n        # forward + backward + optimize\r\n        outputs, hidden = model(inputs, hidden)\r\n        loss = _loss(outputs, session, items)\r\n        acc_loss += loss.data[0]\r\n\r\n        loss.backward()\r\n        # Add parameters&#39; gradients to their values, multiplied by learning rate\r\n        for p in model.parameters():\r\n            p.data.add_(-learning_rate, p.grad.data)",
        "accepted_answer_markdown": "The problem is from my training loop: it doesn\u2019t detach or repackage the hidden state in between batches? If so, then `loss.backward()` is trying to back-propagate all the way through to the start of time, which works for the first batch but not for the second because the graph for the first batch has been discarded.\r\n\r\nthere are two possible solutions.\r\n\r\n 1) detach/repackage the hidden state in between batches. There are (at\r\n    least) three ways to do this (and I chose this solution):\r\n\r\n     hidden.detach_()\r\n     \r\n    (or equivalently hidden = hidden.detach()).\r\n     \r\n    \r\n\r\n2) replace loss.backward() with `loss.backward(retain_graph=True)` but know that each successive batch will take more time than the previous one because it will have to back-propagate all the way through to the start of the first batch.\r\n\r\n[Example][1]\r\n\r\n\r\n  [1]: https://github.com/pytorch/examples/blob/e11e0796fc02cc2cd5b6ec2ad7cea21f77e25402/word_language_model/main.py#L155"
    },
    {
        "question_id": "48343857",
        "accepted_answer_id": "48344268",
        "question_title": "What&#39;s the reason of the error ValueError: Expected more than 1 value per channel?",
        "question_markdown": "[reference fast.ai](http://forums.fast.ai/t/how-do-we-use-our-model-against-a-specific-image/7661/50)\r\n\r\n[github repository of fast.ai](https://github.com/fastai/fastai/tree/master/fastai)\r\n(as the code elevates the library which is built on top of **PyTorch**)\r\n&gt; Please scroll the discussion a bit\r\n\r\nI am running the following code, and get an error while trying to pass the data to the predict_array function\r\n\r\nThe code is failing when i am trying to use it to predict directly on a single image but it run&#39;s perfectly when that same image is in a ```test``` folder\r\n\r\n    from fastai.conv_learner import *\r\n    from planet import f2\r\n    \r\n    PATH = &#39;data/shopstyle/&#39;\r\n    \r\n    metrics=[f2]\r\n    f_model = resnet34\r\n    \r\n    def get_data(sz):\r\n        tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, max_zoom=1.05)\r\n        return ImageClassifierData.from_csv(PATH, &#39;train&#39;, label_csv, tfms=tfms, suffix=&#39;.jpg&#39;, val_idxs=val_idxs, test_name=&#39;test&#39;)\r\n    \r\n    def print_list(list_or_iterator):\r\n            return &quot;[&quot; + &quot;, &quot;.join( str(x) for x in list_or_iterator) + &quot;]&quot;\r\n    \r\n    label_csv = f&#39;{PATH}prod_train.csv&#39;\r\n    n = len(list(open(label_csv)))-1\r\n    val_idxs = get_cv_idxs(n)\r\n    \r\n    sz = 64\r\n    data = get_data(sz)\r\n    \r\n    print(&quot;Loading model...&quot;)\r\n    learn = ConvLearner.pretrained(f_model, data, metrics=metrics)\r\n    learn.load(f&#39;{sz}&#39;)\r\n    #learn.load(&quot;tmp&quot;)\r\n    \r\n    print(&quot;Predicting...&quot;)\r\n    learn.precompute=False\r\n    trn_tfms, val_tfrms = tfms_from_model(f_model, sz)\r\n    #im = val_tfrms(open_image(f&#39;{PATH}valid/4500132.jpg&#39;))\r\n    im = val_tfrms(np.array(PIL.Image.open(f&#39;{PATH}valid/4500132.jpg&#39;)))\r\n    preds = learn.predict_array(im[None])\r\n    p=list(zip(data.classes, preds))\r\n    print(&quot;predictions = &quot; + print_list(p))\r\n\r\n**Here&#39;s the Traceback I am Getting**\r\n\r\n      Traceback (most recent call last):\r\n      File &quot;predict.py&quot;, line 34, in &lt;module&gt;\r\n        preds = learn.predict_array(im[None])\r\n      File &quot;/home/ubuntu/fastai/courses/dl1/fastai/learner.py&quot;, line 266, in predict_array\r\n        def predict_array(self, arr): return to_np(self.model(V(T(arr).cuda())))\r\n      File &quot;/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py&quot;, line 325, in __call__\r\n        result = self.forward(*input, **kwargs)\r\n      File &quot;/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py&quot;, line 67, in forward\r\n        input = module(input)\r\n      File &quot;/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py&quot;, line 325, in __call__\r\n        result = self.forward(*input, **kwargs)\r\n      File &quot;/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py&quot;, line 37, in forward\r\n        self.training, self.momentum, self.eps)\r\n      File &quot;/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py&quot;, line 1011, in batch_norm\r\n        raise ValueError(&#39;Expected more than 1 value per channel when training, got input size {}&#39;.format(size))\r\n    ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]\r\n\r\n**Things I have Tried**\r\n\r\n- `np.expand_dims(IMG,axis=0) or image = image[..., np.newaxis]`\r\n\r\n- Tried a different way of reading the image\r\n\r\n\r\n    ```\r\n    img = cv2.imread(img_path)\r\n    img = cv2.resize(img, dsize = (200,200))\r\n    img = np.einsum(&#39;ijk-&gt;kij&#39;, img)\r\n    img = np.expand_dims(img, axis =0) \r\n    img = torch.from_numpy(img) \r\n    learn.model(Variable(img.float()).cuda())\r\n    ```\r\n\r\n\r\nBTW the error still remains \r\n\r\n    ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]\r\n\r\nCan&#39;t find any **reference** in The *Google search* also..",
        "accepted_answer_markdown": "It will fail on batches of size 1 if we use feature-wise batch normalization. \r\n\r\nAs Batch normalization computes:\r\n\r\n    y = (x - mean(x)) / (std(x) + eps)\r\n\r\nIf we have one sample per batch then `mean(x) = x`, and the output will be entirely zero (ignoring the bias). We can&#39;t use that for learning..."
    },
    {
        "question_id": "48377214",
        "accepted_answer_id": "48389451",
        "question_title": "RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)",
        "question_markdown": "\r\nIm using a Pytorch Unet model to which i am feeding in a image as input and along with that i am feeding the label as the input image mask and traning the dataset on it.\r\nThe Unet model i have picked up from somewhere else, and i am using the cross-entropy loss as a loss function but i get this dimension out of range error,\r\n\r\n    RuntimeError                              \r\n    Traceback (most recent call last)\r\n    &lt;ipython-input-358-fa0ef49a43ae&gt; in &lt;module&gt;()\r\n         16 for epoch in range(0, num_epochs):\r\n         17     # train for one epoch\r\n    ---&gt; 18     curr_loss = train(train_loader, model, criterion, epoch, num_epochs)\r\n         19 \r\n         20     # store best loss and save a model checkpoint\r\n\r\n    &lt;ipython-input-356-1bd6c6c281fb&gt; in train(train_loader, model, criterion, epoch, num_epochs)\r\n         16         # measure loss\r\n         17         print (outputs.size(),labels.size())\r\n    ---&gt; 18         loss = criterion(outputs, labels)\r\n         19         losses.update(loss.data[0], images.size(0))\r\n         20 \r\n\r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in     _ _call__(self, *input, **kwargs)\r\n        323         for hook in self._forward_pre_hooks.values():\r\n        324             hook(self, input)\r\n    --&gt; 325         result = self.forward(*input, **kwargs)\r\n        326         for hook in self._forward_hooks.values():\r\n        327             hook_result = hook(self, input, result)\r\n    \r\n    &lt;ipython-input-355-db66abcdb074&gt; in forward(self, logits, targets)\r\n          9         probs_flat = probs.view(-1)\r\n         10         targets_flat = targets.view(-1)\r\n    ---&gt; 11         return self.crossEntropy_loss(probs_flat, targets_flat)\r\n\r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in     __call__(self, *input, **kwargs)\r\n        323         for hook in self._forward_pre_hooks.values():\r\n        324             hook(self, input)\r\n      --&gt; 325         result = self.forward(*input, **kwargs)\r\n        326         for hook in self._forward_hooks.values():\r\n        327             hook_result = hook(self, input, result)\r\n    \r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/modules/loss.py in f orward(self, input, target)\r\n        599         _assert_no_grad(target)\r\n        600         return F.cross_entropy(input, target, self.weight, self.size_average,\r\n    --&gt; 601                                self.ignore_index, self.reduce)\r\n        602 \r\n        603 \r\n    \r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/functional.py in     cross_entropy(input, target, weight, size_average, ignore_index, reduce)\r\n       1138         &gt;&gt;&gt; loss.backward()\r\n       1139     &quot;&quot;&quot;\r\n    -&gt; 1140     return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)\r\n       1141 \r\n       1142 \r\n\r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/functional.py in     log_softmax(input, dim, _stacklevel)\r\n        784     if dim is None:\r\n        785         dim = _get_softmax_dim(&#39;log_softmax&#39;, input.dim(),      _stacklevel)\r\n    --&gt; 786     return torch._C._nn.log_softmax(input, dim)\r\n        787 \r\n        788 \r\n\r\n    RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)\r\n\r\nPart of my code looks like this \r\n\r\n\r\n    class crossEntropy(nn.Module):\r\n        def __init__(self, weight = None, size_average = True):\r\n            super(crossEntropy, self).__init__()\r\n            self.crossEntropy_loss = nn.CrossEntropyLoss(weight, size_average)\r\n            \r\n        def forward(self, logits, targets):\r\n            probs = F.sigmoid(logits)\r\n            probs_flat = probs.view(-1)\r\n            targets_flat = targets.view(-1)\r\n            return self.crossEntropy_loss(probs_flat, targets_flat)\r\n    \r\n    \r\n    class UNet(nn.Module):\r\n        def __init__(self, imsize):\r\n            super(UNet, self).__init__()\r\n            self.imsize = imsize\r\n    \r\n            self.activation = F.relu\r\n            \r\n            self.pool1 = nn.MaxPool2d(2)\r\n            self.pool2 = nn.MaxPool2d(2)\r\n            self.pool3 = nn.MaxPool2d(2)\r\n            self.pool4 = nn.MaxPool2d(2)\r\n            self.conv_block1_64 = UNetConvBlock(4, 64)\r\n            self.conv_block64_128 = UNetConvBlock(64, 128)\r\n            self.conv_block128_256 = UNetConvBlock(128, 256)\r\n            self.conv_block256_512 = UNetConvBlock(256, 512)\r\n            self.conv_block512_1024 = UNetConvBlock(512, 1024)\r\n    \r\n            self.up_block1024_512 = UNetUpBlock(1024, 512)\r\n            self.up_block512_256 = UNetUpBlock(512, 256)\r\n            self.up_block256_128 = UNetUpBlock(256, 128)\r\n            self.up_block128_64 = UNetUpBlock(128, 64)\r\n    \r\n            self.last = nn.Conv2d(64, 2, 1)\r\n    \r\n    \r\n        def forward(self, x):\r\n            block1 = self.conv_block1_64(x)\r\n            pool1 = self.pool1(block1)\r\n    \r\n            block2 = self.conv_block64_128(pool1)\r\n            pool2 = self.pool2(block2)\r\n    \r\n            block3 = self.conv_block128_256(pool2)\r\n            pool3 = self.pool3(block3)\r\n    \r\n            block4 = self.conv_block256_512(pool3)\r\n            pool4 = self.pool4(block4)\r\n    \r\n            block5 = self.conv_block512_1024(pool4)\r\n    \r\n            up1 = self.up_block1024_512(block5, block4)\r\n    \r\n            up2 = self.up_block512_256(up1, block3)\r\n    \r\n            up3 = self.up_block256_128(up2, block2)\r\n    \r\n            up4 = self.up_block128_64(up3, block1)\r\n    \r\n            return F.log_softmax(self.last(up4))\r\n\r\n",
        "accepted_answer_markdown": "According to your code:\r\n\r\n    probs_flat = probs.view(-1)\r\n    targets_flat = targets.view(-1)\r\n    return self.crossEntropy_loss(probs_flat, targets_flat)\r\n\r\nYou are giving two 1d tensor to `nn.CrossEntropyLoss` but according to [documentation][1], it expects:\r\n\r\n    Input: (N,C) where C = number of classes\r\n    Target: (N) where each value is 0 &lt;= targets[i] &lt;= C-1\r\n    Output: scalar. If reduce is False, then (N) instead.\r\n\r\nI believe that is the cause of the problem you are encountering.\r\n\r\n  [1]: http://pytorch.org/docs/0.3.0/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss"
    },
    {
        "question_id": "48402009",
        "accepted_answer_id": "48559107",
        "question_title": "Given input size: (128x1x1). Calculated output size: (128x0x0). Output size is too small",
        "question_markdown": "I am trying to train a U-Net which looks like this \r\n\r\n\r\n    `class UNet(nn.Module):\r\n    def __init__(self, imsize):\r\n        super(UNet, self).__init__()\r\n        self.imsize = imsize\r\n\r\n        self.activation = F.relu\r\n        self.pool1 = nn.MaxPool2d(2)\r\n        self.pool2 = nn.MaxPool2d(2)\r\n        self.pool3 = nn.MaxPool2d(2)\r\n        self.pool4 = nn.MaxPool2d(2)\r\n        self.conv_block1_64 = UNetConvBlock(4, 64)\r\n        self.conv_block64_128 = UNetConvBlock(64, 128)\r\n        self.conv_block128_256 = UNetConvBlock(128, 256)\r\n        self.conv_block256_512 = UNetConvBlock(256, 512)\r\n        self.conv_block512_1024 = UNetConvBlock(512, 1024)\r\n\r\n        self.up_block1024_512 = UNetUpBlock(1024, 512)\r\n        self.up_block512_256 = UNetUpBlock(512, 256)\r\n        self.up_block256_128 = UNetUpBlock(256, 128)\r\n        self.up_block128_64 = UNetUpBlock(128, 64)\r\n\r\n        self.last = nn.Conv2d(64, 1, 1)`\r\n\r\n\r\nThe loss function i am using is \r\n\r\n    `class BCELoss2d(nn.Module):\r\n    \r\n    def __init__(self, weight=None, size_average=True):\r\n        super(BCELoss2d, self).__init__()\r\n        self.bce_loss = nn.BCELoss(weight, size_average)\r\n\r\n    def forward(self, logits, targets):\r\n        probs = F.sigmoid(logits)\r\n        probs_flat = probs.view(-1)\r\n        targets_flat = targets.view(-1)\r\n        return self.bce_loss(probs_flat, targets_flat)`\r\n\r\nThe input image tensor is [1,1,68,68] and labels are also of the same shape \r\n\r\nI get this error:\r\n\r\n\r\n\r\n\r\n    &lt;ipython-input-72-270210759010&gt; in forward(self, x)\r\n     75 \r\n     76         block4 = self.conv_block256_512(pool3)\r\n    ---&gt; 77         pool4 = self.pool4(block4)\r\n         78 \r\n      79         block5 = self.conv_block512_1024(pool4)\r\n\r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in _    _call__(self, *input, **kwargs)\r\n        323         for hook in self._forward_pre_hooks.values():\r\n        324             hook(self, input)\r\n     325         result = self.forward(*input, **kwargs)\r\n        326         for hook in self._forward_hooks.values():\r\n        327             hook_result = hook(self, input, result)\r\n\r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/modules/pooling.py in forward(self, input)\r\n        141         return F.max_pool2d(input, self.kernel_size, self.stride,\r\n        142                             self.padding, self.dilation, self.ceil_mode,\r\n    --&gt; 143                             self.return_indices)\r\n        144 \r\n        145     def __repr__(self):\r\n\r\n    /usr/local/lib/python3.5/dist-packages/torch/nn/functional.py in max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\r\n        332     See :class:`~torch.nn.MaxPool2d` for details.\r\n        333     &quot;&quot;&quot;\r\n    --&gt; 334     ret = torch._C._nn.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\r\n        335     return ret if return_indices else ret[0]\r\n        336 \r\n\r\n    RuntimeError: Given input size: (128x1x1). Calculated output size: (128x0x0). Output size is too small at /pytorch/torch/lib/THCUNN/generic/SpatialDilatedMaxPooling.cu:69\r\n\r\nI&#39;m guessing I&#39;m making a mistake in my channel size or pooling size but i&#39;m not sure where exactly is the mistake.\r\n",
        "accepted_answer_markdown": "Your problem is that before the Pool4 your image has already reduced to a `1x1`pixel size image. So you need to either feed an much larger image of size at least around double that (~134x134) or remove a pooling layer in your network. "
    },
    {
        "question_id": "49161652",
        "accepted_answer_id": "49316176",
        "question_title": "How to get around in place operation error if index leaf variable for gradient update?",
        "question_markdown": "I am encountering In place operation error when I am trying to index a leaf variable to update gradients with customized Shrink function. I cannot work around it. Any help is highly appreciated!\r\n\r\n&lt;!-- language-all: lang-python --&gt;\r\n\r\n    import torch.nn as nn\r\n    import torch\r\n    import numpy as np\r\n    from torch.autograd import Variable, Function\r\n\r\n    # hyper parameters\r\n    batch_size = 100 # batch size of images\r\n    ld = 0.2 # sparse penalty\r\n    lr = 0.1 # learning rate\r\n\r\n    x = Variable(torch.from_numpy(np.random.normal(0,1,(batch_size,10,10))), requires_grad=False)  # original\r\n\r\n    # depends on size of the dictionary, number of atoms.\r\n    D = Variable(torch.from_numpy(np.random.normal(0,1,(500,10,10))), requires_grad=True)\r\n\r\n    # hx sparse representation\r\n    ht = Variable(torch.from_numpy(np.random.normal(0,1,(batch_size,500,1,1))), requires_grad=True)\r\n\r\n    # Dictionary loss function\r\n    loss = nn.MSELoss()\r\n\r\n    # customized shrink function to update gradient\r\n    shrink_ht = lambda x: torch.stack([torch.sign(i)*torch.max(torch.abs(i)-lr*ld,0)[0] for i in x])\r\n\r\n    ### sparse reprsentation optimizer_ht single image.\r\n    optimizer_ht = torch.optim.SGD([ht], lr=lr, momentum=0.9) # optimizer for sparse representation\r\n\r\n    ## update for the batch\r\n    for idx in range(len(x)):\r\n        optimizer_ht.zero_grad() # clear up gradients\r\n        loss_ht = 0.5*torch.norm((x[idx]-(D*ht[idx]).sum(dim=0)),p=2)**2\r\n        loss_ht.backward() # back propogation and calculate gradients\r\n        optimizer_ht.step() # update parameters with gradients\r\n        ht[idx] = shrink_ht(ht[idx])  # customized shrink function.\r\n\r\n    RuntimeError Traceback (most recent call last) in ()\r\n    15 loss_ht.backward() # back propogation and calculate gradients\r\n    16 optimizer_ht.step() # update parameters with gradients\r\n    \u2014&gt; 17 ht[idx] = shrink_ht(ht[idx]) # customized shrink function.\r\n    18\r\n    19\r\n\r\n    /home/miniconda3/lib/python3.6/site-packages/torch/autograd/variable.py in setitem(self, key, value)\r\n    85 return MaskedFill.apply(self, key, value, True)\r\n    86 else:\r\n    \u2014&gt; 87 return SetItem.apply(self, key, value)\r\n    88\r\n    89 def deepcopy(self, memo):\r\n\r\n    RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\r\n\r\nSpecifically, this line of code below seems give error as it index and update leaf variable at the same time. \r\n\r\n    ht[idx] = shrink_ht(ht[idx])  # customized shrink function.\r\n\r\nThanks.\r\n\r\nW.S.",
        "accepted_answer_markdown": "I just found: In order to update the variable, it needs to be `ht.data[idx]` instead of `ht[idx]`. We can use `.data` to access the tensor directly."
    },
    {
        "question_id": "49206550",
        "accepted_answer_id": "49209628",
        "question_title": "pytorch error: multi-target not supported in CrossEntropyLoss()",
        "question_markdown": "I am on a project using acceleration data to predict some activities. \r\nBut I have problems on the loss calculation. I am using `CrossEntropyLoss` for it.\r\n\r\nData is used for it like below\r\nI use the first 4 data of each rows to predict the index like the last one of each rows.\r\n\r\n    1 84 84 81 4\r\n    81 85 85 80 1\r\n    81 82 84 80 1\r\n    1 85 84 2 0\r\n    81 85 82 80 1\r\n    81 82 84 80 1\r\n    81 25 84 80 5\r\n\r\nThe error messages are like below. \r\n    \r\n    minoh@minoh-VirtualBox:~/cow$ python lec5.py\r\n    Traceback (most recent call last):\r\n      File &quot;lec5.py&quot;, line 97, in &lt;module&gt;\r\n        train(epoch)\r\n      File &quot;lec5.py&quot;, line 74, in train\r\n        loss = criterion(y_pred, labels)\r\n      File &quot;/home/minoh/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py&quot;, line 357, in __call__\r\n        result = self.forward(*input, **kwargs)\r\n      File &quot;/home/minoh/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py&quot;, line 679, in forward\r\n        self.ignore_index, self.reduce)\r\n      File &quot;/home/minoh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py&quot;, line 1161, in cross_entropy\r\n        return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)\r\n      File &quot;/home/minoh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py&quot;, line 1052, in nll_loss\r\n        return torch._C._nn.nll_loss(input, target, weight, size_average, ignore_index, reduce)\r\n    RuntimeError: multi-target not supported at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THNN/generic/ClassNLLCriterion.c:22\r\n\r\nMy code is based on [Sung Kim&#39;s pytorch](https://github.com/hunkim/PyTorchZeroToAll/blob/master/09_2_softmax_mnist.py)\r\n    \r\n    import numpy as np\r\n    import torch    \r\n    from torch.autograd import Variable    \r\n    import torch.nn.functional as F    \r\n    from torch.utils.data import Dataset, DataLoader    \r\n    import torch.nn as nn    \r\n    import torch.optim as optim    \r\n    from torchvision import datasets, transforms    \r\n    \r\n    class CowDataset(Dataset):    \r\n    \tdef __init__(self):    \r\n    \t\txy_str = np.loadtxt(&#39;cow_test&#39;, delimiter = &#39; &#39;, dtype = np.str)    \r\n    \t\txy = xy_str.astype(np.float32)    \r\n    \t\txy_int = xy_str.astype(np.int)    \r\n    \t\tself.len = xy.shape[0]    \r\n    \t\tself.x_data = torch.from_numpy(xy[:, 0:4])    \r\n    \t\tself.y_data = torch.from_numpy(xy_int[:, [4]])    \r\n    \r\n    \tdef __getitem__(self, index):    \r\n    \t\treturn self.x_data[index], self.y_data[index]    \r\n    \r\n    \tdef __len__(self):    \r\n    \t\treturn self.len    \r\n    \r\n    dataset = CowDataset()    \r\n    train_loader = DataLoader(dataset = dataset, batch_size = 32, shuffle = True)    \r\n    \r\n    class CowTestset(Dataset):    \r\n            def __init__(self):    \r\n                    xy_str = np.loadtxt(&#39;cow_test2&#39;, delimiter = &#39; &#39;, dtype =np.str)    \r\n                    xy = xy_str.astype(np.float32)    \r\n                    xy_int = xy_str.astype(np.int)    \r\n                    self.len = xy.shape[0]    \r\n                    self.x_data = torch.from_numpy(xy[:, 0:4])    \r\n                    self.y_data = torch.from_numpy(xy_int[:, [4]])    \r\n    \r\n            def __getitem__(self, index):    \r\n                    return self.x_data[index], self.y_data[index]    \r\n    \r\n            def __len__(self):    \r\n                    return self.len    \r\n    \r\n    testset = CowTestset()    \r\n    test_loader = DataLoader(dataset = testset, batch_size = 32, shuffle = True)    \r\n    \r\n    class Model(torch.nn.Module):    \r\n    \tdef __init__(self):    \r\n    \t\tsuper(Model, self).__init__()    \r\n    \t\tself.l1 = torch.nn.Linear(4,5)    \r\n    \t\tself.l2 = torch.nn.Linear(5,7)    \r\n    \t\tself.l3 = torch.nn.Linear(7,6)    \r\n    \t\tself.sigmoid = torch.nn.Sigmoid()    \r\n    \r\n    \tdef forward(self, x):    \r\n    \t\tout1 = self.sigmoid(self.l1(x))    \r\n    \t\tout2 = self.sigmoid(self.l2(out1))    \r\n    \t\ty_pred = self.sigmoid(self.l3(out2))    \r\n    \t\treturn y_pred    \r\n    \r\n    model = Model()    \r\n    criterion = nn.CrossEntropyLoss()    \r\n    optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum = 0.5)    \r\n    \r\n    def train(epoch):    \r\n    \tmodel.train()    \r\n    \tfor batch_idx, (inputs, labels) in enumerate(train_loader):    \r\n    \t\tinputs, labels = Variable(inputs), Variable(labels)    \r\n    \t\toptimizer.zero_grad()    \r\n    \t\ty_pred = model(inputs)    \r\n    \t\tloss = criterion(y_pred, labels)    \r\n    \t\tloss.backward()    \r\n    \t\toptimizer.step()    \r\n    \t\tif batch_idx % 10 == 0:    \r\n    \t\t\tprint(&#39;Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}&#39;.format(\r\n    \t\t\t\tepoch, batch_idx * len(data), len(train_loader.dataset),\r\n    \t\t\t\t100. * batch_idx / len(train_loader), loss.data[0]))    \r\n    \r\n    def test():    \r\n    \tmodel.eval()    \r\n    \ttest_loss = 0    \r\n    \tcorrect = 0    \r\n    \tfor data, target in test_loader:    \r\n    \t\tdata, target = Variable(data, volatile = True), Variable(target)    \r\n    \t\tprint(target)    \r\n    \t\toutput = model(data)    \r\n    \t\ttest_loss += criterion(output, target).data[0]    \r\n    \t\tpred = output.data.max(1, keepdim = True)[1]    \r\n    \t\tcorrect += pred.eq(target.data.view_as(pred)).cpu().sum()    \r\n    \ttest_loss /= len(test_loader.dataset)    \r\n    \tprint(&#39;\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n&#39;.format(test_loss, correct, len(test_loader.dataset), 100.* correct / len(test_loader.dataset)))    \r\n    \r\n    for epoch in range(1,7):    \r\n    \ttrain(epoch)    \r\n    \ttest()    ",
        "accepted_answer_markdown": "Ok. So I reproduced your problem and after some search and reading the API of `CrossEntropyLoss()`, I have found it&#39;s because you have a wrong label dimension.\r\n\r\n[Offical docs of CrossEntropyLoss](http://pytorch.org/docs/master/nn.html#crossentropyloss) here. And you can see\r\n\r\n&gt; Input: (N,C) where C = number of classes  \r\nTarget: (N) where each value is 0\u2264targets[i]\u2264C\u22121\r\n\r\nWhile here, in your `criterion()` function,  you have a `batchSize x 7` input and `batchSize x 1` label. The confusing point is, say your batchSize is 10, a 10x1 tensor can not be regarded as a size-10 tensor, which is what the loss function expectes. You must explictly do the size conversion.\r\n\r\n**Solution**:  \r\nAdd `labels = labels.squeeze_()` before you call `loss = criterion(y_pred, labels)` and do the same thing in your test code. The `squeeze_()` funciton removes size-1 dimensions inplace. So you have a `batchSize`-size label now.\r\n\r\n\r\n"
    },
    {
        "question_id": "49398255",
        "accepted_answer_id": "50140036",
        "question_title": "How do I re-use trained fastai models?",
        "question_markdown": "How do I load pretrained model using fastai implementation over PyTorch? Like in SkLearn I can use pickle to dump a model in file then load and use later. I&#39;ve use .load() method after declaring learn instance like bellow to load previously saved weights:\r\n\r\n    arch=resnet34\r\n    data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\r\n    learn = ConvLearner.pretrained(arch, data, precompute=False)\r\n    learn.load(&#39;resnet34_test&#39;)\r\n\r\nThen to predict the class of an image:\r\n\r\n    trn_tfms, val_tfms = tfms_from_model(arch,100)\r\n    img = open_image(&#39;circle/14.png&#39;)\r\n    im = val_tfms(img)\r\n    preds = learn.predict_array(im[None])\r\n    print(np.argmax(preds))\r\n\r\nBut It gets me the error:\r\n\r\n    ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]\r\n\r\nThis code works if I use `learn.fit(0.01, 3)` instead of `learn.load()`. What I really want is to avoid the training step In my application. \r\n\r\n\r\n\r\n\r\n",
        "accepted_answer_markdown": "This error occurs whenever a batch of your data contains a single element.\r\n\r\n**Solution 1**:\r\nCall learn.predict() after learn.load(&#39;resnet34_test&#39;)\r\n\r\n**Solution 2**:\r\nRemove 1 data point from your training set.\r\n\r\n[Pytorch issue][1]\r\n\r\n\r\n[Fastai forum issue description][2]\r\n\r\n\r\n  [1]: https://github.com/pytorch/pytorch/issues/4534\r\n  [2]: http://forums.fast.ai/t/understanding-code-error-expected-more-than-1-value-per-channel-when-training/9257"
    },
    {
        "question_id": "49878836",
        "accepted_answer_id": "49944604",
        "question_title": "Running through a dataloader in Pytorch using Google Colab",
        "question_markdown": "I am trying to use Pytorch to run classification on a dataset of images of cats and dogs. In my code I am so far downloading the data and going into the folder train which has two folders in it called &quot;cats&quot; and &quot;dogs.&quot; I am then trying to load this data into a dataloader and iterate through batches, but it is giving me some error I don&#39;t understand in the iteration step.\r\n\r\nSince it is Google Colabs I have code in there for downloading data and installing libraries. Any other advice on my code so far would be appreciated as well.\r\n\r\n    !pip install torch\r\n    !pip install torchvision\r\n    \r\n    from __future__ import print_function, division\r\n    import os\r\n    import torch\r\n    import pandas as pd\r\n    import numpy as np\r\n    # For showing and formatting images\r\n    import matplotlib.pyplot as plt\r\n    import matplotlib.image as mpimg\r\n    \r\n    # For importing datasets into pytorch\r\n    import torchvision.datasets as dataset\r\n    \r\n    # Used for dataloaders\r\n    import torch.utils.data as data\r\n    \r\n    # For pretrained resnet34 model\r\n    import torchvision.models as models\r\n    \r\n    # For optimisation function\r\n    import torch.nn as nn\r\n    import torch.optim as optim\r\n    \r\n    \r\n    !wget http://files.fast.ai/data/dogscats.zip\r\n    !unzip dogscats.zip    \r\n    \r\n    batch_size = 256\r\n    \r\n    train_raw = dataset.ImageFolder(PATH+&quot;train&quot;, transform=transforms.ToTensor())\r\n    train_loader = data.DataLoader(train_raw, batch_size=batch_size, shuffle=True)\r\n    \r\n    for batch_idx, (data, target) in enumerate(train_loader):\r\n      print(&quot;Data: &quot;, batch_idx)\r\n\r\n\r\n\r\nThe error comes up on the last lines and is below:\r\n\r\n    RuntimeErrorTraceback (most recent call last)\r\n    &lt;ipython-input-66-c32dd0c1b880&gt; in &lt;module&gt;()\r\n    ----&gt; 1 for batch_idx, (data, target) in enumerate(train_loader):\r\n          2   print(&quot;Data: &quot;, batch_idx)\r\n          3 \r\n    \r\n    /usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.pyc in __next__(self)\r\n        257         if self.num_workers == 0:  # same-process loading\r\n        258             indices = next(self.sample_iter)  # may raise StopIteration\r\n    --&gt; 259             batch = self.collate_fn([self.dataset[i] for i in indices])\r\n        260             if self.pin_memory:\r\n        261                 batch = pin_memory_batch(batch)\r\n    \r\n    /usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.pyc in default_collate(batch)\r\n        133     elif isinstance(batch[0], collections.Sequence):\r\n        134         transposed = zip(*batch)\r\n    --&gt; 135         return [default_collate(samples) for samples in transposed]\r\n        136 \r\n        137     raise TypeError((error_msg.format(type(batch[0]))))\r\n    \r\n    /usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.pyc in default_collate(batch)\r\n        110             storage = batch[0].storage()._new_shared(numel)\r\n        111             out = batch[0].new(storage)\r\n    --&gt; 112         return torch.stack(batch, 0, out=out)\r\n        113     elif elem_type.__module__ == &#39;numpy&#39; and elem_type.__name__ != &#39;str_&#39; \\\r\n        114             and elem_type.__name__ != &#39;string_&#39;:\r\n    \r\n    /usr/local/lib/python2.7/dist-packages/torch/functional.pyc in stack(sequence, dim, out)\r\n         62     inputs = [t.unsqueeze(dim) for t in sequence]\r\n         63     if out is None:\r\n    ---&gt; 64         return torch.cat(inputs, dim)\r\n         65     else:\r\n         66         return torch.cat(inputs, dim, out=out)\r\n    \r\n    RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 400 and 487 in dimension 2 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897\r\n\r\n\r\nThanks",
        "accepted_answer_markdown": "I think the main problem was images being of different size . I may have understood ImageFolder in other way but, i think you don&#39;t need labels for images if the directory structure is as specified in pytorch and  pytorch will figure out the labels for you. \r\nI would also add more things to your transform that automatically resizes every images from the folder such as:\r\n\r\n       normalize = transforms.Normalize(\r\n                            mean=[0.485, 0.456, 0.406],\r\n                            std=[0.229, 0.224, 0.225]\r\n                            )\r\n       transform = transforms.Compose(\r\n            [transforms.ToTensor(),transforms.Resize((224,224)),\r\n             normalize])\r\n\r\n\r\nAlso you can use other tricks to make your DataLoader much faster such as adding batch_size and number of cpu workers such as:\r\n\r\n        testloader = DataLoader(testset, batch_size=16,\r\n                             shuffle=False, num_workers=4)\r\n\r\nI think this will make you pipeline much faster."
    },
    {
        "question_id": "50090821",
        "accepted_answer_id": "50093900",
        "question_title": "How to apply a custom function to specific columns in a matrix in PyTorch",
        "question_markdown": "I have a tensor of size [150, 182, 91], the first part is just the batch size while the matrix I am interested in is the 182x91 one.\r\n\r\nI need to run a function on the 182x91 matrix for each of the 50 dimensions separately. \r\n\r\nI need to get a diagonal matrix stripe of the 182x91 matrix, and the function I am using is the following one (based on my previous question: https://stackoverflow.com/questions/49982746/getting-diagonal-matrix-stripe-automatically-in-numpy-or-pytorch):\r\n\r\n     def stripe(a):\r\n\r\n        i, j = a.size()\r\n        assert (i &gt;= j)\r\n\r\n        out = torch.zeros((i - j + 1, j))\r\n        for diag in range(0, i - j + 1):\r\n            out[diag] = torch.diag(a, -diag)\r\n        return out\r\n\r\nThe `stripe` function expects a matrix of size IxJ and can&#39;t deal with the 3rd dimension.\r\n\r\nSo when I run this:\r\n\r\n    some_matrix = x # &lt;class &#39;torch.autograd.variable.Variable&#39;&gt; torch.Size([150, 182, 91])\r\n    get_diag = stripe(some_matrix)\r\n\r\nI get this Error: `ValueError: too many values to unpack (expected 2)`\r\n\r\nIf I just try to skip the first dimension by doing `x, i, j = a.size()`, \r\nI get this: `RuntimeError: invalid argument 1: expected a matrix or a vector at`\r\n\r\nI am still on PyTorch 0.3.1. Any help is appreciated!",
        "accepted_answer_markdown": "You can map the stripe function over the first dimension of your tensor using `torch.unbind` as\r\n\r\n    In [1]: import torch\r\n    \r\n    In [2]: def strip(a):\r\n       ...:     i, j = a.size()\r\n       ...:     assert(i &gt;= j)\r\n       ...:     out = torch.zeros((i - j + 1, j))\r\n       ...:     for diag in range(0, i - j + 1):\r\n       ...:         out[diag] = torch.diag(a, -diag)\r\n       ...:     return out\r\n       ...: \r\n       ...: \r\n    \r\n    In [3]: a = torch.randn((182, 91)).cuda()\r\n    \r\n    In [5]: output = strip(a)\r\n    \r\n    In [6]: output.size()\r\n    Out[6]: torch.Size([92, 91])\r\n    \r\n    In [7]: a = torch.randn((150, 182, 91))\r\n    \r\n    In [8]: output = list(map(strip, torch.unbind(a, 0)))\r\n    \r\n    In [9]: output = torch.stack(output, 0)\r\n    \r\n    In [10]: output.size()\r\n    Out[10]: torch.Size([150, 92, 91])\r\n\r\n"
    },
    {
        "question_id": "69832196",
        "accepted_answer_id": "69832599",
        "question_title": "PyTorch RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
        "question_markdown": "I&#39;ve found a lot of answers on this topic but none of them helped.\r\n\r\n**The error is**:\r\n```\r\nRuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\r\n```\r\n\r\n**The training loop**:\r\n```python\r\nmodel = BrainModel()\r\nmodel.to(device)\r\nloss_function = nn.BCELoss()\r\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\r\n\r\nfor epoch in range(EPOCHS):\r\n    for sequences, labels in train_dataloader:\r\n        optimizer.zero_grad()\r\n        labels = labels.view(BATCH_SIZE, -1)\r\n        sequences, labels = sequences.to(device), labels.view(BATCH_SIZE, -1).to(device)\r\n        print(next(model.parameters()).is_cuda, sequences.get_device(), labels.get_device())\r\n        out = model(sequences) # ERROR HERE\r\n        out, labels = out.type(torch.FloatTensor), labels.type(torch.FloatTensor)\r\n        loss = loss_function(out, labels)\r\n        loss.backward()\r\n        optimizer.step()\r\n```\r\nYou can see one print inside the loop, and its output is: \r\n```\r\nTrue 0 0\r\n```\r\nwhich means that all - the model, the x and y - are on cuda. The same code works well when I use CPU but not GPU. I do not understand what else I need to move to `device`. I always write it the way I did here and it always worked fine :C\r\n",
        "accepted_answer_markdown": "Needed to do this: use `nn.ModuleList` instead of python list\r\n```python\r\n        self.convolutions1 = nn.ModuleList([nn.Conv2d(1, 3, 5, 2, 2) for _ in range(sequence_size)])\r\n        emb_dim = calc_embedding_size(self.convolutions1[0], input_size)\r\n        self.convolutions2 = nn.ModuleList([nn.Conv2d(3, 6, 3, 1, 0) for _ in range(sequence_size)])\r\n        emb_dim = calc_embedding_size(self.convolutions2[0], emb_dim)\r\n        self.convolutions3 = nn.ModuleList([nn.Conv2d(6, 9, 5, 1, 0) for _ in range(sequence_size)])\r\n        emb_dim = calc_embedding_size(self.convolutions3[0], emb_dim)\r\n```\r\n\r\nAnd use `torch.cuda.FloatTensor` when training on GPU:\r\n\r\n```\r\nout, labels = out.type(torch.cuda.FloatTensor), labels.type(torch.cuda.FloatTensor)\r\n```"
    },
    {
        "question_id": "69914189",
        "accepted_answer_id": "69914287",
        "question_title": "AttributeError: module &#39;torch.optim.lr_scheduler&#39; has no attribute &#39;LinearLR&#39;",
        "question_markdown": "I&#39;m trying to train my own object detection model with Pytorch. But im getting always this error. I tried to change the torch version but this doesn&#39;t helped.&lt;br&gt;My packages: torchvision-0.11.1 and torch-1.10.0\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n&lt;ipython-input-10-9e52b782b448&gt; in &lt;module&gt;()\r\n      4 for epoch in range(num_epochs):\r\n      5     # training for one epoch\r\n----&gt; 6     train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\r\n      7     # update the learning rate\r\n      8     lr_scheduler.step()\r\n\r\n/content/engine.py in train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq)\r\n     21         warmup_iters = min(1000, len(data_loader) - 1)\r\n     22 \r\n---&gt; 23         lr_scheduler = torch.optim.lr_scheduler.LinearLR(\r\n     24             optimizer, start_factor=warmup_factor, total_iters=warmup_iters\r\n     25         )\r\n\r\nAttributeError: module &#39;torch.optim.lr_scheduler&#39; has no attribute &#39;LinearLR&#39;\r\n```",
        "accepted_answer_markdown": "`LinearLR` scheduler was only recently introduced (v1.10.0). Please make sure your pytorch version is up to date and try again."
    }
]