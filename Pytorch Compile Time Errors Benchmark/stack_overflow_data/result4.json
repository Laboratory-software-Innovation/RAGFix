[
    {
        "question_id": "54380830",
        "accepted_answer_id": "54382914",
        "question_title": "Pytorch RuntimeError: Invalid index in gather",
        "question_markdown": "I&#39;m new to Pytorch and I encounter this error:\r\n\r\n&gt; x.gather(1, c)\r\n&gt; \r\n&gt; RuntimeError: Invalid index in gather at\r\n&gt; /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:457\r\n\r\nHere is some informations about the tensors:\r\n\r\n    print(x.size())\r\n    print(c.size())\r\n    print(type(x))\r\n    print(type(c))\r\n    \r\n    torch.Size([128, 2])\r\n    torch.Size([128, 1])\r\n    &lt;class &#39;torch.Tensor&#39;&gt;\r\n    &lt;class &#39;torch.Tensor&#39;&gt;\r\n\r\nx is filled with float values and c with integers, could it be the problem?",
        "accepted_answer_markdown": "This simply means your index tensor `c` has invalid indices.\r\nFor example, the following index tensor is valid:\r\n\r\n            x = torch.tensor([\r\n            [5, 9, 1],\r\n            [3, 2, 8],\r\n            [7, 4, 0]\r\n        ])\r\n        c = torch.tensor([\r\n            [0, 0, 0],\r\n            [1, 2, 0],\r\n            [2, 2, 1]\r\n        ])\r\n        x.gather(1, c)\r\n    &gt;&gt;&gt;tensor([[5, 5, 5],\r\n            [2, 8, 3],\r\n            [0, 0, 4]])\r\nHowever, the following index tensor is invalid:\r\n\r\n    c = torch.tensor([\r\n        [0, 0, 0],\r\n        [1, 2, 0],\r\n        [2, 2, 3]\r\n    ])\r\nAnd it gives the exception you mention\r\n\r\n&gt; RuntimeError: Invalid index in gather"
    },
    {
        "question_id": "54415345",
        "accepted_answer_id": "54416382",
        "question_title": "How to balance (oversampling) unbalanced data in PyTorch (with WeightedRandomSampler)?",
        "question_markdown": "I have a 2-class problem and my data is highly unbalanced. I have 232550 samples from one class and `13498` from the second class. PyTorch docs and the internet tells me to use the class WeightedRandomSampler for my DataLoader. \r\n\r\nI have tried using the WeightedRandomSampler but I keep getting errors.\r\n\r\n        trainratio = np.bincount(trainset.labels)\r\n        classcount = trainratio.tolist()\r\n        train_weights = 1./torch.tensor(classcount, dtype=torch.float)\r\n        train_sampleweights = train_weights[trainset.labels]\r\n        train_sampler = WeightedRandomSampler(weights=train_sampleweights, \r\n        num_samples = len(train_sampleweights))\r\n        trainloader = DataLoader(trainset, sampler=train_sampler, \r\n        shuffle=False)\r\n\r\n\r\nI can not see why I am getting this error when initializing the WeightedRandomSampler class? \r\n\r\nI have tried other similar workarounds but so far all attempts produce some error.\r\nHow should I implement this to balance my train, validation and test data?\r\n\r\nCurrently getting this error:\r\n\r\n&gt; train__sampleweights = train_weights[trainset.labels] ValueError: too\r\n&gt; many dimensions &#39;str&#39;",
        "accepted_answer_markdown": "The problem is in the type of trainset.labels\r\nTo fix the error it is possible to convert trainset.labels to float"
    },
    {
        "question_id": "54417736",
        "accepted_answer_id": "54418944",
        "question_title": "PyTorch runtime error : invalid argument 0: Sizes of tensors must match except in dimension 1",
        "question_markdown": "I have a PyTorch model and I&#39;m trying to test it by performing a forward pass. Here is the code:\r\n\r\n```\r\nclass ResBlock(nn.Module):\r\n    def __init__(self, inplanes, planes, stride=1):\r\n        super(ResBlock, self).__init__()\r\n        self.conv1x1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=1, bias=False)\r\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n        #batch normalization\r\n        self.bn1 = nn.BatchNorm2d(planes)\r\n        self.relu = nn.ReLU()\r\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n        self.bn2 = nn.BatchNorm2d(planes)\r\n        self.stride = stride\r\n\r\n    def forward(self, x):\r\n        residual = self.conv1x1(x)\r\n\r\n        out = self.conv1(x)\r\n        out = self.bn1(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n        \r\n        #adding the skip connection\r\n        out += residual\r\n        out = self.relu(out)\r\n\r\n        return out\r\n\r\nclass ResUnet (nn.Module):\r\n\r\n    def __init__(self, in_shape,  num_classes):\r\n        super(ResUnet, self).__init__()\r\n        in_channels, height, width = in_shape\r\n        #\r\n        #self.L1 = IncResBlock(in_channels,64)\r\n        self.e1 = nn.Sequential(\r\n            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2,padding=1),\r\n            ResBlock(64,64))\r\n            \r\n        \r\n        self.e2 = nn.Sequential(\r\n            nn.LeakyReLU(0.2,),\r\n            nn.Conv2d(64, 128, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(128),\r\n            ResBlock(128,128))\r\n        #\r\n        self.e2add = nn.Sequential(\r\n            nn.Conv2d(128, 128, kernel_size=3, stride=1,padding=1),\r\n            nn.BatchNorm2d(128))\r\n        #\r\n        ##\r\n        self.e3 = nn.Sequential(\r\n            nn.LeakyReLU(0.2,inplace=True),\r\n            nn.Conv2d(128, 128, kernel_size=3, stride=1,padding=1),\r\n            nn.BatchNorm2d(128),\r\n            nn.LeakyReLU(0.2,),\r\n            nn.Conv2d(128,256, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(256),\r\n            ResBlock(256,256))\r\n    \r\n        self.e4 = nn.Sequential(\r\n            nn.LeakyReLU(0.2,),\r\n            nn.Conv2d(256,512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            ResBlock(512,512))\r\n        #\r\n        self.e4add = nn.Sequential(\r\n            nn.Conv2d(512,512, kernel_size=3, stride=1,padding=1),\r\n            nn.BatchNorm2d(512)) \r\n        #\r\n        self.e5 = nn.Sequential(\r\n            nn.LeakyReLU(0.2,inplace=True),\r\n            nn.Conv2d(512,512, kernel_size=3, stride=1,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            nn.LeakyReLU(0.2,),\r\n            nn.Conv2d(512,512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            ResBlock(512,512))\r\n        #\r\n        #\r\n        self.e6 = nn.Sequential(\r\n            nn.LeakyReLU(0.2,),\r\n            nn.Conv2d(512,512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512), \r\n            ResBlock(512,512))\r\n        #\r\n        self.e6add = nn.Sequential(\r\n            nn.Conv2d(512,512, kernel_size=3, stride=1,padding=1),\r\n            nn.BatchNorm2d(512)) \r\n        #\r\n        self.e7 = nn.Sequential(\r\n            nn.LeakyReLU(0.2,inplace=True),\r\n            nn.Conv2d(512,512, kernel_size=3, stride=1,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            nn.LeakyReLU(0.2,),\r\n            nn.Conv2d(512,512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            ResBlock(512,512))\r\n        #\r\n        self.e8 = nn.Sequential(\r\n            nn.LeakyReLU(0.2,),\r\n            nn.Conv2d(512,512, kernel_size=4, stride=2,padding=1))\r\n            #nn.BatchNorm2d(512))\r\n\r\n        self.d1 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            nn.Dropout(p=0.5),\r\n            ResBlock(512,512))\r\n        #\r\n        self.d2 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            nn.Dropout(p=0.5),\r\n            ResBlock(512,512))\r\n        #\r\n        self.d3 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            nn.Dropout(p=0.5),\r\n            ResBlock(512,512))\r\n        #\r\n        self.d4 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(512),\r\n            ResBlock(512,512))\r\n\r\n        #\r\n        self.d5 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(1024, 256, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(256),\r\n            ResBlock(256,256))\r\n        #\r\n        self.d6 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(512, 128, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(128),\r\n            ResBlock(128,128))\r\n        #\r\n        self.d7 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2,padding=1),\r\n            nn.BatchNorm2d(64),\r\n            ResBlock(64,64))\r\n        #\r\n        self.d8 = nn.Sequential(\r\n            nn.ReLU(),\r\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2,padding=1))\r\n            #nn.BatchNorm2d(64),\r\n            #nn.ReLU())\r\n\r\n        self.out_l = nn.Sequential(\r\n            nn.Conv2d(64,num_classes,kernel_size=1,stride=1))\r\n            #nn.ReLU())\r\n   \r\n    def forward(self, x):\r\n\r\n        #Image Encoder\r\n\r\n        #### Encoder #####\r\n\r\n        en1 = self.e1(x)\r\n\r\n        en2 = self.e2(en1)\r\n        en2add = self.e2add(en2)\r\n\r\n        en3 = self.e3(en2add)\r\n\r\n        en4 = self.e4(en3)\r\n        en4add = self.e4add(en4)\r\n\r\n        en5 = self.e5(en4add)\r\n\r\n        en6 = self.e6(en5)\r\n        en6add = self.e6add(en6)\r\n\r\n        en7 = self.e7(en6add)\r\n\r\n        en8 = self.e8(en7)\r\n\r\n        #### Decoder ####\r\n        de1_ = self.d1(en8)\r\n        de1 = torch.cat([en7,de1_],1)\r\n\r\n        de2_ = self.d2(de1)\r\n        de2 = torch.cat([en6add,de2_],1)\r\n        \r\n        \r\n        de3_ = self.d3(de2)\r\n        de3 = torch.cat([en5,de3_],1)\r\n\r\n        \r\n        de4_ = self.d4(de3)\r\n        de4 = torch.cat([en4add,de4_],1)\r\n        \r\n        \r\n        de5_ = self.d5(de4)\r\n        de5 = torch.cat([en3,de5_],1)\r\n        \r\n        de6_ = self.d6(de5)\r\n        de6 = torch.cat([en2add,de6_],1)\r\n    \r\n        de7_ = self.d7(de6)\r\n        de7 = torch.cat([en1,de7_],1)\r\n        de8 = self.d8(de7)\r\n\r\n        out_l_mask = self.out_l(de8)\r\n         \r\n        return out_l_mask  \r\n```\r\n\r\nHere is how I attempt to test it:\r\n\r\n```\r\nmodl = ResUnet((1,512,512), 1)\r\nx = torch.rand(1, 1, 512, 512)\r\nmodl(x)\r\n```\r\n\r\nThis works fine, as does for any size that are multiples of 64.\r\n\r\nIf I try:\r\n\r\n```\r\nmodl = ResUnet((1,320,320), 1)\r\nx = torch.rand(1, 1, 320, 320)\r\nmodl(x)\r\n```\r\n\r\nIt throws an error\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n&lt;ipython-input-46-4ddc821c365b&gt; in &lt;module&gt;\r\n----&gt; 1 modl(x)\r\n\r\n~/.conda/envs/torch0.4/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    475             result = self._slow_forward(*input, **kwargs)\r\n    476         else:\r\n--&gt; 477             result = self.forward(*input, **kwargs)\r\n    478         for hook in self._forward_hooks.values():\r\n    479             hook_result = hook(self, input, result)\r\n\r\n&lt;ipython-input-36-f9eeefa3c0b8&gt; in forward(self, x)\r\n    221         de2_ = self.d2(de1)\r\n    222         #print de2_.size()\r\n--&gt; 223         de2 = torch.cat([en6add,de2_],1)\r\n    224         #print de2.size()\r\n    225 \r\n\r\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 5 and 4 in dimension 2 at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/TH/generic/THTensorMath.cpp:3616\r\n```\r\n\r\nI figure the problem is caused by the input size not being a power of 2 but I am not sure how to rectify it for the given input dimenstions (320, 320).\r\n\r\n\r\n\r\n",
        "accepted_answer_markdown": "This issue arises from mismatch in size between the variables in the downsampling (encoder) path and the upsampling (decoder) path. Your code is huge and difficult to understand, but by inserting `print` statements, we can check that \r\n\r\n1. `en6add` is of size `[1, 512, 5, 5]`\r\n2. `en7` is `[1, 512, 2, 2]`\r\n3. `en8` is `[1, 512, 1, 1]`\r\n4. then upsampling goes as powers of two: `de1_` is `[1, 512, 2, 2]`\r\n5. `de1` `[1, 1024, 2, 2]`\r\n6. `de2_` `[1, 512, 4, 4]`\r\n\r\nat which point you try to concatenate it with `en6add`, so apparently the code creating `de2_` is not &quot;upsampling enough&quot;. My strong guess is that you need to pay the attention to the `output_padding` parameter of [`nn.ConvTranspose2d`](https://pytorch.org/docs/master/nn.html#torch.nn.ConvTranspose2d) and possibly set it to `1` in a couple of places. I would try and fix this error for you, but that example is so far from being [minimal](https://stackoverflow.com/help/mcve) that I can&#39;t wrap my head around the whole of it."
    },
    {
        "question_id": "54435133",
        "accepted_answer_id": "54435675",
        "question_title": "net.load_state_dict(torch.load(&#39;rnn_x_epoch.net&#39;)) not working on cpu",
        "question_markdown": "I am using pytorch to train a Neural Network. When I train and test on GPU, it works fine.\r\nBut When I try to load the model parameters on CPU using:\r\n\r\n    net.load_state_dict(torch.load(&#39;rnn_x_epoch.net&#39;))\r\n\r\nI get the following error:\r\n\r\n    RuntimeError: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at torch/csrc/cuda/Module.cpp:51\r\n\r\nI have searched for the error, it&#39;s mainly because of CUDA driver dependency, but since I&#39;m running on CPU when I get this error,it must be something else, or may be I missed something.\r\nSince it&#39;s working fine using GPU, I could just run it on GPU but I&#39;m trying to train the network on GPU, store the parameters and then load it on CPU mode for predictions.\r\nI am just looking for a way to load the parameters while on CPU mode.\r\n\r\nI tried this as well to load the parameters:\r\n\r\n    check = torch.load(&#39;rnn_x_epoch.net&#39;)\r\nIt did not work.\r\n\r\nI tried to save the model parameters in two ways, to see if any of these would work, but didn&#39;t:\r\n1)\r\n\r\n    checkpoint = {&#39;n_hidden&#39;: net.n_hidden,\r\n              &#39;n_layers&#39;: net.n_layers,\r\n              &#39;state_dict&#39;: net.state_dict(),\r\n              &#39;tokens&#39;: net.chars}\r\n\r\n    with open(&#39;rnn_x_epoch.net&#39;, &#39;wb&#39;) as f:\r\n        torch.save(checkpoint, f)\r\n2)\r\n\r\n    torch.save(model.state_dict(), &#39;rnn_x_epoch.net&#39;)\r\n\r\nTraceBack:\r\n\r\n    ---------------------------------------------------------------------------\r\n    RuntimeError                              Traceback (most recent call last)\r\n    &lt;ipython-input-9-e61f28013b35&gt; in &lt;module&gt;()\r\n    ----&gt; 1 net.load_state_dict(torch.load(&#39;rnn_x_epoch.net&#39;))\r\n\r\n    /opt/conda/lib/python3.6/site-packages/torch/serialization.py in load(f, map_location, pickle_module)\r\n        301         f = open(f, &#39;rb&#39;)\r\n        302     try:\r\n    --&gt; 303         return _load(f, map_location, pickle_module)\r\n        304     finally:\r\n        305         if new_fd:\r\n\r\n    /opt/conda/lib/python3.6/site-packages/torch/serialization.py in _load(f, map_location, pickle_module)\r\n        467     unpickler = pickle_module.Unpickler(f)\r\n        468     unpickler.persistent_load = persistent_load\r\n    --&gt; 469     result = unpickler.load()\r\n        470 \r\n        471     deserialized_storage_keys = pickle_module.load(f)\r\n\r\n    /opt/conda/lib/python3.6/site-packages/torch/serialization.py in persistent_load(saved_id)\r\n        435             if root_key not in deserialized_objects:\r\n        436                 deserialized_objects[root_key] = restore_location(\r\n    --&gt; 437                     data_type(size), location)\r\n        438             storage = deserialized_objects[root_key]\r\n        439             if view_metadata is not None:\r\n\r\n    /opt/conda/lib/python3.6/site-packages/torch/serialization.py in default_restore_location(storage, location)\r\n         86 def default_restore_location(storage, location):\r\n         87     for _, _, fn in _package_registry:\r\n    ---&gt; 88         result = fn(storage, location)\r\n         89         if result is not None:\r\n         90             return result\r\n\r\n    /opt/conda/lib/python3.6/site-packages/torch/serialization.py in _cuda_deserialize(obj, location)\r\n         68     if location.startswith(&#39;cuda&#39;):\r\n         69         device = max(int(location[5:]), 0)\r\n    ---&gt; 70         return obj.cuda(device)\r\n         71 \r\n         72 \r\n\r\n    /opt/conda/lib/python3.6/site-packages/torch/_utils.py in _cuda(self, device, non_blocking, **kwargs)\r\n         66         if device is None:\r\n         67             device = -1\r\n    ---&gt; 68     with torch.cuda.device(device):\r\n         69         if self.is_sparse:\r\n         70             new_type = getattr(torch.cuda.sparse, \r\n    self.__class__.__name__)\r\n\r\n    /opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py in __enter__(self)\r\n        223         if self.idx is -1:\r\n        224             return\r\n    --&gt; 225         self.prev_idx = torch._C._cuda_getDevice()\r\n        226         if self.prev_idx != self.idx:\r\n        227             torch._C._cuda_setDevice(self.idx)\r\n\r\n    RuntimeError: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at torch/csrc/cuda/Module.cpp:51\r\n\r\nAlso may be the save/load operations in Pytorch are only for GPU mode, but I am not really convinced by that.",
        "accepted_answer_markdown": "From the PyTorch [documentation][1]:\r\n&gt; When you call `torch.load()` on a file which contains GPU tensors, those tensors will be loaded to GPU by default. \r\n\r\nTo load the model on CPU which was saved on GPU, you need to pass `map_location` argument as `cpu` in `load` function as follows:\r\n\r\n```\r\n# Load all tensors onto the CPU\r\nnet.load_state_dict(torch.load(&#39;rnn_x_epoch.net&#39;, map_location=torch.device(&#39;cpu&#39;)))\r\n```\r\n\r\nIn doing so, the storages underlying the tensors are dynamically remapped to the CPU device using the `map_location` argument. You can read more on the official [PyTorch tutorials][2].\r\n\r\nThis can also be done as follows:\r\n\r\n```\r\n# Load all tensors onto the CPU, using a function\r\nnet.load_state_dict(torch.load(&#39;rnn_x_epoch.net&#39;, map_location=lambda storage, loc: storage))\r\n```\r\n\r\n\r\n  [1]: https://pytorch.org/docs/stable/torch.html#torch.load\r\n  [2]: https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-on-gpu-load-on-cpu"
    },
    {
        "question_id": "54678896",
        "accepted_answer_id": "54684415",
        "question_title": "Pytorch ValueError: optimizer got an empty parameter list",
        "question_markdown": "When trying to create a neural network and optimize it using Pytorch, I am getting \r\n\r\n&gt; ValueError: optimizer got an empty parameter list\r\n\r\nHere is the code.\r\n\r\n    \r\n    import torch.nn as nn\r\n    import torch.nn.functional as F\r\n    from os.path import dirname\r\n    from os import getcwd\r\n    from os.path import realpath\r\n    from sys import argv\r\n    \r\n    class NetActor(nn.Module):\r\n        def __init__(self, args, state_vector_size, action_vector_size, hidden_layer_size_list):\r\n            super(NetActor, self).__init__()\r\n            self.args = args\r\n    \r\n            self.state_vector_size = state_vector_size\r\n            self.action_vector_size = action_vector_size\r\n            self.layer_sizes = hidden_layer_size_list\r\n            self.layer_sizes.append(action_vector_size)\r\n    \r\n            self.nn_layers = []\r\n            self._create_net()\r\n\r\n        def _create_net(self):\r\n            prev_layer_size = self.state_vector_size\r\n            for next_layer_size in self.layer_sizes:\r\n                next_layer = nn.Linear(prev_layer_size, next_layer_size)\r\n                prev_layer_size = next_layer_size\r\n                self.nn_layers.append(next_layer)\r\n    \r\n        def forward(self, torch_state):\r\n            activations = torch_state\r\n            for i,layer in enumerate(self.nn_layers):\r\n                if i != len(self.nn_layers)-1:\r\n                    activations = F.relu(layer(activations))\r\n                else:\r\n                    activations = layer(activations)\r\n    \r\n            probs = F.softmax(activations, dim=-1)\r\n            return probs\r\n    \r\n \r\n\r\n\r\nand then the call\r\n\r\n            self.actor_nn = NetActor(self.args, 4, 2, [128])\r\n            self.actor_optimizer = optim.Adam(self.actor_nn.parameters(), lr=args.learning_rate)\r\n\r\ngives the very informative error\r\n\r\n&gt; ValueError: optimizer got an empty parameter list\r\n\r\n\r\nI find it hard to understand what exactly in the network&#39;s definition makes the network have parameters.\r\n\r\nI am following and expanding the example I found in [Pytorch&#39;s tutorial code][1].\r\n\r\nI can&#39;t really tell the difference between my code and theirs that makes mine think it has no parameters to optimize.\r\n\r\n**How to make my network have parameters like the linked example?** \r\n\r\n\r\n  [1]: https://github.com/pytorch/examples/blob/master/reinforcement_learning/reinforce.py",
        "accepted_answer_markdown": "Your `NetActor` does not directly store any [`nn.Parameter`][1]. Moreover, all other layers it eventually uses in `forward` are stored as a *simple* list in `self.nn_layers`.  \r\nIf you want `self.actor_nn.parameters()` to know that the items stored in the list `self.nn_layers` may contain trainable parameters, you should work with [containers][3].  \r\nSpecifically, making `self.nn_layers` to be a [`nn.ModuleList`][2] instead of a simple list should solve your problem:\r\n\r\n    self.nn_layers = nn.ModuleList()\r\n\r\n [1]: https://pytorch.org/docs/0.4.1/nn.html#torch.nn.Parameter\r\n [2]: https://pytorch.org/docs/0.4.1/nn.html#torch.nn.ModuleList\r\n [3]: https://pytorch.org/docs/0.4.1/nn.html#containers"
    },
    {
        "question_id": "54727686",
        "accepted_answer_id": "54729021",
        "question_title": "Concat tensors in PyTorch",
        "question_markdown": "I have a tensor called `data` of the shape `[128, 4, 150, 150]` where 128 is the batch size, 4 is the number of channels, and the last 2 dimensions are height and width. I have another tensor called `fake` of the shape `[128, 1, 150, 150]`.\r\n\r\nI want to drop the last `list/array` from the 2nd dimension of `data`; the shape of data would now be `[128, 3, 150, 150]`; and concatenate it with `fake` giving the output dimension of the concatenation as `[128, 4, 150, 150]`.\r\n\r\nBasically, in other words, I want to concatenate the first 3 dimensions of `data` with `fake` to give a 4-dimensional tensor.\r\n\r\nI am using PyTorch and came across the functions `torch.cat()` and `torch.stack()`\r\n\r\nHere is a sample code I&#39;ve written:\r\n\r\n    fake_combined = []\r\n            for j in range(batch_size):\r\n                fake_combined.append(torch.stack((data[j][0].to(device), data[j][1].to(device), data[j][2].to(device), fake[j][0].to(device))))\r\n    fake_combined = torch.tensor(fake_combined, dtype=torch.float32)\r\n    fake_combined = fake_combined.to(device)\r\n\r\nBut I am getting an error in the line:\r\n\r\n    fake_combined = torch.tensor(fake_combined, dtype=torch.float32)\r\n\r\nThe error is:\r\n\r\n    ValueError: only one element tensors can be converted to Python scalars\r\n\r\nAlso, if I print the shape of `fake_combined`, I get the output as `[128,]` instead of `[128, 4, 150, 150]`\r\n\r\nAnd when I print the shape of `fake_combined[0]`, I get the output as `[4, 150, 150]`, which is as expected.\r\n\r\nSo my question is, why am I not able to convert the list to tensor using `torch.tensor()`. Am I missing something? Is there any better way to do what I intend to do?\r\n\r\nAny help will be appreciated! Thanks!",
        "accepted_answer_markdown": "You could also just assign to that particular dimension.\r\n\r\n    orig = torch.randint(low=0, high=10, size=(2,3,2,2))\r\n    fake = torch.randint(low=111, high=119, size=(2,1,2,2))\r\n    orig[:,[2],:,:] = fake\r\n\r\nOriginal Before\r\n\r\n    tensor([[[[0, 1],\r\n          [8, 0]],\r\n\r\n         [[4, 9],\r\n          [6, 1]],\r\n\r\n         [[8, 2],\r\n          [7, 6]]],\r\n\r\n\r\n        [[[1, 1],\r\n          [8, 5]],\r\n\r\n         [[5, 0],\r\n          [8, 6]],\r\n\r\n         [[5, 5],\r\n          [2, 8]]]])\r\n\r\nFake\r\n\r\n    tensor([[[[117, 115],\r\n          [114, 111]]],\r\n\r\n\r\n        [[[115, 115],\r\n          [118, 115]]]])\r\n\r\nOriginal After\r\n\r\n    tensor([[[[  0,   1],\r\n          [  8,   0]],\r\n\r\n         [[  4,   9],\r\n          [  6,   1]],\r\n\r\n         [[117, 115],\r\n          [114, 111]]],\r\n\r\n\r\n        [[[  1,   1],\r\n          [  8,   5]],\r\n\r\n         [[  5,   0],\r\n          [  8,   6]],\r\n\r\n         [[115, 115],\r\n          [118, 115]]]])\r\n\r\nHope this helps! :)"
    },
    {
        "question_id": "54749244",
        "accepted_answer_id": "54749794",
        "question_title": "Input dimension error on pytorch&#39;s forward check",
        "question_markdown": "I am creating an *RNN* with `pytorch`, it looks like this:\r\n\r\n    class MyRNN(nn.Module):\r\n        def __init__(self, batch_size, n_inputs, n_neurons, n_outputs):\r\n            super(MyRNN, self).__init__()\r\n    \r\n            self.n_neurons = n_neurons\r\n            self.batch_size = batch_size\r\n            self.n_inputs = n_inputs\r\n            self.n_outputs = n_outputs\r\n    \r\n            self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons)\r\n    \r\n            self.FC = nn.Linear(self.n_neurons, self.n_outputs)\r\n    \r\n        def init_hidden(self, ):\r\n            # (num_layers, batch_size, n_neurons)\r\n            return torch.zeros(1, self.batch_size, self.n_neurons)\r\n    \r\n        def forward(self, X):\r\n            self.batch_size = X.size(0)\r\n            self.hidden = self.init_hidden()\r\n    \r\n            lstm_out, self.hidden = self.basic_rnn(X, self.hidden)\r\n            out = self.FC(self.hidden)\r\n    \r\n            return out.view(-1, self.n_outputs)\r\n\r\nMy input `x` looks like this:\r\n\r\n    tensor([[-1.0173e-04, -1.5003e-04, -1.0218e-04, -7.4541e-05, -2.2869e-05,\r\n             -7.7171e-02, -4.4630e-03, -5.0750e-05, -1.7911e-04, -2.8082e-04,\r\n             -9.2992e-06, -1.5608e-05, -3.5471e-05, -4.9127e-05, -3.2883e-01],\r\n            [-1.1193e-04, -1.6928e-04, -1.0218e-04, -7.4541e-05, -2.2869e-05,\r\n             -7.7171e-02, -4.4630e-03, -5.0750e-05, -1.7911e-04, -2.8082e-04,\r\n             -9.2992e-06, -1.5608e-05, -3.5471e-05, -4.9127e-05, -3.2883e-01],\r\n            ...\r\n    \r\n            [-6.9490e-05, -8.9197e-05, -1.0218e-04, -7.4541e-05, -2.2869e-05,\r\n             -7.7171e-02, -4.4630e-03, -5.0750e-05, -1.7911e-04, -2.8082e-04,\r\n             -9.2992e-06, -1.5608e-05, -3.5471e-05, -4.9127e-05, -3.2883e-01]],\r\n           dtype=torch.float64)\r\n\r\nand is a batch of 64 vectors with size 15.\r\n\r\nWhen trying to test this model by doing:\r\n\r\n    BATCH_SIZE = 64\r\n    N_INPUTS = 15\r\n    N_NEURONS = 150\r\n    N_OUTPUTS = 1\r\n    model = MyRNN(BATCH_SIZE, N_INPUTS, N_NEURONS, N_OUTPUTS)\r\n    model(x)\r\n\r\nI get the following error:\r\n\r\n    File &quot;/home/tt/anaconda3/envs/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py&quot;, line 126, in check_forward_args\r\n        expected_input_dim, input.dim()))\r\n    RuntimeError: input must have 3 dimensions, got 2\r\n\r\nHow can I fix it?",
        "accepted_answer_markdown": "You are missing one of the required dimensions for the RNN layer.\n\nPer the [documentation][1], your input size needs to be of shape (sequence length, batch, input size). \n\nSo - with the example above, you are missing one of these. Based on your variable names, it appears you are trying to pass 64 examples of 15 inputs each... if that\u2019s true, you are missing sequence length. \n\nWith an RNN, the sequence length is the number of times you want the layer to recur. For example, in NLP your sequence length might be equal to the number of words in a sentence, while batch size would be the number of sentences you are passing, and input size would be the vector size of each word.\n\nYou might not need an RNN here if you are just trying to do use 64 samples of size 15. \n\n\n  [1]: https://pytorch.org/docs/master/nn.html#torch.nn.RNN"
    },
    {
        "question_id": "54824768",
        "accepted_answer_id": "54895171",
        "question_title": "RNN model (GRU) of word2vec to regression not learning",
        "question_markdown": "I am converting Keras code into PyTorch because I am more familiar with the latter than the former. However, I found that it is not learning (or only barely).\r\n\r\nBelow I have provided almost all of my PyTorch code, including the initialisation code so that you can try it out yourself. The only thing you would need to provide yourself, is the word embeddings (I&#39;m sure you can find many word2vec models online). The first input file should be a file with tokenised text, the second input file should be a file with floating-point numbers, one per line. Because I have provided all the code, this question may seem huge and too broad. However, my question is specific enough I think: what is wrong in my model or training loop that causes my model to not or barely improve. (See below for results.)\r\n\r\nI have tried to provide many comments where applicable, and I have provided the shape transformations as well so you do not *have* to run the code to see what is going on. The data prep methods are not important to inspect.\r\n\r\nThe most important parts are the forward method of the `RegressorNet`, and the training loop of `RegressionNN` (admittedly, these names were badly chosen). I think the mistake is there somewhere.\r\n\r\n\r\n\r\n    from pathlib import Path\r\n    import time\r\n    \r\n    import numpy as np\r\n    import torch\r\n    from torch import nn, optim\r\n    from torch.utils.data import DataLoader\r\n    import gensim\r\n    \r\n    from scipy.stats import pearsonr\r\n    \r\n    from LazyTextDataset import LazyTextDataset\r\n    \r\n    \r\n    class RegressorNet(nn.Module):\r\n        def __init__(self, hidden_dim, embeddings=None, drop_prob=0.0):\r\n            super(RegressorNet, self).__init__()\r\n            self.hidden_dim = hidden_dim\r\n            self.drop_prob = drop_prob\r\n    \r\n            # Load pretrained w2v model, but freeze it: don&#39;t retrain it.\r\n            self.word_embeddings = nn.Embedding.from_pretrained(embeddings)\r\n            self.word_embeddings.weight.requires_grad = False\r\n            self.w2v_rnode = nn.GRU(embeddings.size(1), hidden_dim, bidirectional=True, dropout=drop_prob)\r\n    \r\n            self.dropout = nn.Dropout(drop_prob)\r\n            self.linear = nn.Linear(hidden_dim * 2, 1)\r\n            # LeakyReLU rather than ReLU so that we don&#39;t get stuck in a dead nodes\r\n            self.lrelu = nn.LeakyReLU()\r\n    \r\n        def forward(self, batch_size, sentence_input):\r\n            # shape sizes for:\r\n            # * batch_size 128\r\n            # * embeddings of dim 146\r\n            # * hidden dim of 200\r\n            # * sentence length of 20\r\n    \r\n            # sentence_input: torch.Size([128, 20])\r\n            # Get word2vec vector representation\r\n            embeds = self.word_embeddings(sentence_input)\r\n            # embeds: torch.Size([128, 20, 146])\r\n    \r\n            # embeds.view(-1, batch_size, embeds.size(2)): torch.Size([20, 128, 146])\r\n            # Input vectors into GRU, only keep track of output\r\n            w2v_out, _ = self.w2v_rnode(embeds.view(-1, batch_size, embeds.size(2)))\r\n            # w2v_out = torch.Size([20, 128, 400])\r\n    \r\n            # Leaky ReLU it\r\n            w2v_out = self.lrelu(w2v_out)\r\n    \r\n            # Dropout some nodes\r\n            if self.drop_prob &gt; 0:\r\n                w2v_out = self.dropout(w2v_out)\r\n            # w2v_out: torch.Size([20, 128, 400\r\n    \r\n            # w2v_out[-1, :, :]: torch.Size([128, 400])\r\n            # Only use the last output of a sequence! Supposedly that cell outputs the final information\r\n            regression = self.linear(w2v_out[-1, :, :])\r\n            regression: torch.Size([128, 1])\r\n    \r\n            return regression\r\n    \r\n    \r\n    class RegressionRNN:\r\n        def __init__(self, train_files=None, test_files=None, dev_files=None):\r\n            print(&#39;Using torch &#39; + torch.__version__)\r\n    \r\n            self.datasets, self.dataloaders = RegressionRNN._set_data_loaders(train_files, test_files, dev_files)\r\n            self.device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)\r\n    \r\n            self.model = self.w2v_vocab = self.criterion = self.optimizer = self.scheduler = None\r\n    \r\n        @staticmethod\r\n        def _set_data_loaders(train_files, test_files, dev_files):\r\n            # labels must be the last input file\r\n            datasets = {\r\n                &#39;train&#39;: LazyTextDataset(train_files) if train_files is not None else None,\r\n                &#39;test&#39;: LazyTextDataset(test_files) if test_files is not None else None,\r\n                &#39;valid&#39;: LazyTextDataset(dev_files) if dev_files is not None else None\r\n            }\r\n            dataloaders = {\r\n                &#39;train&#39;: DataLoader(datasets[&#39;train&#39;], batch_size=128, shuffle=True, num_workers=4) if train_files is not None else None,\r\n                &#39;test&#39;: DataLoader(datasets[&#39;test&#39;], batch_size=128, num_workers=4) if test_files is not None else None,\r\n                &#39;valid&#39;: DataLoader(datasets[&#39;valid&#39;], batch_size=128, num_workers=4) if dev_files is not None else None\r\n            }\r\n    \r\n            return datasets, dataloaders\r\n    \r\n        @staticmethod\r\n        def prepare_lines(data, split_on=None, cast_to=None, min_size=None, pad_str=None, max_size=None, to_numpy=False,\r\n                          list_internal=False):\r\n            &quot;&quot;&quot; Converts the string input (line) to an applicable format. &quot;&quot;&quot;\r\n            out = []\r\n            for line in data:\r\n                line = line.strip()\r\n                if split_on:\r\n                    line = line.split(split_on)\r\n                    line = list(filter(None, line))\r\n                else:\r\n                    line = [line]\r\n    \r\n                if cast_to is not None:\r\n                    line = [cast_to(l) for l in line]\r\n    \r\n                if min_size is not None and len(line) &lt; min_size:\r\n                    # pad line up to a number of tokens\r\n                    line += (min_size - len(line)) * [&#39;@pad@&#39;]\r\n                elif max_size and len(line) &gt; max_size:\r\n                    line = line[:max_size]\r\n    \r\n                if list_internal:\r\n                    line = [[item] for item in line]\r\n    \r\n                if to_numpy:\r\n                    line = np.array(line)\r\n    \r\n                out.append(line)\r\n    \r\n            if to_numpy:\r\n                out = np.array(out)\r\n    \r\n            return out\r\n    \r\n        def prepare_w2v(self, data):\r\n            idxs = []\r\n            for seq in data:\r\n                tok_idxs = []\r\n                for word in seq:\r\n                    # For every word, get its index in the w2v model.\r\n                    # If it doesn&#39;t exist, use @unk@ (available in the model).\r\n                    try:\r\n                        tok_idxs.append(self.w2v_vocab[word].index)\r\n                    except KeyError:\r\n                        tok_idxs.append(self.w2v_vocab[&#39;@unk@&#39;].index)\r\n                idxs.append(tok_idxs)\r\n            idxs = torch.tensor(idxs, dtype=torch.long)\r\n    \r\n            return idxs\r\n    \r\n        def train(self, epochs=10):\r\n            valid_loss_min = np.Inf\r\n            train_losses, valid_losses = [], []\r\n            for epoch in range(1, epochs + 1):\r\n                epoch_start = time.time()\r\n    \r\n                train_loss, train_results = self._train_valid(&#39;train&#39;)\r\n                valid_loss, valid_results = self._train_valid(&#39;valid&#39;)\r\n    \r\n                # Calculate Pearson correlation between prediction and target\r\n                try:\r\n                    train_pearson = pearsonr(train_results[&#39;predictions&#39;], train_results[&#39;targets&#39;])\r\n                except FloatingPointError:\r\n                    train_pearson = &quot;Could not calculate Pearsonr&quot;\r\n    \r\n                try:\r\n                    valid_pearson = pearsonr(valid_results[&#39;predictions&#39;], valid_results[&#39;targets&#39;])\r\n                except FloatingPointError:\r\n                    valid_pearson = &quot;Could not calculate Pearsonr&quot;\r\n    \r\n                # calculate average losses\r\n                train_loss = np.mean(train_loss)\r\n                valid_loss = np.mean(valid_loss)\r\n    \r\n                train_losses.append(train_loss)\r\n                valid_losses.append(valid_loss)\r\n    \r\n                # print training/validation statistics\r\n                print(f&#39;----------\\n&#39;\r\n                      f&#39;Epoch {epoch} - completed in {(time.time() - epoch_start):.0f} seconds\\n&#39;\r\n                      f&#39;Training Loss: {train_loss:.6f}\\t Pearson: {train_pearson}\\n&#39;\r\n                      f&#39;Validation loss: {valid_loss:.6f}\\t Pearson: {valid_pearson}&#39;)\r\n    \r\n                # validation loss has decreased\r\n                if valid_loss &lt;= valid_loss_min and train_loss &gt; valid_loss:\r\n                    print(f&#39;!! Validation loss decreased ({valid_loss_min:.6f} --&gt; {valid_loss:.6f}).  Saving model ...&#39;)\r\n                    valid_loss_min = valid_loss\r\n    \r\n                if train_loss &lt;= valid_loss:\r\n                    print(&#39;!! Training loss is lte validation loss. Might be overfitting!&#39;)\r\n    \r\n                # Optimise with scheduler\r\n                if self.scheduler is not None:\r\n                    self.scheduler.step(valid_loss)\r\n    \r\n            print(&#39;Done training...&#39;)\r\n    \r\n        def _train_valid(self, do):\r\n            &quot;&quot;&quot; Do training or validating. &quot;&quot;&quot;\r\n            if do not in (&#39;train&#39;, &#39;valid&#39;):\r\n                raise ValueError(&quot;Use &#39;train&#39; or &#39;valid&#39; for &#39;do&#39;.&quot;)\r\n    \r\n            results = {&#39;predictions&#39;: np.array([]), &#39;targets&#39;: np.array([])}\r\n            losses = np.array([])\r\n    \r\n            self.model = self.model.to(self.device)\r\n            if do == &#39;train&#39;:\r\n                self.model.train()\r\n                torch.set_grad_enabled(True)\r\n            else:\r\n                self.model.eval()\r\n                torch.set_grad_enabled(False)\r\n    \r\n            for batch_idx, data in enumerate(self.dataloaders[do], 1):\r\n                # 1. Data prep\r\n                sentence = data[0]\r\n                target = data[-1]\r\n                curr_batch_size = target.size(0)\r\n    \r\n                # Returns list of tokens, possibly padded @pad@\r\n                sentence = self.prepare_lines(sentence, split_on=&#39; &#39;, min_size=20, max_size=20)\r\n                # Converts tokens into w2v IDs as a Tensor\r\n                sent_w2v_idxs = self.prepare_w2v(sentence)\r\n                # Converts output to Tensor of floats\r\n                target = torch.Tensor(self.prepare_lines(target, cast_to=float))\r\n    \r\n                # Move input to device\r\n                sent_w2v_idxs, target = sent_w2v_idxs.to(self.device), target.to(self.device)\r\n    \r\n                # 2. Predictions\r\n                pred = self.model(curr_batch_size, sentence_input=sent_w2v_idxs)\r\n                loss = self.criterion(pred, target)\r\n    \r\n                # 3. Optimise during training\r\n                if do == &#39;train&#39;:\r\n                    self.optimizer.zero_grad()\r\n                    loss.backward()\r\n                    self.optimizer.step()\r\n    \r\n                # 4. Save results\r\n                pred = pred.detach().cpu().numpy()\r\n                target = target.cpu().numpy()\r\n    \r\n                results[&#39;predictions&#39;] = np.append(results[&#39;predictions&#39;], pred, axis=None)\r\n                results[&#39;targets&#39;] = np.append(results[&#39;targets&#39;], target, axis=None)\r\n                losses = np.append(losses, float(loss))\r\n    \r\n            torch.set_grad_enabled(True)\r\n    \r\n            return losses, results\r\n    \r\n    \r\n    if __name__ == &#39;__main__&#39;:\r\n        HIDDEN_DIM = 200\r\n    \r\n        # Load embeddings from pretrained gensim model\r\n        embed_p = Path(&#39;path-to.w2v_model&#39;).resolve()\r\n        w2v_model = gensim.models.KeyedVectors.load_word2vec_format(str(embed_p))\r\n        # add a padding token with only zeros\r\n        w2v_model.add([&#39;@pad@&#39;], [np.zeros(w2v_model.vectors.shape[1])])\r\n        embed_weights = torch.FloatTensor(w2v_model.vectors)\r\n    \r\n    \r\n        # Text files are used as input. Every line is one datapoint.\r\n        # *.tok.low.*: tokenized (space-separated) sentences\r\n        # *.cross: one floating point number per line, which we are trying to predict\r\n        regr = RegressionRNN(train_files=(r&#39;train.tok.low.en&#39;,\r\n                                          r&#39;train.cross&#39;),\r\n                             dev_files=(r&#39;dev.tok.low.en&#39;,\r\n                                        r&#39;dev.cross&#39;),\r\n                             test_files=(r&#39;test.tok.low.en&#39;,\r\n                                         r&#39;test.cross&#39;))\r\n        regr.w2v_vocab = w2v_model.vocab\r\n        regr.model = RegressorNet(HIDDEN_DIM, embed_weights, drop_prob=0.2)\r\n        regr.criterion = nn.MSELoss()\r\n        regr.optimizer = optim.Adam(list(regr.model.parameters())[0:], lr=0.001)\r\n        regr.scheduler = optim.lr_scheduler.ReduceLROnPlateau(regr.optimizer, &#39;min&#39;, factor=0.1, patience=5, verbose=True)\r\n    \r\n        regr.train(epochs=100)\r\n\r\n\r\n\r\nFor the LazyTextDataset, you can refer to the class below.\r\n\r\n\r\n    from torch.utils.data import Dataset\r\n    \r\n    import linecache\r\n    \r\n    \r\n    class LazyTextDataset(Dataset):\r\n        def __init__(self, paths):\r\n            # labels are in the last path\r\n            self.paths, self.labels_path = paths[:-1], paths[-1]\r\n    \r\n            with open(self.labels_path, encoding=&#39;utf-8&#39;) as fhin:\r\n                lines = 0\r\n                for line in fhin:\r\n                    if line.strip() != &#39;&#39;:\r\n                        lines += 1\r\n    \r\n                self.num_entries = lines\r\n    \r\n        def __getitem__(self, idx):\r\n            data = [linecache.getline(p, idx + 1) for p in self.paths]\r\n            label = linecache.getline(self.labels_path, idx + 1)\r\n    \r\n            return (*data, label)\r\n    \r\n        def __len__(self):\r\n            return self.num_entries\r\n\r\n\r\nAs I wrote before, I am trying to convert a Keras model to PyTorch. The original Keras code does not use an embedding layer, and uses pre-built word2vec vectors per sentence as input. In the model below, there is no embedding layer. The Keras summary looks like this (I don&#39;t have access to the base model setup).\r\n\r\n   ____________________________________________________________________________________________________\r\n    Layer (type)                     Output Shape          Param #     Connected to\r\n    ====================================================================================================\r\n    bidirectional_1 (Bidirectional)  (200, 400)            417600\r\n    ____________________________________________________________________________________________________\r\n    dropout_1 (Dropout)              (200, 800)            0           merge_1[0][0]\r\n    ____________________________________________________________________________________________________\r\n    dense_1 (Dense)                  (200, 1)              801         dropout_1[0][0]\r\n    ====================================================================================================\r\n\r\n\r\nThe issue is that with identical input, the Keras model *works* and gets a +0.5 Pearson correlation between predicted and actual labels. The PyTorch model above, though, does not seem to work at all. To give you an idea, here is the loss (mean squared error) and Pearson (correlation coefficient, p-value) after the first epoch:\r\n\r\n    Epoch 1 - completed in 11 seconds\r\n    Training Loss: 1.684495\t Pearson: (-0.0006077809280690612, 0.8173368901481127)\r\n    Validation loss: 1.708228\t Pearson: (0.017794288315261794, 0.4264098054188664)\r\n\r\nAnd after the 100th epoch:\r\n\r\n    Epoch 100 - completed in 11 seconds\r\n    Training Loss: 1.660194\t Pearson: (0.0020315421756790806, 0.4400929436716754)\r\n    Validation loss: 1.704910\t Pearson: (-0.017288118524826892, 0.4396865964324158)\r\n\r\nThe loss is plotted below (when you look at the Y-axis, you can see the improvements are minimal).\r\n\r\n[![loss plot][1]][1]\r\n\r\nA final indicator that something may be wrong, is that for my 140K lines of input, each epoch only takes 10 seconds on my GTX 1080TI. I feel that his is not much and I would guess that the optimisation is not working/running. I cannot figure out why, though. To issue will probably be in my train loop or the model itself, but I cannot find it.\r\n\r\nAgain, something must be going wrong because:\r\n  - the Keras model *does* perform well;\r\n  - the training speed is &#39;too fast&#39; for 140K sentences\r\n  - almost no improvemnts after training.\r\n\r\nWhat am I missing? The issue is more than likely present in the training loop or in the network structure.\r\n\r\n\r\n  [1]: https://i.sstatic.net/nf0z1.png",
        "accepted_answer_markdown": "__TL;DR__: Use `permute` instead of `view` when swapping axes, see the end of answer to get an intuition about the difference.\r\n\r\n# About RegressorNet (neural network model)\r\n\r\n1. No need to freeze embedding layer if you are using `from_pretrained`. As [documentation](https://pytorch.org/docs/0.4.0/nn.html#torch.nn.Embedding.from_pretrained) states, it __does not__ use gradient updates.\r\n\r\n2. This part:\r\n\r\n        self.w2v_rnode = nn.GRU(embeddings.size(1), hidden_dim, bidirectional=True, dropout=drop_prob)\r\n\r\n and especially `dropout` without providable `num_layers` is totally pointless (as no dropout can be specified with shallow one layer network).\r\n\r\n3. __BUG AND MAIN ISSUE__: in your `forward` function you are using `view` instead of `permute`, here:\r\n\r\n        w2v_out, _ = self.w2v_rnode(embeds.view(-1, batch_size, embeds.size(2)))\r\n\r\n See [this answer](https://stackoverflow.com/questions/51143206/difference-between-tensor-permute-and-tensor-view-in-pytorch) and appropriate documentation for each of those functions and try to use this line instead:\r\n\r\n        w2v_out, _ = self.w2v_rnode(embeds.permute(1, 0, 2))\r\n\r\n You may consider using `batch_first=True` argument during `w2v_rnode` creation, you won&#39;t have to permute indices that way.\r\n\r\n4. Check documentation of [torch.nn.GRU](https://pytorch.org/docs/stable/nn.html#torch.nn.GRU), you are after __last step of the sequence__, not after all of the sequences you have there, so you should be after:\r\n\r\n        _, last_hidden = self.w2v_rnode(embeds.permute(1, 0, 2))\r\n\r\n but I think this part is fine otherwise. \r\n\r\n# Data preparation\r\n\r\nNo offence, but `prepare_lines` is __very unreadable__ and seems pretty hard to maintain as well, not to say spotting an eventual bug (I suppose it lies in here).\r\n\r\nFirst of all, it seems like you are padding manually. __Please don&#39;t do it that way__, use [torch.nn.pad_sequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pad_sequence) to work with batches!\r\n\r\nIn essence, first you encode each word in every sentence as index pointing into embedding (as you seem to do in `prepare_w2v`), after that you use `torch.nn.pad_sequence` and `torch.nn.pack_padded_sequence` __or__ `torch.nn.pack_sequence` if the lines are already sorted by length.\r\n\r\n# Proper batching\r\n\r\nThis part is __very important__ and it seems you are not doing that at all (and likely this is the second error in your implementation).\r\n\r\nPyTorch&#39;s RNN cells take inputs __not as padded tensors__, but as [torch.nn.PackedSequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.PackedSequence) objects. This is an efficient object storing indices which specify __unpadded__ length of each sequence.\r\n\r\nSee more informations on the topic [here](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch), [here](https://gist.github.com/Tushar-N/dfca335e370a2bc3bc79876e6270099e) and in many other blog posts throughout the web.\r\n\r\nFirst sequence in batch __has to be the longest__, and all others have to be provided in the descending length. What follows is:\r\n\r\n 1. You have to sort your batch each time by sequences length __and sort your targets__ in an analogous way __OR__\r\n 2. Sort your batch, push it through the network and __unsort__ it afterwards to match with your targets.\r\n\r\nEither is fine, it&#39;s your call what seems to be more intuitive for you.\r\nWhat I like to do is more or less the following, hope it helps:\r\n\r\n 1. Create unique indices for each word and map each sentence appropriately (you&#39;ve already done it).\r\n 2. Create regular `torch.utils.data.Dataset` object returning single sentence for each __geitem__, where it is returned as a tuple consisting of features (`torch.Tensor`) and labels (single value), seems like you&#39;re doing it as well.\r\n 3. Create custom `collate_fn` for use with [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), which is responsible for sorting and padding each batch in this scenario (+ it returns lengths of each sentence to be passed into neural network).\r\n 4. Using __sorted and padded features__ and __their lengths__ I&#39;m using `torch.nn.pack_sequence` inside neural network&#39;s `forward` method (__do it after embedding!__) to push it through RNN layer.\r\n 5. Depending on the use-case I unpack them using [torch.nn.pad_packed_sequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pad_packed_sequence). In your case, you only care about last hidden state, hence __you don&#39;t have to do that__. If you were using all of the hidden outputs (like is the case with, say, attention networks), you would add this part.\r\n\r\nWhen it comes to the third point, here is a sample implementation of `collate_fn`, you should get the idea:\r\n\r\n    import torch\r\n    \r\n    \r\n    def length_sort(features):\r\n        # Get length of each sentence in batch\r\n        sentences_lengths = torch.tensor(list(map(len, features)))\r\n        # Get indices which sort the sentences based on descending length\r\n        _, sorter = sentences_lengths.sort(descending=True)\r\n        # Pad batch as you have the lengths and sorter saved already\r\n        padded_features = torch.nn.utils.rnn.pad_sequence(features, batch_first=True)\r\n        return padded_features, sentences_lengths, sorter\r\n    \r\n    \r\n    def pad_collate_fn(batch):\r\n        # DataLoader return batch like that unluckily, check it on your own\r\n        features, labels = (\r\n            [element[0] for element in batch],\r\n            [element[1] for element in batch],\r\n        )\r\n        padded_features, sentences_lengths, sorter = length_sort(features)\r\n        # Sort by length features and labels accordingly\r\n        sorted_padded_features, sorted_labels = (\r\n            padded_features[sorter],\r\n            torch.tensor(labels)[sorter],\r\n        )\r\n        return sorted_padded_features, sorted_labels, sentences_lengths\r\n\r\nUse those as `collate_fn` in `DataLoaders` and you should be just about fine (maybe with minor adjustments, so it&#39;s essential you understand the idea standing behind it).\r\n\r\n# Other possible problems and tips\r\n\r\n- __Training loop__: great place for a lot of small errors, you may want to minimalize those by using [PyTorch Ignite](https://github.com/pytorch/ignite). I am having unbelievably hard time going through your Tensorflow-like-Estimator-like-API-like training loop (e.g. `        self.model = self.w2v_vocab = self.criterion = self.optimizer = self.scheduler = None` this). Please, don&#39;t do it this way, separate each task (data creating, data loading, data preparation, model setup, training loop, logging) into it&#39;s own respective module. All in all there is a reason why PyTorch/Keras is more readable and sanity-preserving than Tensorflow.\r\n\r\n- __Make the first row of your embedding equal to vector containg zeros__: By default, [torch.nn.functional.embedding](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.embedding) expects the first row to be used for padding. Hence you should start your unique indexing for each word at 1 __or__ specify an argument `padding_idx` to different value (though I highly discourage this approach, confusing at best).\r\n\r\n__I hope this answer helps you at least a little bit, if something is unclear post a comment below and I&#39;ll try to explain it from a different perspective/more detail.__\r\n\r\n## Some final comments\r\n\r\nThis code __is not reproducible__, nor the question&#39;s specific. We don&#39;t have the data you are using, neither we got your word vectors, random seed is not fixed etc.\r\n\r\nPS. One last thing: Check your performance on __really small subset__ of your data (say 96 examples), if it does not converge, it is very likely you indeed have a bug in your code.\r\n\r\nAbout the times: they are probably off (due to not sorting and not padding I suppose), usually Keras and PyTorch&#39;s times are quite similar (if I understood this part of your question as intended) for correct and efficient implementations.\r\n\r\n# Permute vs view vs reshape explanation\r\n\r\nThis simple example show the differences between `permute()` and `view()`. The first one swaps axes, while the second does not change memory layout, just chunks the array into desired shape (if possible).\r\n\r\n    import torch\r\n    \r\n    a = torch.tensor([[1, 2], [3, 4], [5, 6]])\r\n    \r\n    print(a)\r\n    print(a.permute(1, 0))\r\n    print(a.view(2, 3))\r\n\r\nAnd the output would be:\r\n\r\n    tensor([[1, 2],\r\n            [3, 4],\r\n            [5, 6]])\r\n    tensor([[1, 3, 5],\r\n            [2, 4, 6]])\r\n    tensor([[1, 2, 3],\r\n            [4, 5, 6]])\r\n\r\n`reshape` is almost like `view`, was added for those coming from `numpy`, so it&#39;s easier and more natural for them, but it has one important difference:\r\n\r\n- `view` __never copies data__ and work only on contiguous memory (so after permutation like the one above your data may not be contiguous, hence acces to it might be slower)\r\n- `reshape` __can copy data if needed__, so it would work for non-contiguous arrays as well.\r\n"
    },
    {
        "question_id": "71958197",
        "accepted_answer_id": "71958843",
        "question_title": "UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed",
        "question_markdown": "I am creating Logistic Regression in Pytorch from scratch. But I am facing an issue when I am updating trainable parameters `Weights &amp; biases`. This is my implementation,\r\n\r\n```\r\nclass LogisticRegression():\r\n    \r\n    def __init__(self, n_iter, lr):\r\n        self.n_iter = n_iter\r\n        self.lr = lr\r\n    \r\n    def fit(self, dataset):\r\n        device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)\r\n        n = next(iter(dataset))[0].shape[1]\r\n        self.w = torch.zeros(n, requires_grad=True).to(device)\r\n        self.b = torch.tensor(0., requires_grad=True).to(device)\r\n        \r\n        for i in range(self.n_iter):\r\n            with tqdm(total=len(dataset)) as pbar:\r\n                for x, y in dataset:\r\n                    x = x.to(device)\r\n                    y = y.to(device)\r\n                    y_pred = self.predict(x.float())\r\n                    loss = self.loss(y, y_pred)\r\n                    loss.backward()\r\n                    with torch.no_grad():\r\n                        print(self.w, self.b)\r\n                        self.w -= self.w.grad * self.lr\r\n                        self.b -= self.b.grad * self.lr\r\n                        self.w.grad.zero_()\r\n                        self.b.grad.zero_()\r\n                    pbar.update(1)\r\n            print(f&#39;Epoch: {i} | Loss: {loss}&#39;)\r\n    \r\n    def loss(self, y, y_pred):\r\n        y_pred = torch.clip(y_pred, 1e-7, 1 - 1e-7)\r\n        return -torch.mean(\r\n                y * torch.log(y_pred + 1e-7) + \r\n                (1 - y) * torch.log(1 - y_pred + 1e-7),\r\n            axis=0)\r\n    \r\n    def predict(self, x):\r\n        return self.sigmoid(torch.matmul(x, self.w) + self.b)\r\n    \r\n    def sigmoid(self, x):\r\n        return 1/(1 + torch.exp(-x))\r\n```\r\n\r\nAs you can see when I am fitting the model with a dataset I am initializing Weights and biases with zeroes and set `requires_grad=True` so I can access gradients later. I used the sklearn breast cancer dataset,\r\n\r\n```\r\nX, y = load_breast_cancer(return_X_y=True) # load dataset\r\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # train test split\r\n\r\n# convert all numpy arrays to torch tensor\r\nx_train = torch.tensor(x_train)\r\nx_test = torch.tensor(x_test)\r\ny_train = torch.tensor(y_train)\r\ny_test = torch.tensor(y_test)\r\n\r\n# Making it a Torch dataset then into DataLoader\r\ntrain_dataset = torch.utils.data.TensorDataset(x_train, y_train)\r\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\r\n\r\ntest_dataset = torch.utils.data.TensorDataset(x_test, y_test)\r\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\r\n\r\nlog = LogisticRegression(n_iter=10, lr=0.001)\r\nlog.fit(train_loader)\r\n```\r\n\r\nAs soon as I fit the dataset into Logistic Regression it gives me this error (I have also added one print statement in Logistic regression just before gradient update in which it is clear that it has grad_fn parameter),\r\n\r\n```\r\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;, grad_fn=&lt;ToCopyBackward0&gt;) tensor(0., device=&#39;cuda:0&#39;, grad_fn=&lt;ToCopyBackward0&gt;)\r\n\r\nTypeError: unsupported operand type(s) for *: &#39;NoneType&#39; and &#39;float&#39;\r\n```\r\n\r\nAt the start of this Error, it gives this User warning\r\n\r\n```\r\nUserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won&#39;t be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\r\n```\r\n\r\nI need help to solve the error so the gradient update and the model trains successfully!\r\n",
        "accepted_answer_markdown": "Breast cancer dataset features have big range of possible values, from 0.001 to 1000, and big variances too, so it influence gradients (when gradients become too big it leads to instability and later to NaNs). To overcome such dependence it&#39;s common practice to normalize data after splitting, for example:\r\n\r\n    from sklearn import preprocessing\r\n    from sklearn.datasets import load_breast_cancer\r\n    from sklearn.model_selection import train_test_split \r\n\r\n    X, y = load_breast_cancer(return_X_y=True) # load dataset\r\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # train test split\r\n    \r\n    scaler = preprocessing.StandardScaler().fit(x_train)  # computing mean and variance of train data\r\n    x_train = scaler.transform(x_train) # normalizing train data\r\n    x_test = scaler.transform(x_test)   # normalizing test data based on statistics of train\r\n\r\nSo after that everything should be fine."
    },
    {
        "question_id": "72239086",
        "accepted_answer_id": "72258827",
        "question_title": "pytorch gather failed with sparse_grad=True",
        "question_markdown": "With even very simple example, `backward()` cannot work if `sparse_grad=True`, please see the error below.\r\n\r\nIs this error expected, or I&#39;m using `gather` in a wrong way?\r\n\r\n```python\r\nIn [1]: import torch as th\r\n\r\nIn [2]: x = th.rand((3,3), requires_grad=True)\r\n\r\n# sparse_grad = False, the backward could work as expetecd\r\nIn [3]: th.gather(x @ x, 1, th.LongTensor([[0], [1]]), sparse_grad=False).sum().backward()\r\n\r\n# sparse_grad = True, backward CANNOT work\r\nIn [4]: th.gather(x @ x, 1, th.LongTensor([[0], [1]]), sparse_grad=True).sum().backward()\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n----&gt; 1 th.gather(x @ x, 1, th.LongTensor([[0], [1]]), sparse_grad=True).sum().backward()\r\n\r\n~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)\r\n    305                 create_graph=create_graph,\r\n    306                 inputs=inputs)\r\n--&gt; 307         torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\r\n    308\r\n    309     def register_hook(self, hook):\r\n\r\n~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\r\n    152         retain_graph = create_graph\r\n    153\r\n--&gt; 154     Variable._execution_engine.run_backward(\r\n    155         tensors, grad_tensors_, retain_graph, create_graph, inputs,\r\n    156         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\r\n\r\nRuntimeError: sparse tensors do not have strides\r\n```",
        "accepted_answer_markdown": "I think `torch.gather` does not support sparse operators:\r\n```python\r\ntorch.gather(x, 1, torch.LongTensor([[0], [1]]).to_sparse())\r\n```\r\nResults with:\r\n&gt;     NotImplementedError: Could not run &#39;aten::gather.out&#39; with arguments from the &#39;SparseCPU&#39; backend.\r\n\r\nI think you should open an issue or a feature request on [pytorch&#39;s github][1].\r\n\r\n [1]: https://github.com/pytorch/pytorch/issues/new?assignees=&amp;labels=&amp;template=feature-request.yml"
    },
    {
        "question_id": "72331271",
        "accepted_answer_id": "72331382",
        "question_title": "Matrix 2D on Convolutional Netowrk",
        "question_markdown": "that may be a silly question, but I wanted to use a convolutional neural network in my deep reinforcement learning project and I got a problem I don&#39;t understand.\r\nIn my project I want to insert into network matrix `6x7` which should be equivalent to black and white picture of 6x7 size (42 pixels) right? \r\n\r\n```\r\nclass CNN(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.model = torch.nn.Sequential()\r\n        self.model.add_module(&quot;conv_1&quot;, torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=4, stride = 1))\r\n        self.model.add_module(&quot;relu_1&quot;, torch.nn.ReLU())\r\n        self.model.add_module(&quot;max_pool&quot;, torch.nn.MaxPool2d(2))\r\n        self.model.add_module(&quot;conv_2&quot;, torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=4, stride = 1))\r\n        self.model.add_module(&quot;relu_2&quot;, torch.nn.ReLU())\r\n        self.model.add_module(&quot;flatten&quot;, torch.nn.Flatten())\r\n\r\n        self.model.add_module(&quot;linear&quot;, torch.nn.Linear(in_features=16*16*16, out_features=7))\r\n\r\n    def forward(self, x):\r\n        x = self.model(x)\r\n        return x\r\n```\r\nIn `conv1` `in_channels=1` because I have got only 1 matrix (if it was image recognition that means 1 color). Other `in_channels` and `out_channels` are kind of random until `linear`.  I have no idea where I should insert the size of a matrix, but the final output should be a size of `7` which i typed in `linear`.\r\n\r\nThe error i get is:\r\n\r\n``` \r\nRuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [6, 7]\r\n```",
        "accepted_answer_markdown": "There are a few problems with your code. First, the reason you&#39;re getting that error message is because the CNN is expecting a tensor with shape `(N, Cin, Hin, Win)`, where:\r\n\r\n - `N` is the batch size\r\n - `Cin` is the number of input channels\r\n - `Hin` is the input image pixel height\r\n - `Win` is the input image pixel width\r\n\r\nYou&#39;re only providing the `width` and `height` dimensions. You need to explicitly add a `channels` and `batch` dimension, even if the value of those dimensions is only `1`:\r\n```python\r\nmodel = CNN()\r\n\r\nexample_input = torch.randn(size=(6, 7)) # this is your input image\r\n\r\nprint(example_input.shape) # should be (6, 7)\r\n\r\noutput = model(example_input) # you original error\r\n\r\nexample_input = example_input.unsqueeze(0).unsqueeze(0) # adds batch and channels dimension\r\n\r\nprint(example_input.shape) # should now be (1, 1, 6, 7)\r\n\r\noutput = model(example_input) # no more error!\r\n```\r\n\r\nYou&#39;ll note however, you get a different error now:\r\n```\r\nRuntimeError: Calculated padded input size per channel: (1 x 2). Kernel size: (4 x 4). Kernel size can&#39;t be greater than actual input size\r\n```\r\n\r\nThis is because after the first conv layer, your data is of shape `1x2`, but your kernel size for the second layer is `4`, which makes the operation impossible. An input image of size `6x7` is quite small, either reduce the kernel size to something that works, or use a larger images.\r\n\r\nHere&#39;s a working example:\r\n```python\r\nimport torch\r\nfrom torch import nn\r\n\r\n\r\nclass CNN(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.model = torch.nn.Sequential()\r\n        self.model.add_module(\r\n            &quot;conv_1&quot;,\r\n            torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=1),\r\n        )\r\n        self.model.add_module(&quot;relu_1&quot;, torch.nn.ReLU())\r\n        self.model.add_module(&quot;max_pool&quot;, torch.nn.MaxPool2d(2))\r\n        self.model.add_module(\r\n            &quot;conv_2&quot;,\r\n            torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=2, stride=1),\r\n        )\r\n        self.model.add_module(&quot;relu_2&quot;, torch.nn.ReLU())\r\n        self.model.add_module(&quot;flatten&quot;, torch.nn.Flatten())\r\n\r\n        self.model.add_module(&quot;linear&quot;, torch.nn.Linear(in_features=32, out_features=7))\r\n\r\n    def forward(self, x):\r\n        x = self.model(x)\r\n        return x\r\n\r\n\r\nmodel = CNN()\r\nx = torch.randn(size=(6, 7))\r\nx = x.unsqueeze(0).unsqueeze(0)\r\noutput = model(x)\r\nprint(output.shape) # has shape (1, 7)\r\n```\r\n\r\nNote, I changed the `kernel_size` to 2, and the final linear layer has an input size of `32`. Also, the output has shape `(1, 7)`, the 1 is the batch_size, which in our case was only 1. If you want just the 7 output features, just use `x = torch.squeeze(x)`."
    },
    {
        "question_id": "72724452",
        "accepted_answer_id": "72724755",
        "question_title": "mat1 and mat2 shapes cannot be multiplied (128x4 and 128x64)",
        "question_markdown": "Could not find out why the mat1 from the convolutional network is 128x4 and not 4x128. The following is the convolutional network used:\r\n\r\n    \r\n    model = torch.nn.Sequential(\r\n    torch.nn.Conv2d(2,32,kernel_size=3,padding=1),\r\n    torch.nn.ReLU(),\r\n    torch.nn.MaxPool2d(2,2),\r\n\r\n    torch.nn.Conv2d(32,64,kernel_size=3,padding=1),\r\n    torch.nn.ReLU(),\r\n    torch.nn.MaxPool2d(2,2),\r\n\r\n    torch.nn.Conv2d(64,128,kernel_size=3,padding=1),\r\n    torch.nn.ReLU(),\r\n    torch.nn.MaxPool2d(2,2,padding=1),\r\n    torch.nn.Flatten(),\r\n\r\n    torch.nn.Linear(128, 64),\r\n    torch.nn.ReLU(),\r\n    torch.nn.Linear(64,4)\r\n    )\r\n\r\nThe model training code is as follows:\r\n\r\n    epochs = 1000\r\n    losses = [] #A\r\n    for i in range(epochs): #B\r\n        game = Gridworld(size=size, mode=&#39;static&#39;) #C\r\n        # state_ = game.board.render_np().reshape(1,l1) + np.random.rand(1,l1)/10.0 #D\r\n        state_ = game.board.render_np() + np.random.rand(size,size)/10.0 #D\r\n        state1 = torch.from_numpy(state_).float() #E\r\n        print(state1.shape)\r\n        status = 1 #F\r\n        while(status == 1): #G\r\n            qval = model(state1) #H\r\n            qval_ = qval.data.numpy()\r\n            if (random.random() &lt; epsilon): #I\r\n                action_ = np.random.randint(0,4)\r\n            else:\r\n                action_ = np.argmax(qval_)\r\n           \r\n            action = action_set[action_] #J\r\n            game.makeMove(action) #K\r\n            state2_ = game.board.render_np().reshape(1,l1) + np.random.rand(1,l1)/10.0\r\n            state2 = torch.from_numpy(state2_).float() #L\r\n            reward = game.reward()\r\n            with torch.no_grad():\r\n                newQ = model(state2.reshape(1,l1))\r\n            maxQ = torch.max(newQ) #M\r\n            if reward == -1: #N\r\n                Y = reward + (gamma * maxQ)\r\n            else:\r\n                Y = reward\r\n            Y = torch.Tensor([Y]).detach()\r\n            X = qval.squeeze()[action_] #O\r\n            loss = loss_fn(X, Y) #P\r\n            print(i, loss.item())\r\n            clear_output(wait=True)\r\n            optimizer.zero_grad()\r\n            loss.backward()\r\n            losses.append(loss.item())\r\n            optimizer.step()\r\n            state1 = state2\r\n            if reward != -1: #Q\r\n                status = 0\r\n        if epsilon &gt; 0.1: #R\r\n            epsilon -= (1/epochs)\r\n\r\nThe error log shown is:\r\n\r\n    torch.Size([2, 12, 12])\r\n    ---------------------------------------------------------------------------\r\n    RuntimeError                              Traceback (most recent call last)\r\n    &lt;ipython-input-22-d2f43f09fd01&gt; in &lt;module&gt;()\r\n         74     status = 1 #F\r\n         75     while(status == 1): #G\r\n    ---&gt; 76         qval = model(state1) #H\r\n         77         qval_ = qval.data.numpy()\r\n         78         if (random.random() &lt; epsilon): #I\r\n    \r\n    3 frames\r\n    /usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py in forward(self, input)\r\n        101 \r\n        102     def forward(self, input: Tensor) -&gt; Tensor:\r\n    --&gt; 103         return F.linear(input, self.weight, self.bias)\r\n        104 \r\n        105     def extra_repr(self) -&gt; str:\r\n    \r\n    RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x4 and 128x64)\r\n\r\nmat1 should be the output of the convolutional network after it is flattened, and mat2 is the linear network following it.\r\nAppreciate any help. Thanks!\r\n\r\n\r\n\r\n",
        "accepted_answer_markdown": "Here are the output shapes for each layer\r\n```\r\nConv2d(2,32,kernel_size=3,padding=1)   # 32x12x12\r\nMaxPool2d(2,2)                         # 32x6x6\r\nConv2d(32,64,kernel_size=3,padding=1)  # 64x6x6\r\nMaxPool2d(2,2)                         # 64x3x3\r\nConv2d(64,128,kernel_size=3,padding=1) # 128x3x3\r\nMaxPool2d(2,2,padding=1)               # 128x2x2\r\nFlatten()                              # 128x4\r\n```\r\n\r\nYou&#39;ll need to change the kernel parameters and padding sizes if you wish to obtain an output of a given shape. This [link](https://stackoverflow.com/questions/53580088/calculate-the-output-size-in-convolution-layer) might help in calculating the output shapes after each layer.\r\n\r\nAnother approach is that you could take a transpose of the flattened array and pass it into the Linear layers. You&#39;ll need to add the line in your forward function like below\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass NN(nn.Module):\r\n  def __init__(self):\r\n      super(NN, self).__init__()\r\n      \r\n      self.layer1 = nn.Sequential(\r\n          torch.nn.Conv2d(2,32,kernel_size=3,padding=1),\r\n          torch.nn.ReLU(),\r\n          torch.nn.MaxPool2d(2,2))\r\n\r\n      self.layer2 = nn.Sequential(\r\n          torch.nn.Conv2d(32,64,kernel_size=3,padding=1),\r\n          torch.nn.ReLU(),\r\n          torch.nn.MaxPool2d(2,2))\r\n      \r\n      self.layer3 = nn.Sequential(\r\n          torch.nn.Conv2d(64,128,kernel_size=3,padding=1),\r\n          torch.nn.ReLU(),\r\n          torch.nn.MaxPool2d(2,2,padding=1))\r\n      \r\n      self.flattened_tensor = nn.Flatten()\r\n\r\n      self.linear_layer = nn.Sequential(\r\n          torch.nn.Linear(128, 64),\r\n          torch.nn.ReLU(),\r\n          torch.nn.Linear(64,4)\r\n      )\r\n    \r\n  def forward(self, inp):\r\n    conv_output = self.layer3(self.layer2(self.layer1(inp)))\r\n    flattened_output = self.flattened_tensor(conv_output)\r\n    \r\n    transposed_matrix = torch.transpose(flattened_output, 0, 1)\r\n    \r\n    linear_output = self.linear_layer(transposed_matrix)\r\n    return linear_output\r\n\r\nmodel = NN()\r\noutput = model(arr)\r\n```"
    },
    {
        "question_id": "72808402",
        "accepted_answer_id": "72810743",
        "question_title": "Pytorch identifying batch size as number of channels in Conv2d layer",
        "question_markdown": "I am a total newbie to neural networks using Pytorch to create a VAE model. I&#39;ve used a bit of tensorflow before, but I have no idea what &quot;in_channels&quot; and &quot;out_channels&quot; are, as arguments to nn.Conv2d/nn.Conv1d. \r\n\r\nDisclaimers aside, currently, my model takes in a dataloader with batch size 128 and where each input is a 248 by 46 tensor (so, a 128 x 248 x 46 tensor). \r\n\r\nMy encoder looks like this right now -- I chopped it down so I could focus on where the error was coming from. \r\n\r\n```\r\nclass Encoder(nn.Module):\r\n    def __init__(self, latent_dim):\r\n        super(Encoder, self).__init__()\r\n        self.latent_dim = latent_dim\r\n        self.conv1 = nn.Conv2d(in_channels=248, out_channels=46, kernel_size=(9, 9), stride=(5, 1), padding=(5, 4))\r\n\r\n    def forward(self, x):\r\n        print(x.size())\r\n        x = F.relu(self.conv1(x))\r\n        return x\r\n```\r\n\r\nThe Conv2d layer was meant to reduce the 248 by 46 input into a 50 by 46 tensor. However, I get this error: \r\n\r\n```\r\nRuntimeError: Given groups=1, weight of size [46, 248, 9, 9], expected input[1, 128, 248, 46] to have 248 channels, but got 128 channels instead\r\n```\r\n...even though I print ```x.size()``` and it displays as ```[torch.Size([128, 248, 46])```.\r\n\r\nI am unsure a) why the error shows that the layer is adding on an extra dimension to x, and b) whether I am even understanding channels correctly. Should 46 be the real number of channels? Why doesn&#39;t Pytorch simply request my input size as a tuple or something, like ```in=(248, 46)```? \r\nOr c) if this is an issue with the way I loaded in my data to the model. I have a numpy array ```data``` of shape ```(-1, 248, 46)``` and then started training my model as follows.\r\n```\r\ntensor_data = torch.from_numpy(data)\r\ndataset = TensorDataset(tensor_data, tensor_data)\r\ntrain_dl = DataLoader(dataset, batch_size=128, shuffle=True)\r\n...\r\nfor epoch in range(20):\r\n     for x_train, y_train in train_loader:\r\n          x_train = x_train.to(device).float()\r\n          optimizer.zero_grad()\r\n          x_pred, mu, log_var = vae(x_train)\r\n          bce_loss = train.BCE(y_train, x_pred)\r\n          kl_loss = train.KL(mu, log_var)\r\n          loss = bce_loss + kl_loss\r\n          loss.backward()\r\n          optimizer.step()\r\n```\r\n\r\nAny thoughts appreciated!",
        "accepted_answer_markdown": "In pytorch, `nn.Conv2d` assumes the input (mostly image data) is shaped like: `[B, C_in, H, W]`, where `B` is the batch size, `C_in` is the number of channels, `H` and `W` are the height and width of the image. The output has a similar shape `[B, C_out, H_out, W_out]`. Here, `C_in` and `C_out` are `in_channels` and `out_channels`, respectively. `(H_out, W_out)` is the output image size, which may or may not equal `(H, W)`, depending on the kernel size, the stride and the padding.\r\n\r\nHowever, it is confusing to apply conv2d to reduce `[128, 248, 46]` inputs to `[128, 50, 46]`. Are they image data with height 248 and width 46? If so you can reshape the inputs to `[128, 1, 248, 46]` and use `in_channels = 1` and `out_channels = 1` in conv2d."
    },
    {
        "question_id": "73445876",
        "accepted_answer_id": "73748065",
        "question_title": "ValueError: base_distribution needs to have shape with size at least 6, but got torch.Size([6])",
        "question_markdown": "I have the following architecture for my neural network\r\n\r\n    import torch\r\n    import torch.distributions as pyd\r\n    import toch.nn as nn\r\n    from torch.distributions import transforms as tT\r\n    from torch.distributions.transformed_distribution import TransformedDistribution\r\n     \r\n    LOG_STD_MIN = -5\r\n    LOG_STD_MAX = 0\r\n    class TanhTransform(pyd.transforms.Transform):\r\n        domain = pyd.constraints.real\r\n        codomain = pyd.constraints.interval(-1.0, 1.0)\r\n        bijective = True\r\n        sign = +1\r\n    \r\n        def __init__(self, cache_size=1):\r\n            self.device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)\r\n            super().__init__(cache_size=cache_size)\r\n    \r\n        @staticmethod\r\n        def atanh(x):\r\n            return 0.5 * (x.log1p() - (-x).log1p())\r\n    \r\n        def __eq__(self, other):\r\n            return isinstance(other, TanhTransform)\r\n    \r\n        def _call(self, x):\r\n            return x.tanh()\r\n    \r\n        def _inverse(self, y):\r\n            return self.atanh(y.clamp(-0.99, 0.99))\r\n    \r\n        def log_abs_det_jacobian(self, x, y):\r\n            return 2.0 * (math.log(2.0) - x - F.softplus(-2.0 * x))\r\n    \r\n    def get_spec_means_mags(spec):\r\n      means = (spec.maximum + spec.minimum) / 2.0\r\n      mags = (spec.maximum - spec.minimum) / 2.0\r\n      means = Variable(torch.tensor(means).type(torch.FloatTensor), requires_grad=False)\r\n      mags  = Variable(torch.tensor(mags).type(torch.FloatTensor), requires_grad=False)\r\n      return means, mags\r\n    \r\n    class Split(torch.nn.Module):\r\n        def __init__(self, module, n_parts: int, dim=1):\r\n            super().__init__()\r\n            self._n_parts = n_parts\r\n            self._dim = dim\r\n            self._module = module\r\n    \r\n        def forward(self, inputs):\r\n            output = self._module(inputs)\r\n            if output.ndim==1:\r\n               result=torch.hsplit(output, self._n_parts )\r\n            else:\r\n               chunk_size = output.shape[self._dim] // self._n_parts\r\n               result =torch.split(output, chunk_size, dim=self._dim)\r\n    \r\n            return result\r\n    \r\n    class Network(nn.Module):\r\n      def __init__(\r\n          self,\r\n          state,\r\n          act,\r\n          fc_layer_params=(),\r\n          ):\r\n        super(Network, self).__init__()\r\n        self._act = act\r\n        self._layers = nn.ModuleList()\r\n        for hidden_size in fc_layer_params:\r\n            if len(self._layers)==0:\r\n               self._layers.append(nn.Linear(state.shape[0], hidden_size))\r\n            else:\r\n               self._layers.append(nn.Linear(hidden_size, hidden_size))\r\n            self._layers.append(nn.ReLU())\r\n        output_layer = nn.Linear(hidden_size,self._act.shape[0] * 2)\r\n        self._layers.append(output_layer)\r\n        \r\n        self._act_means, self._act_mags = get_spec_means_mags(\r\n            self._act)\r\n    \r\n    \r\n      def _get_outputs(self, state):\r\n          h = state\r\n          \r\n          for l in nn.Sequential(*(list(self._layers.children())[:-1])):\r\n              h = l(h)\r\n    \r\n          self._mean_logvar_layers = Split(\r\n             self._layers[-1],\r\n             n_parts=2,\r\n          )\r\n          mean, log_std = self._mean_logvar_layers(h)\r\n          \r\n          a_tanh_mode = torch.tanh(mean) * self._action_mags + self._action_means\r\n          log_std = torch.tanh(log_std).to(device=self.device)\r\n          log_std = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (log_std + 1)\r\n          std = torch.exp(log_std)\r\n          a_distribution = TransformedDistribution(\r\n                            base_distribution=Normal(loc=torch.full_like(mean, 0).to(device=self.device), \r\n                                                     scale=torch.full_like(mean, 1).to(device=self.device)), \r\n                            transforms=tT.ComposeTransform([\r\n                                       tT.AffineTransform(loc=self._action_means, scale=self._action_mags, event_dim=mean.shape[-1]), \r\n                                       TanhTransform(),\r\n                                       tT.AffineTransform(loc=mean, scale=std, event_dim=mean.shape[-1])]))\r\n          \r\n          return a_distribution, a_tanh_mode\r\n    \r\n      def get_log_density(self, state, action):\r\n        a_dist, _ = self._get_outputs(state)\r\n        log_density = a_dist.log_prob(action)\r\n        return log_density\r\n      def __call__(self, state):\r\n        a_dist, a_tanh_mode = self._get_outputs(state)\r\n        a_sample = a_dist.sample()\r\n        log_pi_a = a_dist.log_prob(a_sample)\r\n        return a_tanh_mode, a_sample, log_pi_a\r\n\r\nWhen I run my code I get this error message:\r\n\r\n        action = self._a_network(latent_states)[1]\r\n      File &quot;/home/planner_regularizer.py&quot;, line 182, in __call__\r\n        a_dist, a_tanh_mode = self._get_outputs(state.to(device=self.device))\r\n      File &quot;/home/planner_regularizer.py&quot;, line 159, in _get_outputs\r\n        a_distribution = TransformedDistribution(\r\n      File &quot;/home/dm_control/lib/python3.8/site-packages/torch/distributions/transformed_distribution.py&quot;, line 61, in __init__\r\n        raise ValueError(&quot;base_distribution needs to have shape with size at least {}, but got {}.&quot;\r\n    ValueError: base_distribution needs to have shape with size at least 6, but got torch.Size([6]).\r\n\r\nHow can I fix this error message?\r\n\r\n**Update**: if I remove `event_dim` from `AffineTransform`, I wouldn&#39;t get above error but the output of `log_prob` would be size 1 which is not correct. Any suggestion?\r\n\r\n",
        "accepted_answer_markdown": "The error is telling you exactly what the problem is: TransformedDistribution expects the base distribution to have event_shape of at least length 6, but you are passing a Normal distribution with event_shape=[6].\r\nThis minimum length requirement exists because TransformedDistribution applies affine transforms, which require at least 2 dimensions:\r\n\r\n1 for the batch_shape\r\n1 for the event coordinates being transformed\r\n\r\nSimply construct your Normal distribution with more dimensions, e.g.\r\nNormal(loc=torch.zeros(1, 6), scale=torch.ones(1, 6))"
    },
    {
        "question_id": "73532345",
        "accepted_answer_id": "73534098",
        "question_title": "Defining my own gradient function for pytorch to use",
        "question_markdown": "I want to feed pytorch gradients manually. In my real problem, I have my own adjoint function that does not use tensors. Is there any way I can define my own gradient function for pytorch to use during optimization?\r\n\r\n    import numpy as np\r\n    import torch\r\n    \r\n    # define rosenbrock function and gradient\r\n    x0 = np.array([0.1, 0.1])\r\n    a = 1\r\n    b = 5\r\n    def f(x):\r\n       return (a - x[0]) ** 2 + b * (x[1] - x[0] ** 2) ** 2\r\n    \r\n    def jac(x):\r\n       dx1 = -2 * a + 4 * b * x[0] ** 3 - 4 * b * x[0] * x[1] + 2 * x[0]\r\n       dx2 = 2 * b * (x[1] - x[0] ** 2)\r\n       return np.array([dx1, dx2])\r\n    \r\n    # create stochastic rosenbrock function and gradient\r\n    # (the crude analogy is that I have predefined stochastic\r\n    #  forward and backward functions)\r\n    def f_rand(x):\r\n       return f(x) * np.random.uniform(0.5, 1.5)\r\n    \r\n    def jac_rand(x): return jac(x) * np.random.uniform(0.5, 1.5)\r\n    \r\n\r\n    x_tensor = torch.tensor(x0, requires_grad=False)\r\n    optimizer = torch.optim.Adam([x_tensor], lr=0.1)\r\n    \r\n    # here, closure is fed f_rand to compute the gradient.\r\n    # I need to feed closer the gradient directly from jac_rand\r\n    def closure():\r\n       optimizer.zero_grad()\r\n       loss = f_rand(x_tensor)\r\n       loss.backward() # jac_rand(x)\r\n       return loss\r\n    \r\n    for ii in range(200):\r\n       optimizer.step(closure) \r\n    \r\n    print(x_tensor, f(x_tensor))\r\n      # tensor([1.0000, 1.0000], dtype=torch.float64, requires_grad=True) tensor(4.5799e-09, dtype=torch.float64, grad_fn=&lt;AddBackward0&gt;)\r\n      # ( this is the right answer, E[f(1, 1)] = 0 )\r\n\r\n\r\n\r\n\r\n\r\nI&#39;ve tried defining a custom function, but I can&#39;t get it to work. This is my best attempt so far:\r\n\r\n\r\n\r\n    import numpy as np\r\n    import torch\r\n    \r\n    # define rosenbrock function and gradient\r\n    \r\n    x0 = np.array([0.1, 0.1])\r\n    a = 1\r\n    b = 5\r\n    def f(x):\r\n       return (a - x[0]) ** 2 + b * (x[1] - x[0] ** 2) ** 2\r\n    \r\n    def jac(x):\r\n       dx1 = -2 * a + 4 * b * x[0] ** 3 - 4 * b * x[0] * x[1] + 2 * x[0]\r\n       dx2 = 2 * b * (x[1] - x[0] ** 2)\r\n       return np.array([dx1, dx2])\r\n    \r\n    # create stochastic rosenbrock function and gradient\r\n    def f_rand(x):\r\n       return f(x) * np.random.uniform(0.5, 1.5)\r\n    \r\n    def jac_rand(x): return jac(x) * np.random.uniform(0.5, 1.5)\r\n    \r\n    class custom_function(torch.autograd.Function):\r\n    \r\n        @staticmethod\r\n        def forward(ctx, input):\r\n           ctx.save_for_backward(input)\r\n           return f_rand(input)\r\n    \r\n        @staticmethod\r\n        def backward(ctx, grad_output):\r\n            input, = ctx.saved_tensors\r\n            return grad_output * g_rand(input)\r\n    \r\n    x_tensor = torch.tensor(x0, requires_grad=False)\r\n    optimizer = torch.optim.Adam([x_tensor], lr=0.1)\r\n    \r\n    for ii in range(200):\r\n       print(&#39;x_tensor &#39;, x_tensor)\r\n       optimizer.step(custom_function())\r\n    \r\n    print(x_tensor, f(x_tensor))\r\n\r\n\r\nIt says:\r\n\r\n`RuntimeError: Legacy autograd function with non-static forward method\r\nis deprecated. Please use new-style autograd function with static\r\nforward method. (Example:\r\nhttps://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)`",
        "accepted_answer_markdown": "Not quite sure if this is exactly what you want but the method call `loss.backward()` computes gradients via pytorch&#39;s computational graph and stores the gradient values in the weight tensors themselves (in your case it&#39;s in `x_tensor`). And these gradients can be accessed via `x_tensor.grad`. However, if you don&#39;t want to use pytorch&#39;s gradient computing method using `loss.backward()`, then you can manually feed your gradients into your tensor&#39;s `.grad` attribute as follows:\r\n```\r\nwith torch.no_grad():\r\n    def closure():\r\n       optimizer.zero_grad()\r\n       loss = f_rand(x_tensor)\r\n       x_tensor.grad = torch.from_numpy(jac_rand(x_tensor))\r\n       return loss\r\n```"
    },
    {
        "question_id": "73913522",
        "accepted_answer_id": "74061560",
        "question_title": "Why don&#39;t the images align when concatenating two data sets in pytorch using torch.utils.data.ConcatDataset?",
        "question_markdown": "I wanted to concatenate multiple data sets where the labels are disjoint (so don&#39;t share labels). I did:\r\n```\r\nclass ConcatDataset(Dataset):\r\n    &quot;&quot;&quot;\r\n\r\n    ref: https://discuss.pytorch.org/t/concat-image-datasets-with-different-size-and-number-of-channels/36362/12\r\n    &quot;&quot;&quot;\r\n\r\n    def __init__(self, datasets: list[Dataset]):\r\n        &quot;&quot;&quot;\r\n        &quot;&quot;&quot;\r\n        # I think concat is better than passing data to a self.data = x obj since concat likely using the getitem method of the passed dataset and thus if the passed dataset doesnt put all the data in memory concat won&#39;t either\r\n        self.concat_datasets = torch.utils.data.ConcatDataset(datasets)\r\n        # maps a class label to a list of sample indices with that label.\r\n        self.labels_to_indices = defaultdict(list)\r\n        # maps a sample index to its corresponding class label.\r\n        self.indices_to_labels = defaultdict(None)\r\n        # - do the relabeling\r\n        offset: int = 0\r\n        new_idx: int = 0\r\n        for dataset_idx, dataset in enumerate(datasets):\r\n            assert len(dataset) == len(self.concat_datasets.datasets[dataset_idx])\r\n            assert dataset == self.concat_datasets.datasets[dataset_idx]\r\n            for x, y in dataset:\r\n                y = int(y)\r\n                _x, _y = self.concat_datasets[new_idx]\r\n                _y = int(_y)\r\n                # assert y == _y\r\n                assert torch.equal(x, _x)\r\n                new_label = y + offset\r\n                self.indices_to_labels[new_idx] = new_label\r\n                self.labels_to_indices[new_label] = new_idx\r\n            num_labels_for_current_dataset: int = max([y for _, y in dataset])\r\n            offset += num_labels_for_current_dataset\r\n            new_idx += 1\r\n        assert len(self.indices_to_labels.keys()) == len(self.concat_datasets)\r\n        # contains the list of labels from 0 - total num labels after concat\r\n        self.labels = range(offset)\r\n        self.target_transform = lambda data: torch.tensor(data, dtype=torch.int)\r\n\r\n    def __len__(self):\r\n        return len(self.concat_datasets)\r\n\r\n    def __getitem__(self, idx: int) -&gt; tuple[Tensor, Tensor]:\r\n        x = self.concat_datasets[idx]\r\n        y = self.indices_to_labels[idx]\r\n        if self.target_transform is not None:\r\n            y = self.target_transform(y)\r\n        return x, y\r\n```\r\nbut it doesn&#39;t even work to align the x images (so never mind if my relabling works!). Why?\r\n```\r\ndef check_xs_align_cifar100():\r\n    from pathlib import Path\r\n\r\n    root = Path(&quot;~/data/&quot;).expanduser()\r\n    # root = Path(&quot;.&quot;).expanduser()\r\n    train = torchvision.datasets.CIFAR100(root=root, train=True, download=True)\r\n    test = torchvision.datasets.CIFAR100(root=root, train=False, download=True)\r\n\r\n    concat = ConcatDataset([train, test])\r\n    print(f&#39;{len(concat)=}&#39;)\r\n    print(f&#39;{len(concat.labels)=}&#39;)\r\n```\r\nerror\r\n```\r\nFiles already downloaded and verified\r\nFiles already downloaded and verified\r\nTraceback (most recent call last):\r\n  File &quot;/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py&quot;, line 1491, in _exec\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File &quot;/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py&quot;, line 18, in execfile\r\n    exec(compile(contents+&quot;\\n&quot;, file, &#39;exec&#39;), glob, loc)\r\n  File &quot;/Users/brandomiranda/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/dataset/concate_dataset.py&quot;, line 405, in &lt;module&gt;\r\n    check_xs_align()\r\n  File &quot;/Users/brandomiranda/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/dataset/concate_dataset.py&quot;, line 391, in check_xs_align\r\n    concat = ConcatDataset([train, test])\r\n  File &quot;/Users/brandomiranda/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/dataset/concate_dataset.py&quot;, line 71, in __init__\r\n    assert torch.equal(x, _x)\r\nTypeError: equal(): argument &#39;input&#39; (position 1) must be Tensor, not Image\r\npython-BaseException\r\n```\r\n\r\nBonus: let me know if relabeling is correct please.\r\n\r\nrelated discussion: https://discuss.pytorch.org/t/concat-image-datasets-with-different-size-and-number-of-channels/36362/12\r\n\r\n----\r\n\r\n# Edit 1: PIL comparison fails\r\n\r\nI did a PIL image comparison according to https://stackoverflow.com/questions/35176639/compare-images-python-pil but it failed:\r\n```\r\nTraceback (most recent call last):\r\n  File &quot;/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py&quot;, line 1491, in _exec\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File &quot;/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py&quot;, line 18, in execfile\r\n    exec(compile(contents+&quot;\\n&quot;, file, &#39;exec&#39;), glob, loc)\r\n  File &quot;/Users/brandomiranda/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/dataset/concate_dataset.py&quot;, line 419, in &lt;module&gt;\r\n    check_xs_align_cifar100()\r\n  File &quot;/Users/brandomiranda/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/dataset/concate_dataset.py&quot;, line 405, in check_xs_align_cifar100\r\n    concat = ConcatDataset([train, test])\r\n  File &quot;/Users/brandomiranda/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/dataset/concate_dataset.py&quot;, line 78, in __init__\r\n    assert diff.getbbox(), f&#39;comparison of imgs failed: {diff.getbbox()=}&#39;\r\nAssertionError: comparison of imgs failed: diff.getbbox()=None\r\npython-BaseException\r\ndiff\r\nPyDev console: starting.\r\n&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x7FBE897A21C0&gt;\r\n```\r\ncode comparison:\r\n```\r\n                diff = ImageChops.difference(x, _x)  # https://stackoverflow.com/questions/35176639/compare-images-python-pil\r\n                assert diff.getbbox(), f&#39;comparison of imgs failed: {diff.getbbox()=}&#39;\r\n```\r\nthis also failed:\r\n```\r\n    assert list(x.getdata()) == list(_x.getdata()), f&#39;\\n{list(x.getdata())=}, \\n{list(_x.getdata())=}&#39;\r\nAssertionError: ...long msg... \r\n```\r\nassert statement was:\r\n```\r\n                assert list(x.getdata()) == list(_x.getdata()), f&#39;\\n{list(x.getdata())=}, \\n{list(_x.getdata())=}&#39;\r\n\r\n```\r\n\r\n----\r\n\r\n# Edit 2: Tensor comparison Fails\r\n\r\nI tried to convert images to tensors but it still fails:\r\n```\r\nAssertionError: Error for some reason, got: data_idx=1, x.norm()=tensor(45.9401), _x.norm()=tensor(33.9407), x=tensor([[[1.0000, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 1.0000],\r\n```\r\ncode:\r\n```\r\nclass ConcatDataset(Dataset):\r\n    &quot;&quot;&quot;\r\n    ref:\r\n        - https://discuss.pytorch.org/t/concat-image-datasets-with-different-size-and-number-of-channels/36362/12\r\n        - https://stackoverflow.com/questions/73913522/why-dont-the-images-align-when-concatenating-two-data-sets-in-pytorch-using-tor\r\n    &quot;&quot;&quot;\r\n\r\n    def __init__(self, datasets: list[Dataset]):\r\n        &quot;&quot;&quot;\r\n        &quot;&quot;&quot;\r\n        # I think concat is better than passing data to a self.data = x obj since concat likely using the getitem method of the passed dataset and thus if the passed dataset doesnt put all the data in memory concat won&#39;t either\r\n        self.concat_datasets = torch.utils.data.ConcatDataset(datasets)\r\n        # maps a class label to a list of sample indices with that label.\r\n        self.labels_to_indices = defaultdict(list)\r\n        # maps a sample index to its corresponding class label.\r\n        self.indices_to_labels = defaultdict(None)\r\n        # - do the relabeling\r\n        img2tensor: Callable = torchvision.transforms.ToTensor()\r\n        offset: int = 0\r\n        new_idx: int = 0\r\n        for dataset_idx, dataset in enumerate(datasets):\r\n            assert len(dataset) == len(self.concat_datasets.datasets[dataset_idx])\r\n            assert dataset == self.concat_datasets.datasets[dataset_idx]\r\n            for data_idx, (x, y) in enumerate(dataset):\r\n                y = int(y)\r\n                # - get data point from concataned data set (to compare with the data point from the data set list)\r\n                _x, _y = self.concat_datasets[new_idx]\r\n                _y = int(_y)\r\n                # - sanity check concatanted data set aligns with the list of datasets\r\n                # assert y == _y\r\n                # from PIL import ImageChops\r\n                # diff = ImageChops.difference(x, _x)  # https://stackoverflow.com/questions/35176639/compare-images-python-pil\r\n                # assert diff.getbbox(), f&#39;comparison of imgs failed: {diff.getbbox()=}&#39;\r\n                # assert list(x.getdata()) == list(_x.getdata()), f&#39;\\n{list(x.getdata())=}, \\n{list(_x.getdata())=}&#39;\r\n                # tensor comparison\r\n                x, _x = img2tensor(x), img2tensor(_x)\r\n                print(f&#39;{data_idx=}, {x.norm()=}, {_x.norm()=}&#39;)\r\n                assert torch.equal(x, _x), f&#39;Error for some reason, got: {data_idx=}, {x.norm()=}, {_x.norm()=}, {x=}, {_x=}&#39;\r\n                # - relabling\r\n                new_label = y + offset\r\n                self.indices_to_labels[new_idx] = new_label\r\n                self.labels_to_indices[new_label] = new_idx\r\n            num_labels_for_current_dataset: int = max([y for _, y in dataset])\r\n            offset += num_labels_for_current_dataset\r\n            new_idx += 1\r\n        assert len(self.indices_to_labels.keys()) == len(self.concat_datasets)\r\n        # contains the list of labels from 0 - total num labels after concat\r\n        self.labels = range(offset)\r\n        self.target_transform = lambda data: torch.tensor(data, dtype=torch.int)\r\n\r\n    def __len__(self):\r\n        return len(self.concat_datasets)\r\n\r\n    def __getitem__(self, idx: int) -&gt; tuple[Tensor, Tensor]:\r\n        x = self.concat_datasets[idx]\r\n        y = self.indices_to_labels[idx]\r\n        if self.target_transform is not None:\r\n            y = self.target_transform(y)\r\n        return x, y\r\n```\r\n\r\n----\r\n\r\n# Edit 3, clarification request:\r\n\r\nMy vision of the data set I want is a concatenation of a data sets in question -- where relabeling starting the first label commences. The curicial thing (according to me -- might be wrong on this) is that once concatenated we should verify in some way that the data set indeed behaves the way we want it. One check I thought is to index the data point from the list of data sets and also from the concatenation object of the data set. If the data set was correctly conatenated I&#39;d expect the images to be correspond according to this indexing. So if the first image in the first data set had some unique identifier (e.g. the pixels) then the concatenation of the data sets should have the first image be the same as the first image in the list of data sets and so on...if this doesn&#39;t hold, if I start creating new labels -- how do I know I am even doing this correctly?\r\n\r\n----\r\n\r\nreddit link: https://www.reddit.com/r/pytorch/comments/xurnu9/why_dont_the_images_align_when_concatenating_two/\r\n\r\ncross posted pytorch discuss: https://discuss.pytorch.org/t/why-dont-the-images-align-when-concatenating-two-data-sets-in-pytorch-using-torch-utils-data-concatdataset/162801?u=brando_miranda",
        "accepted_answer_markdown": "Corrected code can be found here https://github.com/brando90/ultimate-utils/blob/master/ultimate-utils-proj-src/uutils/torch_uu/dataset/concate_dataset.py you can pip install the library `pip install ultimate-utils`.\r\n\r\nSince only links is not a good way to answer I will copy paste the code too with it&#39;s test and expected output:\r\n```\r\n&quot;&quot;&quot;\r\n\r\ndo checks, loop through all data points, create counts for each label how many data points there are\r\ndo this for MI only\r\n\r\nthen check union and ur implementation?\r\ncompare the mappings of one &amp; the other?\r\n\r\nactually it&#39;s easy, just add the cummulative offset and that&#39;s it. :D the indices are already -1 indexed.\r\n\r\nassert every image has a label between 0 --&gt; n1+n2+... and every bin for each class is none empty\r\n\r\nfor it to work with any standard pytorch data set I think the workflow would be:\r\n```\r\npytorch dataset -&gt; l2l meta data set -&gt; union data set -&gt; .dataset field -&gt; data loader\r\n```\r\nfor l2l data sets:\r\n```\r\nl2l meta data set -&gt; union data set -&gt; .dataset field -&gt; data loader\r\n```\r\nbut the last one might need to make sure .indices or .labels is created or a get labels function that checking the attribute\r\ngets the right .labels or remaps it correctly\r\n&quot;&quot;&quot;\r\nfrom collections import defaultdict\r\nfrom pathlib import Path\r\nfrom typing import Callable, Optional\r\n\r\nimport torch\r\nimport torchvision\r\nfrom torch import Tensor\r\nfrom torch.utils.data import Dataset, DataLoader\r\n\r\n\r\nclass ConcatDatasetMutuallyExclusiveLabels(Dataset):\r\n    &quot;&quot;&quot;\r\n    Useful attributes:\r\n        - self.labels: contains all new USL labels i.e. contains the list of labels from 0 - total num labels after concat.\r\n        - len(self): gives number of images after all images have been concatenated\r\n        - self.indices_to_labels: maps the new concat idx to the new label after concat.\r\n\r\n    ref:\r\n        - https://stackoverflow.com/questions/73913522/why-dont-the-images-align-when-concatenating-two-data-sets-in-pytorch-using-tor\r\n        - https://discuss.pytorch.org/t/concat-image-datasets-with-different-size-and-number-of-channels/36362/12\r\n    &quot;&quot;&quot;\r\n\r\n    def __init__(self, datasets: list[Dataset],\r\n                 transform: Optional[Callable] = None,\r\n                 target_transform: Optional[Callable] = None,\r\n                 compare_imgs_directly: bool = False,\r\n                 verify_xs_align: bool = False,\r\n                 ):\r\n        &quot;&quot;&quot;\r\n        Concatenates different data sets assuming the labels are mutually exclusive in the data sets.\r\n\r\n        compare_imgs_directly: adds the additional test that imgs compare at the PIL imgage level.\r\n        &quot;&quot;&quot;\r\n        self.datasets = datasets\r\n        self.transform = transform\r\n        self.target_transform = target_transform\r\n        # I think concat is better than passing data to a self.data = x obj since concat likely using the getitem method of the passed dataset and thus if the passed dataset doesnt put all the data in memory concat won&#39;t either\r\n        self.concat_datasets = torch.utils.data.ConcatDataset(datasets)\r\n        # maps a class label to a list of sample indices with that label.\r\n        self.labels_to_indices = defaultdict(list)\r\n        # maps a sample index to its corresponding class label.\r\n        self.indices_to_labels = defaultdict(None)\r\n        # - do the relabeling\r\n        self._re_label_all_dataset(datasets, compare_imgs_directly, verify_xs_align)\r\n\r\n    def __len__(self):\r\n        return len(self.concat_datasets)\r\n\r\n    def _re_label_all_dataset(self, datasets: list[Dataset],\r\n                              compare_imgs_directly: bool = False,\r\n                              verify_xs_align: bool = False,\r\n                              ):\r\n        &quot;&quot;&quot;\r\n        Relabels according to a blind (mutually exclusive) assumption.\r\n\r\n        Relabling Algorithm:\r\n        The zero index of the label starts at the number of labels collected so far. So when relabling we do:\r\n            y =  y + total_number_labels\r\n            total_number_labels += max label for current data set\r\n        where total_number_labels always has the + 1 to correct for the zero indexing.\r\n\r\n        :param datasets:\r\n        :param compare_imgs_directly:\r\n        :parm verify_xs_align: set to false by default in case your transforms aren&#39;t deterministic.\r\n        :return:\r\n        &quot;&quot;&quot;\r\n        self.img2tensor: Callable = torchvision.transforms.ToTensor()\r\n        self.int2tensor: Callable = lambda data: torch.tensor(data, dtype=torch.int)\r\n        total_num_labels_so_far: int = 0\r\n        new_idx: int = 0\r\n        for dataset_idx, dataset in enumerate(datasets):\r\n            assert len(dataset) == len(self.concat_datasets.datasets[dataset_idx])\r\n            assert dataset == self.concat_datasets.datasets[dataset_idx]\r\n            for data_idx, (x, y) in enumerate(dataset):\r\n                y = int(y)\r\n                # - get data point from concataned data set (to compare with the data point from the data set list)\r\n                _x, _y = self.concat_datasets[new_idx]\r\n                _y = int(_y)\r\n                # - sanity check concatanted data set aligns with the list of datasets\r\n                assert y == _y\r\n                if compare_imgs_directly:\r\n                    # from PIL import ImageChops\r\n                    # diff = ImageChops.difference(x, _x)  # https://stackoverflow.com/questions/35176639/compare-images-python-pil\r\n                    # assert diff.getbbox(), f&#39;comparison of imgs failed: {diff.getbbox()=}&#39; # doesn&#39;t work :/\r\n                    assert list(x.getdata()) == list(_x.getdata()), f&#39;\\n{list(x.getdata())=}, \\n{list(_x.getdata())=}&#39;\r\n                    # tensor comparison\r\n                if not isinstance(x, Tensor):\r\n                    x, _x = self.img2tensor(x), self.img2tensor(_x)\r\n                if isinstance(y, int):\r\n                    y, _y = self.int2tensor(y), self.int2tensor(_y)\r\n                if verify_xs_align:\r\n                    # this might fails if there are random ops in the getitem\r\n                    assert torch.equal(x,\r\n                                       _x), f&#39;Error for some reason, got: {dataset_idx=},&#39; \\\r\n                                            f&#39; {new_idx=}, {data_idx=}, &#39; \\\r\n                                            f&#39;{x.norm()=}, {_x.norm()=}, &#39; \\\r\n                                            f&#39;{x=}, {_x=}&#39;\r\n                # - relabling\r\n                new_label = y + total_num_labels_so_far\r\n                self.indices_to_labels[new_idx] = new_label\r\n                self.labels_to_indices[new_label].append(new_idx)\r\n                new_idx += 1\r\n            num_labels_for_current_dataset: int = int(max([y for _, y in dataset])) + 1\r\n            # - you&#39;d likely resolve unions if you wanted a proper union, the addition assumes mutual exclusivity\r\n            total_num_labels_so_far += num_labels_for_current_dataset\r\n        assert len(self.indices_to_labels.keys()) == len(self.concat_datasets)\r\n        # contains the list of labels from 0 - total num labels after concat, assume mutually exclusive\r\n        self.labels = range(total_num_labels_so_far)\r\n\r\n    def __getitem__(self, idx: int) -&gt; tuple[Tensor, Tensor]:\r\n        &quot;&quot;&quot;\r\n        Get&#39;s the data point and it&#39;s new label according to a mutually exclusive concatenation.\r\n\r\n        For later?\r\n        to do the relabling on the fly we&#39;d need to figure out which data set idx corresponds to and to compute the\r\n        total_num_labels_so_far. Something like this:\r\n            current_data_set_idx = bisect_left(idx)\r\n            total_num_labels_so_far = sum(max(_, y in dataset)+1 for dataset_idx, dataset in enumerate(self.datasets) if dataset_idx &lt;= current_data_set_idx)\r\n            new_y = total_num_labels_so_far\r\n            self.indices_to_labels[idx] = new_y\r\n        :param idx:\r\n        :return:\r\n        &quot;&quot;&quot;\r\n        x, _y = self.concat_datasets[idx]\r\n        y = self.indices_to_labels[idx]\r\n        # for the first data set they aren&#39;t re-labaled so can&#39;t use assert\r\n        # assert y != _y, f&#39;concat dataset returns x, y so the y is not relabeled, but why are they the same {_y}, {y=}&#39;\r\n        # idk what this is but could be useful? mnist had this.\r\n        # img = Image.fromarray(img.numpy(), mode=&quot;L&quot;)\r\n        if self.transform is not None:\r\n            x = self.transform(x)\r\n        if self.target_transform is not None:\r\n            y = self.target_transform(y)\r\n        return x, y\r\n\r\n\r\ndef assert_dataset_is_pytorch_dataset(datasets: list, verbose: bool = False):\r\n    &quot;&quot;&quot; to do 1 data set wrap it in a list&quot;&quot;&quot;\r\n    for dataset in datasets:\r\n        if verbose:\r\n            print(f&#39;{type(dataset)=}&#39;)\r\n            print(f&#39;{type(dataset.dataset)=}&#39;)\r\n        assert isinstance(dataset, Dataset), f&#39;Expect dataset to be of type Dataset but got {type(dataset)=}.&#39;\r\n\r\n\r\ndef get_relabling_counts(dataset: Dataset) -&gt; dict:\r\n    &quot;&quot;&quot;\r\n    counts[new_label] -&gt; counts/number of data points for that new label\r\n    &quot;&quot;&quot;\r\n    assert isinstance(dataset, Dataset), f&#39;Expect dataset to be of type Dataset but got {type(dataset)=}.&#39;\r\n    counts: dict = {}\r\n    iter_dataset = iter(dataset)\r\n    for datapoint in iter_dataset:\r\n        x, y = datapoint\r\n        # assert isinstance(x, torch.Tensor)\r\n        # assert isinstance(y, int)\r\n        if y not in counts:\r\n            counts[y] = 0\r\n        else:\r\n            counts[y] += 1\r\n    return counts\r\n\r\n\r\ndef assert_relabling_counts(counts: dict, labels: int = 100, counts_per_label: int = 600):\r\n    &quot;&quot;&quot;\r\n    default values are for MI.\r\n\r\n    - checks each label/class has the right number of expected images per class\r\n    - checks the relabels start from 0 and increase by 1\r\n    - checks the total number of labels after concat is what you expect\r\n\r\n    ref: https://openreview.net/pdf?id=rJY0-Kcll\r\n    Because the exact splits used in Vinyals et al. (2016)\r\n    were not released, we create our own version of the Mini-Imagenet dataset by selecting a random\r\n    100 classes from ImageNet and picking 600 examples of each class. We use 64, 16, and 20 classes\r\n    for training, validation and testing, respectively.\r\n    &quot;&quot;&quot;\r\n    # - check each image has the right number of total images\r\n    seen_labels: list[int] = []\r\n    for label, count in counts.items():\r\n        seen_labels.append(label)\r\n        assert counts[label] == counts_per_label\r\n    # - check all labels are there and total is correct\r\n    seen_labels.sort()\r\n    prev_label = -1\r\n    for label in seen_labels:\r\n        diff = label - prev_label\r\n        assert diff == 1\r\n        assert prev_label &lt; label\r\n    # - checks the final label is the total number of labels\r\n    assert label == labels - 1\r\n\r\n\r\ndef check_entire_data_via_the_dataloader(dataloader: DataLoader) -&gt; dict:\r\n    counts: dict = {}\r\n    for it, batch in enumerate(dataloader):\r\n        xs, ys = batch\r\n        for y in ys:\r\n            if y not in counts:\r\n                counts[y] = 0\r\n            else:\r\n                counts[y] += 1\r\n    return counts\r\n\r\n\r\n# - tests\r\n\r\ndef check_xs_align_mnist():\r\n    root = Path(&#39;~/data/&#39;).expanduser()\r\n    import torchvision\r\n    # - test 1, imgs (not the recommended use)\r\n    train = torchvision.datasets.MNIST(root=root, train=True, download=True)\r\n    test = torchvision.datasets.MNIST(root=root, train=False, download=True)\r\n    concat = ConcatDatasetMutuallyExclusiveLabels([train, test], compare_imgs_directly=True)\r\n    print(f&#39;{len(concat)=}&#39;)\r\n    print(f&#39;{len(concat.labels)=}&#39;)\r\n    # - test 2, tensor imgs\r\n    train = torchvision.datasets.MNIST(root=root, train=True, download=True,\r\n                                       transform=torchvision.transforms.ToTensor(),\r\n                                       target_transform=lambda data: torch.tensor(data, dtype=torch.int))\r\n    test = torchvision.datasets.MNIST(root=root, train=False, download=True,\r\n                                      transform=torchvision.transforms.ToTensor(),\r\n                                      target_transform=lambda data: torch.tensor(data, dtype=torch.int))\r\n    concat = ConcatDatasetMutuallyExclusiveLabels([train, test], verify_xs_align=True)\r\n    print(f&#39;{len(concat)=}&#39;)\r\n    print(f&#39;{len(concat.labels)=}&#39;)\r\n    assert len(concat) == 10 * 7000, f&#39;Err, unexpected number of datapoints {len(concat)=} expected {100 * 700}&#39;\r\n    assert len(\r\n        concat.labels) == 20, f&#39;Note it should be 20 (since it is not a true union), but got {len(concat.labels)=}&#39;\r\n\r\n    # - test dataloader\r\n    loader = DataLoader(concat)\r\n    for batch in loader:\r\n        x, y = batch\r\n        assert isinstance(x, torch.Tensor)\r\n        assert isinstance(y, torch.Tensor)\r\n\r\n\r\ndef check_xs_align_cifar100():\r\n    from pathlib import Path\r\n    root = Path(&#39;~/data/&#39;).expanduser()\r\n    import torchvision\r\n    # - test 1, imgs (not the recommended use)\r\n    train = torchvision.datasets.CIFAR100(root=root, train=True, download=True)\r\n    test = torchvision.datasets.CIFAR100(root=root, train=False, download=True)\r\n    concat = ConcatDatasetMutuallyExclusiveLabels([train, test], compare_imgs_directly=True)\r\n    print(f&#39;{len(concat)=}&#39;)\r\n    print(f&#39;{len(concat.labels)=}&#39;)\r\n    # - test 2, tensor imgs\r\n    train = torchvision.datasets.CIFAR100(root=root, train=True, download=True,\r\n                                          transform=torchvision.transforms.ToTensor(),\r\n                                          target_transform=lambda data: torch.tensor(data, dtype=torch.int))\r\n    test = torchvision.datasets.CIFAR100(root=root, train=False, download=True,\r\n                                         transform=torchvision.transforms.ToTensor(),\r\n                                         target_transform=lambda data: torch.tensor(data, dtype=torch.int))\r\n    concat = ConcatDatasetMutuallyExclusiveLabels([train, test], verify_xs_align=True)\r\n    print(f&#39;{len(concat)=}&#39;)\r\n    print(f&#39;{len(concat.labels)=}&#39;)\r\n    assert len(concat) == 100 * 600, f&#39;Err, unexpected number of datapoints {len(concat)=} expected {100 * 600}&#39;\r\n    assert len(\r\n        concat.labels) == 200, f&#39;Note it should be 200 (since it is not a true union), but got {len(concat.labels)=}&#39;\r\n    # details on cifar100: https://www.cs.toronto.edu/~kriz/cifar.html\r\n\r\n    # - test dataloader\r\n    loader = DataLoader(concat)\r\n    for batch in loader:\r\n        x, y = batch\r\n        assert isinstance(x, torch.Tensor)\r\n        assert isinstance(y, torch.Tensor)\r\n\r\n\r\ndef concat_data_set_mi():\r\n    &quot;&quot;&quot;\r\n    note test had to be in MI where train, val, test have disjount/different labels. In cifar100 classic the labels\r\n    in train, val and test are shared from 0-99 instead of being different/disjoint.\r\n    :return:\r\n    &quot;&quot;&quot;\r\n    # - get mi data set\r\n    from diversity_src.dataloaders.hdb1_mi_omniglot_l2l import get_mi_datasets\r\n    train_dataset, validation_dataset, test_dataset = get_mi_datasets()\r\n    assert_dataset_is_pytorch_dataset([train_dataset, validation_dataset, test_dataset])\r\n    train_dataset, validation_dataset, test_dataset = train_dataset.dataset, validation_dataset.dataset, test_dataset.dataset\r\n    # - create usl data set\r\n    union = ConcatDatasetMutuallyExclusiveLabels([train_dataset, validation_dataset, test_dataset])\r\n    # union = ConcatDatasetMutuallyExclusiveLabels([train_dataset, validation_dataset, test_dataset],\r\n    #                                              compare_imgs_directly=True)\r\n    assert_dataset_is_pytorch_dataset([union])\r\n    assert len(union) == 100 * 600, f&#39;got {len(union)=}&#39;\r\n    assert len(union.labels) == 100, f&#39;got {len(union.labels)=}&#39;\r\n\r\n    # - create dataloader\r\n    from uutils.torch_uu.dataloaders.common import get_serial_or_distributed_dataloaders\r\n    union_loader, _ = get_serial_or_distributed_dataloaders(train_dataset=union, val_dataset=union)\r\n    for batch in union_loader:\r\n        x, y = batch\r\n        assert x is not None\r\n        assert y is not None\r\n\r\n\r\nif __name__ == &#39;__main__&#39;:\r\n    import time\r\n    from uutils import report_times\r\n\r\n    start = time.time()\r\n    # - run experiment\r\n    check_xs_align_mnist()\r\n    check_xs_align_cifar100()\r\n    concat_data_set_mi()\r\n    # - Done\r\n    print(f&quot;\\nSuccess Done!: {report_times(start)}\\a&quot;)\r\n\r\n```\r\nexpected correct output:\r\n```\r\nlen(concat)=70000\r\nlen(concat.labels)=20\r\nlen(concat)=70000\r\nlen(concat.labels)=20\r\nFiles already downloaded and verified\r\nFiles already downloaded and verified\r\nlen(concat)=60000\r\nlen(concat.labels)=200\r\nFiles already downloaded and verified\r\nFiles already downloaded and verified\r\nlen(concat)=60000\r\nlen(concat.labels)=200\r\nSuccess Done!: time passed: hours:0.16719497998555502, minutes=10.0316987991333, seconds=601.901927947998\r\n```\r\n\r\nwarning:\r\n&gt; if you have a transform that is random the verification that the data sets align might make it look as if the two data points are not algined. The code is correct so it&#39;s not an issue, but perhaps remove the randomness somehow. Note, I actually decided to not force the user to check all the images of their data set and trust my code works from running once my unit tests. Also note that it&#39;s slow to construct the data set since I do the re-labling at the beginning. Might be better to relabel on the fly. I outlined the code for it on how to do it but decided against it since we always see all the data set at least once so doing this amortized is the same as doing it on the fly (note the fly pseudo-code saves the labels to avoid recomputations).\r\n\r\n----\r\n\r\nThis is better:\r\n```\r\n# int2tensor: Callable = lambda data: torch.tensor(data, dtype=torch.int)\r\nint2tensor: Callable = lambda data: torch.tensor(data, dtype=torch.long)\r\n\r\n\r\nclass ConcatDatasetMutuallyExclusiveLabels(Dataset):\r\n    &quot;&quot;&quot;\r\n    Useful attributes:\r\n        - self.labels: contains all new USL labels i.e. contains the list of labels from 0 - total num labels after concat.\r\n        - len(self): gives number of images after all images have been concatenated\r\n        - self.indices_to_labels: maps the new concat idx to the new label after concat.\r\n\r\n    ref:\r\n        - https://stackoverflow.com/questions/73913522/why-dont-the-images-align-when-concatenating-two-data-sets-in-pytorch-using-tor\r\n        - https://discuss.pytorch.org/t/concat-image-datasets-with-different-size-and-number-of-channels/36362/12\r\n    &quot;&quot;&quot;\r\n\r\n    def __init__(self, datasets: list[Dataset],\r\n                 transform: Optional[Callable] = None,\r\n                 target_transform: Optional[Callable] = None,\r\n                 compare_imgs_directly: bool = False,\r\n                 verify_xs_align: bool = False,\r\n                 ):\r\n        &quot;&quot;&quot;\r\n        Concatenates different data sets assuming the labels are mutually exclusive in the data sets.\r\n\r\n        compare_imgs_directly: adds the additional test that imgs compare at the PIL imgage level.\r\n        &quot;&quot;&quot;\r\n        self.datasets = datasets\r\n        self.transform = transform\r\n        self.target_transform = target_transform\r\n        # I think concat is better than passing data to a self.data = x obj since concat likely using the getitem method of the passed dataset and thus if the passed dataset doesnt put all the data in memory concat won&#39;t either\r\n        self.concat_datasets = torch.utils.data.ConcatDataset(datasets)\r\n        # maps a class label to a list of sample indices with that label.\r\n        self.labels_to_indices = defaultdict(list)\r\n        # maps a sample index to its corresponding class label.\r\n        self.indices_to_labels = defaultdict(None)\r\n        # - do the relabeling\r\n        self._re_label_all_dataset(datasets, compare_imgs_directly, verify_xs_align)\r\n\r\n    def __len__(self):\r\n        return len(self.concat_datasets)\r\n\r\n    def _re_label_all_dataset(self, datasets: list[Dataset],\r\n                              compare_imgs_directly: bool = False,\r\n                              verify_xs_align: bool = False,\r\n                              verbose: bool = False,\r\n                              ):\r\n        &quot;&quot;&quot;\r\n        Relabels according to a blind (mutually exclusive) assumption.\r\n\r\n        Relabling Algorithm:\r\n        The zero index of the label starts at the number of labels collected so far. So when relabling we do:\r\n            y =  y + total_number_labels\r\n            total_number_labels += max label for current data set\r\n        where total_number_labels always has the + 1 to correct for the zero indexing.\r\n\r\n        assumption: it re-lables the data points to have a concatenation of all the labels. If there are rebeated labels\r\n        they are treated as different. So if dataset1 and dataset2 both have cats (represented as indices), then they\r\n        will get unique integers representing these. So the cats are treated as entirely different labels.\r\n        &quot;&quot;&quot;\r\n        print()\r\n        self.img2tensor: Callable = torchvision.transforms.ToTensor()\r\n        total_num_labels_so_far: int = 0\r\n        global_idx: int = 0  # new_idx\r\n        assert len(self.indices_to_labels.keys()) == 0\r\n        assert len(self.labels_to_indices.keys()) == 0\r\n        for dataset_idx, dataset in enumerate(datasets):\r\n            print(f&#39;{dataset_idx=} \\n{len(dataset)=}&#39;)\r\n            if hasattr(dataset, &#39;labels&#39;):\r\n                print(f&#39;{len(dataset.labels)=}&#39;)\r\n            assert len(dataset) == len(self.concat_datasets.datasets[dataset_idx])\r\n            assert dataset == self.concat_datasets.datasets[dataset_idx]\r\n            original_label2global_idx: defaultdict = defaultdict(list)\r\n            for original_data_idx, (x, original_y) in enumerate(dataset):\r\n                original_y = int(original_y)\r\n                # - get data point from concataned data set (to compare with the data point from the data set list)\r\n                _x, _y = self.concat_datasets[global_idx]\r\n                _y = int(_y)\r\n                # - sanity check concatanted data set aligns with the list of datasets\r\n                assert original_y == _y, f&#39;{original_y=}, {_y=}&#39;\r\n                if compare_imgs_directly:\r\n                    # from PIL import ImageChops\r\n                    # diff = ImageChops.difference(x, _x)  # https://stackoverflow.com/questions/35176639/compare-images-python-pil\r\n                    # assert diff.getbbox(), f&#39;comparison of imgs failed: {diff.getbbox()=}&#39; # doesn&#39;t work :/\r\n                    assert list(x.getdata()) == list(_x.getdata()), f&#39;\\n{list(x.getdata())=}, \\n{list(_x.getdata())=}&#39;\r\n                # - tensor comparison of raw images\r\n                if not isinstance(x, Tensor):\r\n                    x, _x = self.img2tensor(x), self.img2tensor(_x)\r\n                # if isinstance(original_y, int):\r\n                #     original_y, _y = int2tensor(original_y), int2tensor(_y)\r\n                if verify_xs_align:  # checks the data points after doing get item make them match.\r\n                    # this might fails if there are random ops in the getitem\r\n                    assert torch.equal(x,\r\n                                       _x), f&#39;Error for some reason, got: {dataset_idx=},&#39; \\\r\n                                            f&#39; {global_idx=}, {original_data_idx=}, &#39; \\\r\n                                            f&#39;{x.norm()=}, {_x.norm()=}, &#39; \\\r\n                                            f&#39;{x=}, {_x=}&#39;\r\n                # - collect original labels in dictionary keys\r\n                original_label2global_idx[int(original_y)].append(global_idx)\r\n                global_idx += 1\r\n            print(f&#39;{global_idx=}&#39;)\r\n            local_num_dps: int = sum(len(global_indices) for global_indices in original_label2global_idx.values())\r\n            assert len(dataset) == local_num_dps, f&#39;Error: \\n{local_num_dps=} \\n{len(dataset)=}&#39;\r\n            # - do relabeling - original labeling to new global labels\r\n            print(f&#39;{total_num_labels_so_far=}&#39;)\r\n            assert total_num_labels_so_far != len(dataset), f&#39;Err:\\n{total_num_labels_so_far=}\\n{len(dataset)=}&#39;\r\n            new_local_label2global_indices: dict = {}\r\n            global_label2global_indices: dict = {}\r\n            # make sure to sort to avoid random looping of unordered data structures e.g. keys in a dict\r\n            for new_local_label, original_label in enumerate(sorted(original_label2global_idx.keys())):\r\n                global_indices: list[int] = original_label2global_idx[original_label]\r\n                new_local_label2global_indices[int(new_local_label)] = global_indices\r\n                new_global_label: int = total_num_labels_so_far + new_local_label\r\n                global_label2global_indices[int(new_global_label)] = global_indices\r\n            local_num_dps: int = sum(len(global_indices) for global_indices in original_label2global_idx.values())\r\n            assert len(dataset) == local_num_dps, f&#39;Error: \\n{local_num_dps=} \\n{len(dataset)=}&#39;\r\n            local_num_dps: int = sum(len(global_indices) for global_indices in new_local_label2global_indices.values())\r\n            assert len(dataset) == local_num_dps, f&#39;Error: \\n{local_num_dps=} \\n{len(dataset)=}&#39;\r\n            local_num_dps: int = sum(len(global_indices) for global_indices in global_label2global_indices.values())\r\n            assert len(dataset) == local_num_dps, f&#39;Error: \\n{local_num_dps=} \\n{len(dataset)=}&#39;\r\n            # - this assumes the integers in each data set is different, if there were unions you&#39;d likely need semantic information about the label e.g. the string cat instead of absolute integers, or know the integers are shared between the two data sets\r\n            print(f&#39;{total_num_labels_so_far=}&#39;)\r\n            # this is the step where classes are concatenated. Note due to the previous loops assuming each label is uning this should never have intersecting keys.\r\n            print(f&#39;{list(self.labels_to_indices.keys())=}&#39;)\r\n            print(f&#39;{list(global_label2global_indices.keys())=}&#39;)\r\n            dup: list = get_duplicates(list(self.labels_to_indices.keys()) + list(global_label2global_indices.keys()))\r\n            print(f&#39;{list(self.labels_to_indices.keys())=}&#39;)\r\n            print(f&#39;{list(global_label2global_indices.keys())=}&#39;)\r\n            assert len(dup) == 0, f&#39;Error:\\n{self.labels_to_indices.keys()=}\\n{global_label2global_indices.keys()=}\\n{dup=}&#39;\r\n            for global_label, global_indices in global_label2global_indices.items():\r\n                # note g_idx might different to global_idx!\r\n                global_indices: list[int]\r\n                for g_idx in global_indices:\r\n                    self.labels_to_indices[int(global_label)] = g_idx\r\n                    self.indices_to_labels[g_idx] = int(global_label)\r\n            # - update number of labels seen so far\r\n            num_labels_for_current_dataset: int = len(original_label2global_idx.keys())\r\n            print(f&#39;{num_labels_for_current_dataset=}&#39;)\r\n            total_num_labels_so_far += num_labels_for_current_dataset\r\n            assert total_num_labels_so_far == len(self.labels_to_indices.keys()), f&#39;Err:\\n{total_num_labels_so_far=}&#39; \\\r\n                                                                                  f&#39;\\n{len(self.labels_to_indices.keys())=}&#39;\r\n            assert global_idx == len(self.indices_to_labels.keys()), f&#39;Err:\\n{global_idx=}\\n{len(self.indices_to_labels.keys())=}&#39;\r\n            if hasattr(dataset, &#39;labels&#39;):\r\n                assert len(dataset.labels) == num_labels_for_current_dataset, f&#39;Err:\\n{len(dataset.labels)=}&#39; \\\r\n                                                                              f&#39;\\n{num_labels_for_current_dataset=}&#39;\r\n        # - relabling done\r\n        assert len(self.indices_to_labels.keys()) == len(\r\n            self.concat_datasets), f&#39;Err: \\n{len(self.indices_to_labels.keys())=}&#39; \\\r\n                                   f&#39;\\n {len(self.concat_datasets)=}&#39;\r\n        if all(hasattr(dataset, &#39;labels&#39;) for dataset in datasets):\r\n            assert sum(len(dataset.labels) for dataset in datasets) == total_num_labels_so_far\r\n        # contains the list of labels from 0 - total num labels after concat, assume mutually exclusive\r\n        # - set &amp; validate new labels\r\n        self.labels = range(total_num_labels_so_far)\r\n        labels = list(sorted(list(self.labels_to_indices.keys())))\r\n        assert labels == list(labels), f&#39;labels should match and be consecutive, but got: \\n{labels=}, \\n{self.labels=}&#39;\r\n\r\n    def __getitem__(self, idx: int) -&gt; tuple[Tensor, Tensor]:\r\n        &quot;&quot;&quot;\r\n        Get&#39;s the data point and it&#39;s new label according to a mutually exclusive concatenation.\r\n\r\n        For later?\r\n        to do the relabling on the fly we&#39;d need to figure out which data set idx corresponds to and to compute the\r\n        total_num_labels_so_far. Something like this:\r\n            current_data_set_idx = bisect_left(idx)\r\n            total_num_labels_so_far = sum(max(_, y in dataset)+1 for dataset_idx, dataset in enumerate(self.datasets) if dataset_idx &lt;= current_data_set_idx)\r\n            new_y = total_num_labels_so_far + y\r\n            self.indices_to_labels[idx] = new_y\r\n        :param idx:\r\n        :return:\r\n        &quot;&quot;&quot;\r\n        x, _y = self.concat_datasets[idx]\r\n        y = self.indices_to_labels[idx]\r\n        # for the first data set they aren&#39;t re-labaled so can&#39;t use assert\r\n        # assert y != _y, f&#39;concat dataset returns x, y so the y is not relabeled, but why are they the same {_y}, {y=}&#39;\r\n        # idk what this is but could be useful? mnist had this.\r\n        # img = Image.fromarray(img.numpy(), mode=&quot;L&quot;)\r\n        if self.transform is not None:\r\n            x = self.transform(x)\r\n        if self.target_transform is not None:\r\n            y = self.target_transform(y)\r\n        return x, y\r\n```"
    },
    {
        "question_id": "74014379",
        "accepted_answer_id": "74021554",
        "question_title": "How to fine-tune gpt-j using Huggingface Trainer",
        "question_markdown": "I&#39;m attempting to fine-tune gpt-j using the huggingface trainer and failing miserably. I followed the example that references bert, but of course, the gpt-j model isn&#39;t exactly like the bert model. \r\n\r\nThe error indicates that the model isn&#39;t producing a loss, which is great, except that I have no idea how to make it generate a loss or how to change what the trainer is expecting.\r\n\r\nI&#39;m using Transformers 4.22.2. I would like to get this working on a CPU before I try to do anything on Paperspace with a GPU. I did make an initial attempt there using a GPU that received the same error, with slightly different code to use cuda.\r\n\r\nI suspect that my approach is entirely wrong. I found a very old example of fine-tuning gpt-j using 8-bit quantization, but even that repository says it is deprecated.\r\n\r\nI&#39;m unsure if my mistake is in using the compute_metrics() I found in the bert example or if it is something else. Any advice would be appreciated. Or, maybe it is an issue with the labels I provide the config, but I&#39;ve tried different permutations.\r\n\r\nI understand what a loss function is, but I don&#39;t know how it is supposed to be configured in this case.\r\n\r\nMy Code:\r\n```\r\nfrom transformers import Trainer, TrainingArguments, AutoModelForCausalLM\r\nfrom transformers import GPTJForCausalLM, AutoTokenizer\r\nfrom datasets import load_dataset\r\nimport time\r\nimport torch\r\nimport os\r\nimport numpy as np\r\nimport evaluate\r\nimport sklearn\r\n\r\nstart = time.time()\r\n\r\nGPTJ_FINE_TUNED_FILE = &quot;./fine_tuned_models/gpt-j-6B&quot;\r\n\r\nprint(&quot;Loading model&quot;)\r\nmodel = GPTJForCausalLM.from_pretrained(&quot;EleutherAI/gpt-j-6B&quot;, low_cpu_mem_usage=True)\r\nmodel.config.pad_token_id = model.config.eos_token_id\r\n\r\nprint(&quot;Loading tokenizer&quot;)\r\ntokenizer = AutoTokenizer.from_pretrained(&quot;EleutherAI/gpt-j-6B&quot;)\r\ntokenizer.pad_token = tokenizer.eos_token\r\n\r\nprint(&quot;Loading dataset&quot;)\r\ncurrent_dataset = load_dataset(&quot;wikitext&quot;, &#39;wikitext-103-v1&#39;)\r\ncurrent_dataset[&#39;train&#39;] = current_dataset[&#39;train&#39;].select(range(1200))\r\n\r\n\r\ndef tokenize_function(examples):\r\n    current_tokenizer_result = tokenizer(examples[&quot;text&quot;], padding=&quot;max_length&quot;, truncation=True)\r\n    return current_tokenizer_result\r\n\r\n\r\nprint(&quot;Splitting and tokenizing dataset&quot;)\r\ntokenized_datasets = current_dataset.map(tokenize_function, batched=True)\r\nsmall_train_dataset = tokenized_datasets[&quot;train&quot;].select(range(100))\r\n\r\nprint(&quot;Preparing training arguments&quot;)\r\n\r\ntraining_args = TrainingArguments(output_dir=GPTJ_FINE_TUNED_FILE,\r\n                                  report_to=&#39;all&#39;,\r\n                                  logging_dir=&#39;./logs&#39;,\r\n                                  per_device_train_batch_size=1,\r\n                                  label_names=[&#39;input_ids&#39;, &#39;attention_mask&#39;],  # &#39;logits&#39;, &#39;past_key_values&#39;\r\n                                  num_train_epochs=1,\r\n                                  no_cuda=True\r\n                                  )\r\n\r\nmetric = evaluate.load(&quot;accuracy&quot;)\r\n\r\n\r\ndef compute_metrics(eval_pred):\r\n    logits, labels = eval_pred\r\n    predictions = np.argmax(logits, axis=-1)\r\n    return metric.compute(predictions=predictions, references=labels)\r\n\r\n\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=small_train_dataset\r\n)\r\n\r\nprint(&quot;Starting training&quot;)\r\ntrainer.train()\r\nprint(f&quot;Finished fine-tuning in {time.time() - start}&quot;)\r\n```\r\n\r\nWhich leads to the error and stacktrace:\r\n```\r\n  File &quot;xxx\\ft_v3.py&quot;, line 66, in &lt;module&gt;\r\n  File &quot;xxx\\venv\\lib\\site-packages\\transformers\\trainer.py&quot;, line 1521, in train\r\n    return inner_training_loop(\r\n  File &quot;xxx\\venv\\lib\\site-packages\\transformers\\trainer.py&quot;, line 1763, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model, inputs)\r\n  File &quot;xxx\\venv\\lib\\site-packages\\transformers\\trainer.py&quot;, line 2499, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\n  File &quot;xxx\\venv\\lib\\site-packages\\transformers\\trainer.py&quot;, line 2544, in compute_loss\r\n    raise ValueError(\r\nValueError: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.\r\n```",
        "accepted_answer_markdown": "I found what appears to work, though now I&#39;m running low on memory and working through ways of handling it.\r\n\r\nThe data_collator parameter seems to take care of the exact issue that I was having.\r\n\r\n\r\n```\r\ndata_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\r\n\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=small_train_dataset,\r\n    eval_dataset=small_eval_dataset,\r\n    compute_metrics=compute_metrics,\r\n    data_collator=data_collator,\r\n)\r\n```"
    },
    {
        "question_id": "74261921",
        "accepted_answer_id": "74261922",
        "question_title": "ImportError: libtinfo.so.5: cannot open shared object file: No such file or directory",
        "question_markdown": "On an Ubuntu-based system, I got this error that I didn&#39;t have before in an existing FastAI Python project.\r\n\r\nTraceback:\r\n```\r\nTraceback (most recent call last):\r\n  File &quot;/home/me/PycharmProjects/project/model/predict.py&quot;, line 6, in &lt;module&gt;\r\n    from fastai.vision.all import *\r\n  File &quot;/home/me/miniconda3/envs/venv/lib/python3.9/site-packages/fastai/vision/all.py&quot;, line 1, in &lt;module&gt;\r\n    from . import models\r\n  File &quot;/home/me/miniconda3/envs/venv/lib/python3.9/site-packages/fastai/vision/models/__init__.py&quot;, line 1, in &lt;module&gt;\r\n    from . import xresnet\r\n  File &quot;/home/me/miniconda3/envs/venv/lib/python3.9/site-packages/fastai/vision/models/xresnet.py&quot;, line 17, in &lt;module&gt;\r\n    from ...torch_basics import *\r\n  File &quot;/home/me/miniconda3/envs/venv/lib/python3.9/site-packages/fastai/torch_basics.py&quot;, line 1, in &lt;module&gt;\r\n    from torch import multiprocessing\r\n  File &quot;/home/me/miniconda3/envs/venv/lib/python3.9/site-packages/torch/__init__.py&quot;, line 190, in &lt;module&gt;\r\n    from torch._C import *\r\nImportError: libtinfo.so.5: cannot open shared object file: No such file or directory\r\n```",
        "accepted_answer_markdown": "Terminal:\r\n```\r\nsudo apt-get install libtinfo5\r\n```"
    },
    {
        "question_id": "75102134",
        "accepted_answer_id": "76474507",
        "question_title": "mat1 and mat2 must have the same dtype",
        "question_markdown": "I&#39;m trying to build a neural network to predict per-capita-income for counties in US based on the education level of their citizens.\r\nX and y have the same dtype (I have checked this) but I&#39;m getting an error.\r\nHere is my data:\r\n```\r\n   county_FIPS state          county  per_capita_personal_income_2019  \\\r\n0        51013    VA   Arlington, VA                            97629   \r\n\r\n   per_capita_personal_income_2020  per_capita_personal_income_2021  \\\r\n0                           100687                           107603    \r\n\r\n   associate_degree_numbers_2016_2020  bachelor_degree_numbers_2016_2020  \\\r\n0                               19573                             132394   \r\n \r\n```\r\nAnd here is my network\r\n```\r\nimport torch\r\nimport pandas as pd\r\ndf = pd.read_csv(&quot;./input/US counties - education vs per capita personal income - results-20221227-213216.csv&quot;)\r\nX = torch.tensor(df[[&quot;bachelor_degree_numbers_2016_2020&quot;, &quot;associate_degree_numbers_2016_2020&quot;]].values)\r\ny = torch.tensor(df[&quot;per_capita_personal_income_2020&quot;].values)\r\n\r\nX.dtype\r\ntorch.int64\r\n\r\ny.dtype\r\ntorch.int64\r\n\r\nimport torch.nn as nn\r\nclass BaseNet(nn.Module):\r\n    def __init__(self, in_dim, hidden_dim, out_dim):\r\n        super(BaseNet, self).__init__()\r\n        self.classifier = nn.Sequential(\r\n        nn.Linear(in_dim, hidden_dim, bias=True), \r\n        nn.ReLU(), \r\n        nn.Linear(feature_dim, out_dim, bias=True))\r\n        \r\n    def forward(self, x): \r\n        return self.classifier(x)\r\n\r\nfrom torch import optim\r\nimport matplotlib.pyplot as plt\r\nin_dim, hidden_dim, out_dim = 2, 20, 1\r\nlr = 1e-3\r\nepochs = 40\r\nloss_fn = nn.CrossEntropyLoss()\r\nclassifier = BaseNet(in_dim, hidden_dim, out_dim)\r\noptimizer = optim.SGD(classifier.parameters(), lr=lr)\r\n\r\ndef train(classifier, optimizer, epochs, loss_fn):\r\n    classifier.train()\r\n    losses = []\r\n    for epoch in range(epochs):\r\n        out = classifier(X)\r\n        loss = loss_fn(out, y)\r\n        loss.backward()\r\n        optimizer.step()\r\n        optimizer.zero_grad()\r\n        losses.append(loss/len(X))\r\n        print(&quot;Epoch {} train loss: {}&quot;.format(epoch+1, loss/len(X)))\r\n    \r\n    plt.plot([i for i in range(1, epochs + 1)])\r\n    plt.xlabel(&quot;Epoch&quot;)\r\n    plt.ylabel(&quot;Training Loss&quot;)\r\n    plt.show()\r\n\r\ntrain(classifier, optimizer, epochs, loss_fn)\r\n```\r\nHere is the full stack trace of the error that I am getting when I try to train the network:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nInput In [77], in &lt;cell line: 39&gt;()\r\n     36     plt.ylabel(&quot;Training Loss&quot;)\r\n     37     plt.show()\r\n---&gt; 39 train(classifier, optimizer, epochs, loss_fn)\r\n\r\nInput In [77], in train(classifier, optimizer, epochs, loss_fn)\r\n     24 losses = []\r\n     25 for epoch in range(epochs):\r\n---&gt; 26     out = classifier(X)\r\n     27     loss = loss_fn(out, y)\r\n     28     loss.backward()\r\n\r\nFile ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194, in Module._call_impl(self, *input, **kwargs)\r\n   1190 # If we don&#39;t have any hooks, we want to skip the rest of the logic in\r\n   1191 # this function, and just call forward.\r\n   1192 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1193         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-&gt; 1194     return forward_call(*input, **kwargs)\r\n   1195 # Do not call functions when jit is used\r\n   1196 full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\nInput In [77], in BaseNet.forward(self, x)\r\n     10 def forward(self, x): \r\n---&gt; 11     return self.classifier(x)\r\n\r\nFile ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194, in Module._call_impl(self, *input, **kwargs)\r\n   1190 # If we don&#39;t have any hooks, we want to skip the rest of the logic in\r\n   1191 # this function, and just call forward.\r\n   1192 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1193         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-&gt; 1194     return forward_call(*input, **kwargs)\r\n   1195 # Do not call functions when jit is used\r\n   1196 full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\nFile ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:204, in Sequential.forward(self, input)\r\n    202 def forward(self, input):\r\n    203     for module in self:\r\n--&gt; 204         input = module(input)\r\n    205     return input\r\n\r\nFile ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194, in Module._call_impl(self, *input, **kwargs)\r\n   1190 # If we don&#39;t have any hooks, we want to skip the rest of the logic in\r\n   1191 # this function, and just call forward.\r\n   1192 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1193         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-&gt; 1194     return forward_call(*input, **kwargs)\r\n   1195 # Do not call functions when jit is used\r\n   1196 full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\nFile ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114, in Linear.forward(self, input)\r\n    113 def forward(self, input: Tensor) -&gt; Tensor:\r\n--&gt; 114     return F.linear(input, self.weight, self.bias)\r\n\r\nRuntimeError: mat1 and mat2 must have the same dtype\r\n```\r\n\r\nUpdates\r\n==============\r\n\r\nI have tried casting X and y to float tensors but this comes up with the following error: `expected scalar type Long but found Float`. If someone who knows PyTorch could try running this notebook for themselves that would be a great help. I&#39;m struggling to get off the ground with Kaggle and ML.",
        "accepted_answer_markdown": "The reason for this is because the parameters dtype of `nn.Linear` doesn&#39;t match your input&#39;s dtype; the default dtype for `nn.Linear` is `torch.float32` which is in your case different from your input data - `float64`.\r\n\r\nThe solution to [this question](https://stackoverflow.com/questions/67456368/pytorch-getting-runtimeerror-found-dtype-double-but-expected-float) solves your problem and explains why @Anonymous answer works.\r\n\r\nIn short, add `self.double()` at the end of your constructor and things should run."
    },
    {
        "question_id": "75117132",
        "accepted_answer_id": "75117214",
        "question_title": "TypeError: No loop matching the specified signature and casting was found for ufunc greater",
        "question_markdown": "I&#39;m a beginner to python and machine learning. When I ran the train.py of a project based on the yolov5 (The link of the project is https://github.com/DocF/multispectral-object-detection), I get below error:\r\n\r\n&gt; Traceback (most recent call last):\r\n&gt; File &quot;E:\\0_Final_Project\\GithubProject\\multispectral-object-detection-main\\train.py&quot;, line 1010, in &lt;module&gt;\r\n&gt; train_rgb_ir(hyp, opt, device, tb_writer)\r\n&gt; File &quot;E:\\0_Final_Project\\GithubProject\\multispectral-object-detection-main\\train.py&quot;, line 647, in train_rgb_ir\r\n&gt; tb_writer.add_histogram(&#39;classes&#39;, c, 0)\r\n&gt; File &quot;C:\\Users\\hzji1127\\.conda\\envs\\multispectral-object-detection\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py&quot;, line 485, in add_histogram\r\n&gt; histogram(tag, values, bins, max_bins=max_bins), global_step, walltime\r\n&gt; File &quot;C:\\Users\\hzji1127\\.conda\\envs\\multispectral-object-detection\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py&quot;, line 358, in histogram\r\n&gt; hist = make_histogram(values.astype(float), bins, max_bins)\r\n&gt; File &quot;C:\\Users\\hzji1127\\.conda\\envs\\multispectral-object-detection\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py&quot;, line 386, in make_histogram\r\n&gt; cum_counts = np.cumsum(np.greater(counts, 0, dtype=np.int32))\r\n&gt; TypeError: No loop matching the specified signature and casting was found for ufunc greater\r\n\r\nRelated code:\r\n\r\n```python\r\ndef make_histogram(values, bins, max_bins=None):\r\n    &quot;&quot;&quot;Convert values into a histogram proto using logic from histogram.cc.&quot;&quot;&quot;\r\n    if values.size == 0:\r\n        raise ValueError(&quot;The input has no element.&quot;)\r\n    values = values.reshape(-1)\r\n    counts, limits = np.histogram(values, bins=bins)\r\n    num_bins = len(counts)\r\n    if max_bins is not None and num_bins &gt; max_bins:\r\n        subsampling = num_bins // max_bins\r\n        subsampling_remainder = num_bins % subsampling\r\n        if subsampling_remainder != 0:\r\n            counts = np.pad(\r\n                counts,\r\n                pad_width=[[0, subsampling - subsampling_remainder]],\r\n                mode=&quot;constant&quot;,\r\n                constant_values=0,\r\n            )\r\n        counts = counts.reshape(-1, subsampling).sum(axis=-1)\r\n        new_limits = np.empty((counts.size + 1,), limits.dtype)\r\n        new_limits[:-1] = limits[:-1:subsampling]\r\n        new_limits[-1] = limits[-1]\r\n        limits = new_limits\r\n\r\n    # Find the first and the last bin defining the support of the histogram:\r\n    cum_counts = np.cumsum(np.greater(counts, 0, dtype=np.int32))\r\n    start, end = np.searchsorted(cum_counts, [0, cum_counts[-1] - 1], side=&quot;right&quot;)\r\n    start = int(start)\r\n    end = int(end) + 1\r\n    del cum_counts\r\n\r\n    # TensorBoard only includes the right bin limits. To still have the leftmost limit\r\n    # included, we include an empty bin left.\r\n    # If start == 0, we need to add an empty one left, otherwise we can just include the bin left to the\r\n    # first nonzero-count bin:\r\n    counts = (\r\n        counts[start - 1 : end] if start &gt; 0 else np.concatenate([[0], counts[:end]])\r\n    )\r\n    limits = limits[start : end + 1]\r\n\r\n    if counts.size == 0 or limits.size == 0:\r\n        raise ValueError(&quot;The histogram is empty, please file a bug report.&quot;)\r\n\r\n    sum_sq = values.dot(values)\r\n    return HistogramProto(\r\n        min=values.min(),\r\n        max=values.max(),\r\n        num=len(values),\r\n        sum=values.sum(),\r\n        sum_squares=sum_sq,\r\n        bucket_limit=limits.tolist(),\r\n        bucket=counts.tolist(),\r\n    )\r\n```\r\n\r\n\r\nI have looked up on the stackoverflow and google, but I couldn&#39;t find anything helpful to solve this issue.\r\nPlease help! Thanks",
        "accepted_answer_markdown": "Try with:\r\n```\r\ncum_counts = np.cumsum(np.greater(counts, 0))\r\n```"
    },
    {
        "question_id": "54928638",
        "accepted_answer_id": "54936925",
        "question_title": "Pytorch CNN error: Expected input batch_size (4) to match target batch_size (64)",
        "question_markdown": "I&#39;ve been teaching myself this since November and any help on this would be really appreciated, thank you for looking, as I seem to be going round in circles. I am trying to use a Pytorch CNN example that was used with the Mnist dataset. Now I am trying to modify the CNN for facial key point recognition.  I am using the Kaggle dataset (CSV) of 7048 training images and key points (15 key points per face) and 1783 test images.  I split training dataset and converted the images to jpeg, made separate file for the key points (shape 15, 2). I have made dataset and data loader and can iterate through and display images and plot key points. When I run the CNN I am getting this error.\r\n\r\n    &gt; Net(\r\n      (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\r\n      (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\r\n      (conv2_drop): Dropout2d(p=0.5)\r\n      (fc1): Linear(in_features=589824, out_features=100, bias=True)\r\n      (fc2): Linear(in_features=100, out_features=30, bias=True)\r\n    )\r\n    Data and target shape:  torch.Size([64, 96, 96])   torch.Size([64, 15, 2])\r\n    Data and target shape:  torch.Size([64, 1, 96, 96])   torch.Size([64, 15, 2])\r\n\r\n    Traceback (most recent call last):\r\n      File &quot;/home/keith/PycharmProjects/FacialLandMarks/WorkOut.py&quot;, line 416, in &lt;module&gt;\r\n        main()\r\n      File &quot;/home/keith/PycharmProjects/FacialLandMarks/WorkOut.py&quot;, line 412, in main\r\n        train(args, model, device, train_loader, optimizer, epoch)\r\n      File &quot;/home/keith/PycharmProjects/FacialLandMarks/WorkOut.py&quot;, line 324, in train\r\n        loss = F.nll_loss(output, target)\r\n      File &quot;/home/keith/Desktop/PycharmProjects/fkp/FacialLandMarks/lib/python3.6/site-packages/torch/nn/functional.py&quot;, line 1788, in nll_loss\r\n        .format(input.size(0), target.size(0)))\r\n    ValueError: Expected input batch_size (4) to match target batch_size (64).\r\n    \r\n    Process finished with exit code 1\r\n\r\nHere are some links I have read, I could not figure out the problem\r\nbut may help some one else.\r\n\r\n&gt; &gt; \r\nhttps://github.com/pytorch/pytorch/issues/11762\r\n    https://stackoverflow.com/questions/53875372/how-do-i-modify-this- \r\n        pytorch-convolutional-neural-network-to-accept-a-64-x-64-im\r\n    https://stackoverflow.com/questions/52178922/pytorch-validating- \r\n        model-error-expected-input-batch-size-3-to-match-target-ba\r\n\r\nHere is my code:\r\n\r\n        class Net(nn.Module):\r\n        def __init__(self):\r\n            super(Net, self).__init__()\r\n            self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=(2, 2))\r\n            self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=(2, 2))\r\n            self.conv2_drop = nn.Dropout2d()\r\n            self.fc1 = nn.Linear(64 * 96 * 96, 100)\r\n            self.fc2 = nn.Linear(100, 30)  # 30 is x and y key points\r\n    \r\n        def forward(self, x):\r\n            x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\r\n            x = x.view(-1, 64 * 96 * 96)\r\n            # x = x.view(x.size(0), -1)\r\n            # x = x.view(x.size()[0], 30, -1)\r\n            x = F.relu(self.fc1(x))\r\n            x = F.dropout(x, training=self.training)\r\n            x = self.fc2(x)\r\n            return F.log_softmax(x, dim=1)\r\n    \r\n    \r\n    def train(args, model, device, train_loader, optimizer, epoch):\r\n        model.train()\r\n        for batch_idx, batch in enumerate(train_loader):\r\n            data = batch[&#39;image&#39;]\r\n            target = batch[&#39;key_points&#39;]\r\n            print(&#39;Data and target shape: &#39;, data.shape, &#39; &#39;, target.shape)\r\n            data, target = data.to(device), target.to(device)\r\n            optimizer.zero_grad()\r\n            data = data.unsqueeze(1).float()\r\n    \r\n            print(&#39;Data and target shape: &#39;, data.shape, &#39; &#39;, target.shape)\r\n    \r\n            output = model(data)\r\n            loss = F.nll_loss(output, target)\r\n            loss.backward()\r\n            optimizer.step()\r\n            if batch_idx % args.log_interval == 0:\r\n                print(&#39;Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}&#39;.format(\r\n                    epoch, batch_idx * len(data), len(train_loader.dataset),\r\n                    100. * batch_idx / len(train_loader), loss.item()))\r\n    \r\n    \r\n    # def test(args, model, device, test_loader):\r\n    #     model.eval()\r\n    #     test_loss = 0\r\n    #     correct = 0\r\n    #     with torch.no_grad():\r\n    #         for data, target in test_loader:\r\n    #             data, target = data.to(device), target.to(device)\r\n    #             output = model(data)\r\n    #             test_loss += F.nll_loss(output, target, reduction=&#39;sum&#39;).item() # sum up batch loss\r\n    #             pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\r\n    #             correct += pred.eq(target.view_as(pred)).sum().item()\r\n    #\r\n    #     test_loss /= len(test_loader.dataset)\r\n    #     print(&#39;\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n&#39;.format(\r\n    #         test_loss, correct, len(test_loader.dataset),\r\n    #         100. * correct / len(test_loader.dataset)))\r\n    \r\n    \r\n    \r\n    def main():\r\n        # Training settings\r\n        parser = argparse.ArgumentParser(description=&#39;Project&#39;)\r\n        parser.add_argument(&#39;--batch-size&#39;, type=int, default=64, metavar=&#39;N&#39;,\r\n                            help=&#39;input batch size for training (default: 64)&#39;)\r\n        parser.add_argument(&#39;--test-batch-size&#39;, type=int, default=1000, metavar=&#39;N&#39;,\r\n                            help=&#39;input batch size for testing (default: 1000)&#39;)\r\n        parser.add_argument(&#39;--epochs&#39;, type=int, default=10, metavar=&#39;N&#39;,   # ========  epoch\r\n                            help=&#39;number of epochs to train (default: 10)&#39;)\r\n        parser.add_argument(&#39;--lr&#39;, type=float, default=0.01, metavar=&#39;LR&#39;,\r\n                            help=&#39;learning rate (default: 0.01)&#39;)\r\n        parser.add_argument(&#39;--momentum&#39;, type=float, default=0.5, metavar=&#39;M&#39;,\r\n                            help=&#39;SGD momentum (default: 0.5)&#39;)\r\n        parser.add_argument(&#39;--no-cuda&#39;, action=&#39;store_true&#39;, default=False,\r\n                            help=&#39;disables CUDA training&#39;)\r\n        parser.add_argument(&#39;--seed&#39;, type=int, default=1, metavar=&#39;S&#39;,\r\n                            help=&#39;random seed (default: 1)&#39;)\r\n        parser.add_argument(&#39;--log-interval&#39;, type=int, default=10, metavar=&#39;N&#39;,\r\n                            help=&#39;how many batches to wait before logging training status&#39;)\r\n        args = parser.parse_args()\r\n        use_cuda = not args.no_cuda and torch.cuda.is_available()\r\n    \r\n        torch.manual_seed(args.seed)\r\n    \r\n        device = torch.device(&quot;cuda&quot; if use_cuda else &quot;cpu&quot;)\r\n    \r\n        kwargs = {&#39;num_workers&#39;: 1, &#39;pin_memory&#39;: True} if use_cuda else {}\r\n        train_data_set = FaceKeyPointDataSet(csv_file=&#39;faces/Kep_points_and_id.csv&#39;,\r\n                                             root_dir=&#39;faces/&#39;,\r\n                                             transform=transforms.Compose([\r\n                                                 # Rescale(96),\r\n                                                 ToTensor()\r\n                                             ]))\r\n    \r\n        train_loader = DataLoader(train_data_set, batch_size=args.batch_size,\r\n                                  shuffle=True)\r\n    \r\n        print(&#39;Number of samples: &#39;, len(train_data_set))\r\n        print(&#39;Number of train_loader: &#39;, len(train_loader))\r\n    \r\n        model = Net().to(device)\r\n        print(model)\r\n        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\r\n    \r\n        for epoch in range(1, args.epochs + 1):\r\n            train(args, model, device, train_loader, optimizer, epoch)\r\n            # test(args, model, device, test_loader)\r\n    \r\n    if __name__ == &#39;__main__&#39;:\r\n        main()\r\n\r\n",
        "accepted_answer_markdown": "to understand what went wrong you can print shape after every step in forward : \r\n\r\n    # Input data\r\n    torch.Size([64, 1, 96, 96])\r\n    x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n    torch.Size([64, 32, 48, 48])\r\n    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\r\n    torch.Size([64, 64, 24, 24])\r\n    x = x.view(-1, 64 * 96 * 96)\r\n    torch.Size([4, 589824])\r\n    x = F.relu(self.fc1(x))\r\n    torch.Size([4, 100])\r\n    x = F.dropout(x, training=self.training)\r\n    torch.Size([4, 100])\r\n    x = self.fc2(x)\r\n    torch.Size([4, 30])\r\n    return F.log_softmax(x, dim=1)    \r\n    torch.Size([4, 30])\r\n\r\n - Your `maxpool2d` layers reduce the height and width of your feature maps.\r\n - The &#39;view&#39; should be `x = x.view(-1, 64 * 24 * 24)`  \r\n - the first linear layer of size : `self.fc1 = nn.Linear(64 * 24 * 24, 100)`\r\n\r\nthis will give your `output = model(data)` final shape of `torch.Size([64, 30])`\r\n\r\n\r\nBut this code will still face a problem in calculating the Negative Log Likelihood Loss : \r\n\r\n&gt; The input is expected to contain scores for each class. input has to\r\n&gt; be a 2D Tensor of size (minibatch, C). This criterion expects a class\r\n&gt; index (0 to C-1) as the target for each value of a 1D tensor of size\r\n&gt; minibatch\r\n\r\nwhere class indices are just labels : \r\n\r\n&gt; values representing a class. For example:\r\n&gt; \r\n&gt; 0 - class0,  1 - class1,\r\n\r\nSince your last nn layer outputs a softmax over 30 classes, i&#39;m assuming that is the output classes you want to classify into, \r\nso transformation for target : \r\n\r\n    target = target.view(64, -1) # gives 64X30 ie, 30 values per channel\r\n    loss = F.nll_loss(x, torch.max(t, 1)[1]) # takes max amongst the 30 values as class label\r\n\r\nThis is when the target is a probability distribution over 30 classes, if not can do a soft-max before that. Thus the maximum value in the 30 values will represent the highest probability - thus that class which is exactly what your output represents and thus you calculate a nll between the two values. . \r\n "
    },
    {
        "question_id": "54999926",
        "accepted_answer_id": "55002849",
        "question_title": "Pytorch TypeError: eq() received an invalid combination of arguments",
        "question_markdown": "    num_samples = 10\r\n    def predict(x):\r\n        sampled_models = [guide(None, None) for _ in range(num_samples)]\r\n        yhats = [model(x).data for model in sampled_models]\r\n        mean = torch.mean(torch.stack(yhats), 0)\r\n        return np.argmax(mean.numpy(), axis=1)\r\n    \r\n    print(&#39;Prediction when network is forced to predict&#39;)\r\n    correct = 0\r\n    total = 0\r\n    for j, data in enumerate(test_loader):\r\n        images, labels = data\r\n        predicted = predict(images.view(-1,28*28))\r\n        total += labels.size(0)\r\n        correct += (predicted == labels).sum().item()\r\n    print(&quot;accuracy: %d %%&quot; % (100 * correct / total))\r\n    \r\n    \r\n    \r\n**Error**:\r\n   \r\n\r\n&gt;     correct += (predicted == labels).sum().item() TypeError: \r\n&gt;     eq() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:  \r\n&gt;     * (Tensor other)\r\n&gt;       didn&#39;t match because some of the arguments have invalid types: (!numpy.ndarray!)\r\n&gt;     * (Number other)\r\n&gt;       didn&#39;t match because some of the arguments have invalid types: (!numpy.ndarray!)\r\n\r\n*",
        "accepted_answer_markdown": "You are trying to compare `predicted` and `labels`. However, your `predicted` is an `np.array` while `labels` is a `torch.tensor` therefore `eq()` (the `==` operator) cannot compare between them.  \r\nReplace the `np.argmax` with [`torch.argmax`][1]:\r\n\r\n     return torch.argmax(mean, dim=1)\r\n\r\nAnd you should be okay.\r\n\r\n [1]: https://pytorch.org/docs/0.4.1/torch.html#torch.argmax"
    },
    {
        "question_id": "55145561",
        "accepted_answer_id": "55149434",
        "question_title": "Implementation of VGG16 on Pytorch giving size mismatch error",
        "question_markdown": "Snippet of my code implementation on PyTorch is:\r\n\r\n    model = models.vgg16(pretrained = False)\r\n    classifier = nn.Sequential(\r\n            nn.Linear(25088, 128),\r\n            nn.ReLU(True),\r\n            nn.Dropout(),\r\n            nn.Linear(128, 128),\r\n            nn.ReLU(True),\r\n            nn.Dropout(),\r\n            nn.Linear(128, 20)\r\n    )\r\n    model.classifier = classifier\r\nI&#39;m feeding images of input size (60x60x3) and batch_size = 30.\r\n\r\nWhen I run the code from Linux (Ubuntu) Terminal (with PyTorch Version:  1.0.0, Torchvision Version:  0.2.1) it gives me, the following *error message*:\r\n\r\n&gt; RuntimeError: size mismatch, m1: [30 x 512], m2: [25088 x 128]\r\n\r\nWhile, when I run it from Spyder (Anaconda) on Windows (with PyTorch Version:  1.0.1, Torchvision Version:  0.2.2), *it runs perfectly*. \r\n\r\nAm I missing something or is this because of some version mismatch in Pytorch and Torchvision? Both, I&#39;m running on Python 3.6. \r\nPlease suggest.\r\n\r\n[**UPDATE**: Mistakenly interchanged the version numbers for the error-case and error-free case. Thanks @Manoj Mohan for pointing it out]",
        "accepted_answer_markdown": "It&#39;s probably the other way around. Things run perfectly on torchvision 0.2.2 and fails on torch vision 0.2.1. \r\n\r\nThis change of using AdaptiveAvgPool2d that went into 0.2.2 is why you don&#39;t see the error. https://github.com/pytorch/vision/commit/83b2dfb2ebcd1b0694d46e3006ca96183c303706\r\n\r\n    &gt;&gt;&gt; import torch\r\n    &gt;&gt;&gt; model = models.vgg16(pretrained = False)\r\n    &gt;&gt;&gt; x = torch.randn(1,3,60,60) # random image\r\n    &gt;&gt;&gt; feat = model.features(x)\r\n    &gt;&gt;&gt; flat_feat = feat.view(feat.size(0), -1) # flatten\r\n    &gt;&gt;&gt; flat_feat.shape\r\n    torch.Size([1, 512])\r\n    &gt;&gt;&gt; model.classifier(flat_feat)\r\n\r\nRuntimeError: size mismatch, m1: [1 x 512], m2: [25088 x 4096] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:940\r\n\r\nYou see the error of size mismatch. After, adaptive average pooling, things work fine. \r\n\r\n    &gt;&gt;&gt; import torch.nn.functional as F\r\n    &gt;&gt;&gt; avg = F.adaptive_avg_pool2d(feat, (7,7))\r\n    &gt;&gt;&gt; avg = avg.view(avg.size(0), -1)\r\n    &gt;&gt;&gt; output = model.classifier(avg)\r\n    &gt;&gt;&gt; output.shape\r\n    torch.Size([1, 1000])\r\n"
    },
    {
        "question_id": "55156877",
        "accepted_answer_id": "55374951",
        "question_title": "How to pass parameters to forward function of my torch nn.module from skorch.NeuralNetClassifier.fit()",
        "question_markdown": "I have extended `nn.Module` to implement my network whose forward function is like this ...\r\n\r\n    def forward(self, X, **kwargs):\r\n\r\n        batch_size, seq_len = X.size()\r\n\r\n        length = kwargs[&#39;length&#39;]\r\n        embedded = self.embedding(X) # [batch_size, seq_len, embedding_dim]\r\n        if self.use_padding:\r\n            if length is None:\r\n                raise AttributeError(&quot;Length must be a tensor when using padding&quot;)\r\n            embedded = nn.utils.rnn.pack_padded_sequence(embedded, length, batch_first=True)\r\n            #print(&quot;Size of Embedded packed&quot;, embedded[0].size())\r\n\r\n        \r\n        hidden, cell = self.init_hidden(batch_size)\r\n        if self.rnn_unit == &#39;rnn&#39;:\r\n            out, _ = self.rnn(embedded, hidden)\r\n        elif self.rnn_unit == &#39;lstm&#39;:\r\n            out, (hidden, cell) = self.rnn(embedded, (hidden, cell))\r\n\r\n        \r\n        # unpack if padding was used\r\n        if self.use_padding:\r\n            out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first = True)\r\n\r\n\r\nI initialized a skorch `NeuralNetClassifier` like this,\r\n\r\n\r\n    net = NeuralNetClassifier(\r\n        model,\r\n        criterion=nn.CrossEntropyLoss,\r\n        optimizer=Adam, \r\n        max_epochs=8, \r\n        lr=0.01, \r\n        batch_size=32\r\n    )\r\n\r\nNow if I call `net.fit(X, y, length=X_len)` it throws an error \r\n\r\n    TypeError: __call__() got an unexpected keyword argument &#39;length&#39;\r\n\r\nAccording to the documentation fit function expects a `fit_params` dictionary,\r\n\r\n&gt;     **fit_params : dict\r\n&gt;        Additional parameters passed to the ``forward`` method of\r\n&gt;        the module and to the ``self.train_split`` call.\r\n \r\nand the source code always send my parameters to `train_split` where obviously my keyword argument would not be recognized.\r\n\r\nIs there any way around to pass the arguments to my forward function?",
        "accepted_answer_markdown": "The `fit_params` parameter is intended for passing information that is relevant to data splits and the model alike, like split groups.\r\n\r\nIn your case, you are passing additional *data* to the module via `fit_params` which is not what it is intended for. In fact, you could easily run into trouble doing this if you, for example, enable batch shuffling on the train data loader since then your lengths and your data are misaligned.\r\n\r\nThe best way to do this is already described in the [answer to your question on the issue tracker][1]:\r\n\r\n    X_dict = {&#39;X&#39;: X, &#39;length&#39;: X_len}\r\n    net.fit(X_dict, y)\r\n\r\nSince skorch supports `dict`s you can simply add the length&#39;s to your input dict and have it both passed to the module, nicely batched and passed through the same data loader. In your module you can then access it via the parameters in `forward`:\r\n\r\n    def forward(self, X, length):\r\n         return ...\r\n\r\nFurther documentation of this behaviour can be found [in the docs][2]. \r\n\r\n[1]: https://github.com/skorch-dev/skorch/issues/444#issuecomment-473042801\r\n[2]: https://skorch.readthedocs.io/en/stable/user/dataset.html#id1"
    },
    {
        "question_id": "55268726",
        "accepted_answer_id": "55274292",
        "question_title": "Pytorch - why does preallocating memory cause &quot;trying to backward through the graph a second time&quot;",
        "question_markdown": "Suppose I have a simple one-hidden-layer network that I&#39;m training in the typical way:\r\n\r\n\r\n        for x,y in trainData:\r\n            optimizer.zero_grad()\r\n            out = self(x)\r\n            loss = self.lossfn(out, y)\r\n            loss.backward()\r\n            optimizer.step() \r\n\r\nThis works as expected, but if I instead pre-allocate and update the output array, I get an error:\r\n\r\n        out = torch.empty_like(trainData.tensors[1])\r\n        for i,(x,y) in enumerate(trainData):\r\n            optimizer.zero_grad()\r\n            out[i] = self(x)\r\n            loss = self.lossfn(out[i], y)\r\n            loss.backward()\r\n            optimizer.step()  \r\n\r\n   \r\n\r\n&gt; RuntimeError: Trying to backward through the graph a second time, but\r\n&gt; the buffers have already been freed. Specify retain_graph=True when\r\n&gt; calling backward the first time.\r\n\r\nWhat&#39;s happening here that in the second version Pytorch attempts to backward through the graph again? Why is this not an issue in the first version? (Note that this error occurs even if I don&#39;t `zero_grad()`)",
        "accepted_answer_markdown": "The error implies that the program is trying to backpropagate through a set of operations a second time. The first time you backpropagate through a set of operations, pytorch deletes the computational graph to free memory. Therefore, the second time you try to backpropagate it fails as the graph has already been deleted.\r\n \r\n[Here&#39;s](https://stackoverflow.com/questions/46774641/what-does-the-parameter-retain-graph-mean-in-the-variables-backward-method) a detailed explanation of the same.\r\n\r\n## Short answer\r\nUse `loss.backward(retain_graph=True)`. This will not delete the computational graph.\r\n\r\n## Detailed answer\r\nIn the first version, in each loop iteration, a new computational graph is generated every time `out = self(x)` is run. \r\n```\r\nEvery loop&#39;s graph\r\nout = self(x) -&gt; loss = self.lossfn(out, y)\r\n```\r\nIn the second version, since `out` is declared outside the loop, the computational graphs in every loop have a parent node outside.\r\n\r\n```\r\n           - out[i] = self(x) -&gt; loss = self.lossfn(out[i], y) \r\nout[i] - | - out[i] = self(x) -&gt; loss = self.lossfn(out[i], y) \r\n           - out[i] = self(x) -&gt; loss = self.lossfn(out[i], y)\r\n```\r\nTherefore, here&#39;s a timeline of what happens.\r\n\r\n1. The first iteration runs\r\n1. The computation graph is deleted including the parent node\r\n1. The second iteration attempts to backpropagate but failed since it didn&#39;t find the the parent node\r\n\r\n"
    },
    {
        "question_id": "55278566",
        "accepted_answer_id": "55279230",
        "question_title": "RuntimeError: Expected object of backend CUDA but got backend CPU for argument: ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())",
        "question_markdown": "When the `forward` function of my neural network (after the training phase is completed) is being executed, I&#39;m experiencing `RuntimeError: Expected object of backend CUDA but got backend CPU for argument #4 &#39;mat1&#39;.` The error trace indicates the error happens due to the call of `output = self.layer1(x)` command. I have tried to move all the data of the tensors to my GPU. It seems I miss something to be moved as well.\r\n\r\n**Here is the code I have tried:**\r\n\r\n    use_cuda = torch.cuda.is_available()\r\n    device = torch.device(&#39;cuda:0&#39; if use_cuda else &#39;cpu&#39;)\r\n    \r\n    class NeuralNet(nn.Module):\r\n    \r\n        def __init__(self, input_size, hidden_size, output_size):\r\n            super(NeuralNet, self).__init__()\r\n            self.layer1 = nn.Linear(input_size, hidden_size).cuda(device)\r\n            self.layer2 = nn.Linear(hidden_size, output_size).cuda(device)\r\n            self.relu = nn.ReLU().cuda(device)\r\n    \r\n        def forward(self, x):\r\n            x.cuda(device)\r\n            output = self.layer1(x)  # throws the error\r\n            output = self.relu(output)\r\n            output = self.layer2(output)\r\n            return output\r\n    \r\n    \r\n    def main():\r\n        transform = transforms.Compose([\r\n            transforms.ToTensor()\r\n        ])\r\n    \r\n        mnist_trainset = datasets.MNIST(root=&#39;D:\\\\MNIST&#39;, train=True, download=False, transform=transform)\r\n        mnist_testset = datasets.MNIST(root=&#39;D:\\\\MNIST&#39;, train=False, download=False, transform=transform)\r\n    \r\n        train_loader = DataLoader(dataset=mnist_trainset, batch_size=100, shuffle=True)\r\n        test_loader = DataLoader(dataset=mnist_testset, batch_size=100, shuffle=False)\r\n    \r\n        input_size = 784\r\n        hidden_size = 500\r\n        output_size = 10\r\n        num_epochs = 5\r\n    \r\n        learning_rate = 0.001\r\n    \r\n        model = NeuralNet(input_size, hidden_size, output_size)\r\n        model.cuda(device)\r\n    \r\n        lossFunction = nn.CrossEntropyLoss()\r\n        lossFunction.cuda(device)\r\n        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n    \r\n        losses_in_epochs = []\r\n        total_step = len(train_loader)\r\n        for epoch in range(num_epochs):\r\n            for i, (images, labels) in enumerate(train_loader):\r\n                images = images.to(device)\r\n                labels = labels.to(device)\r\n                images = images.reshape(-1, 28 * 28)\r\n    \r\n                out = model(images)\r\n                loss = lossFunction(out, labels)\r\n    \r\n                optimizer.zero_grad()\r\n                loss.backward()\r\n                optimizer.step()\r\n    \r\n                if (i + 1) % 100 == 0:\r\n                    print(&#39;Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}&#39;.format(epoch + 1, num_epochs, i + 1, total_step,\r\n                                                                             loss.item()))\r\n    \r\n                if (i % 600) == 0:\r\n                    losses_in_epochs.append(loss.item())\r\n    \r\n        with torch.no_grad():\r\n            correct = 0\r\n            total = 0\r\n            for images, labels in test_loader:\r\n                images = images.reshape(-1, 28 * 28)\r\n                out = model(images)\r\n                _, predicted = torch.max(out.data, 1)\r\n                total += labels.size(0)\r\n                correct += (predicted == labels).sum().item()\r\n                print(&#39;Accuracy of the network on the 10000 test images: {} %&#39;.format(100 * correct / total))\r\n    \r\n    \r\n    if __name__ == &#39;__main__&#39;:\r\n        main()\r\n\r\n**The software stack:**\r\n\r\n    Python 3.7.1\r\n    torch 1.0.1 (with Cuda 9.0)\r\n    Windows 10 64-bit",
        "accepted_answer_markdown": "The error only happens only at the testing step, when you try calculating the accuracy, this might already give you a hint. The training loop runs without a problem.\r\n\r\nThe error is simply that you don&#39;t send the images and labels to the GPU at this step. This is your corrected evaluation loop:\r\n\r\n\r\n    with torch.no_grad():\r\n        correct = 0\r\n        total = 0\r\n        for images, labels in test_loader:\r\n            images = images.to(device)  # missing line from original code\r\n            labels = labels.to(device)  # missing line from original code\r\n            images = images.reshape(-1, 28 * 28)\r\n            out = model(images)\r\n            _, predicted = torch.max(out.data, 1)\r\n            total += labels.size(0)\r\n            correct += (predicted == labels).sum().item()\r\n\r\nBTW you don&#39;t need to send all your layers to the GPU separately (at your class `__init__()`). It&#39;s better to just send the whole instantiated model to the gpu at once.\r\n\r\n    "
    },
    {
        "question_id": "55476131",
        "accepted_answer_id": "55477773",
        "question_title": "Error libtorch_python.so: cannot open shared object file: No such file or directory",
        "question_markdown": "I&#39;m trying to implement fastai pretrain language model and it requires torch to work. After run the code, I got some problem about the import torch._C \r\n\r\nI run it on my linux, python 3.7.1, via pip: torch 1.0.1.post2, cuda V7.5.17. I&#39;m getting this error:\r\n\r\n    Traceback (most recent call last):\r\n      File &quot;pretrain_lm.py&quot;, line 7, in &lt;module&gt;\r\n        import fastai\r\n      File &quot;/home/andira/anaconda3/lib/python3.7/site-packages/fastai/__init__.py&quot;, line 1, in &lt;module&gt;\r\n        from .basic_train import *\r\n      File &quot;/home/andira/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py&quot;, line 2, in &lt;module&gt;\r\n        from .torch_core import *\r\n      File &quot;/home/andira/anaconda3/lib/python3.7/site-packages/fastai/torch_core.py&quot;, line 2, in &lt;module&gt;\r\n        from .imports.torch import *\r\n      File &quot;/home/andira/anaconda3/lib/python3.7/site-packages/fastai/imports/__init__.py&quot;, line 2, in &lt;module&gt;\r\n        from .torch import *\r\n      File &quot;/home/andira/anaconda3/lib/python3.7/site-packages/fastai/imports/torch.py&quot;, line 1, in &lt;module&gt;\r\n        import torch, torch.nn.functional as F\r\n      File &quot;/home/andira/anaconda3/lib/python3.7/site-packages/torch/__init__.py&quot;, line 84, in &lt;module&gt;\r\n        from torch._C import *\r\n    ImportError: libtorch_python.so: cannot open shared object file: No such file or directory\r\n\r\nSo I tried to run this line:\r\n\r\n    from torch._C import *\r\n\r\nand got same result\r\n\r\n    ImportError: libtorch_python.so: cannot open shared object file: No such file or directory\r\n\r\nI checked `/home/andira/anaconda3/lib/python3.7/site-packages/torch/lib` and there are only `libcaffe2_gpu.so` and `libshm.so` file, and I can&#39;t find libtorch_python.so either. My question is, what is actually libtorch_python.so? I&#39;ve read some of article and like most of it talked about *undefined symbol*, not *cannot open shared object file: No such file or directory* like mine. I&#39;m new at python and torch so I really appreciate your answer.",
        "accepted_answer_markdown": "My problem is solved. I&#39;m uninstalling my torch twice \r\n\r\n    pip uninstall torch\r\n    pip uninstall torch\r\n\r\nand then re-installing it back: \r\n\r\n    pip install torch==1.0.1.post2"
    },
    {
        "question_id": "55507391",
        "accepted_answer_id": "55508063",
        "question_title": "Pytorch loss function error in the last batch",
        "question_markdown": "Assume that I have 77 samples to train my CNN, and my `batch size` is 10. Then the last batch has a `batch size` of 7 instead of 10. Somehow when I pass it to the loss function such as `nn.MSELoss()`, it gives me the error:\r\n\r\n&gt; RuntimeError: The size of tensor a (10) must match the size of tensor\r\n&gt; b (7) at non-singleton dimension 1\r\n\r\nSo pytorch doesn&#39;t support batches with different sizes? \r\n\r\nMy code in doubt:\r\n-----------------\r\n\r\n    import numpy as np\r\n    import torch\r\n    from torch import nn\r\n    import torchvision\r\n    import torch.nn.functional as F\r\n    import torch.optim as optim\r\n    \r\n    class Net(nn.Module):\r\n        def __init__(self):\r\n            super(Net, self).__init__()\r\n            self.conv1 = nn.Conv2d(1, 6, (5,4))\r\n            self.pool = nn.MaxPool2d(2, 2)\r\n            self.conv2 = nn.Conv2d(6, 16, 5)\r\n            self.fc1 = nn.Linear(64, 120)\r\n            self.fc2 = nn.Linear(120, 84)\r\n            self.fc3 = nn.Linear(84, 10)\r\n    \r\n        def forward(self, x):\r\n            x = self.pool(F.relu(self.conv1(x)))\r\n            x = self.pool(F.relu(self.conv2(x)))\r\n            x = x.view(-1, x.shape[1] * x.shape[2] * x.shape[3])\r\n            x = F.relu(self.fc1(x))\r\n            x = F.relu(self.fc2(x))\r\n            x = self.fc3(x)\r\n            return x\r\n    \r\n    model = Net()\r\n    \r\n    batch_size = 10\r\n    \r\n    # Generating Artifical data\r\n    x_train = torch.randn((77,1,20,20))\r\n    y_train = torch.randint(0,10,size=(77,),dtype=torch.float)\r\n    \r\n    trainset = torch.utils.data.TensorDataset(x_train,y_train)\r\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\r\n    # testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\r\n    \r\n    criterion = nn.MSELoss()\r\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\r\n    \r\n    for epoch in range(20):  # loop over the dataset multiple times\r\n    \r\n        running_loss = 0.0\r\n        for i, data in enumerate(trainloader, 0):\r\n            # get the inputs\r\n            inputs, labels = data\r\n            # zero the parameter gradients\r\n            optimizer.zero_grad()\r\n    \r\n            # forward + backward + optimize\r\n            outputs = model(inputs)\r\n            loss = criterion(outputs, labels)\r\n            loss.backward()\r\n            optimizer.step()\r\n    \r\n            # print statistics\r\n            running_loss += loss.item()\r\n            if i%10==0:\r\n                print(&#39;epoch{}, step{}, loss: {}&#39;.format(epoch + 1, i + 1, running_loss))\r\n    #             print(&quot;frac post = {}&quot;.format(frac_post))\r\n                running_loss = 0.0",
        "accepted_answer_markdown": "The problem is not due to the batch size, but to a failure to broadcast properly between the 10 outputs of your CNN and the single label provided in each example.\r\nIf you look at the model output and label tensor shapes during the batch where the error is thrown, \r\n\r\n```python\r\nprint(outputs.shape, labels.shape)\r\n#out: torch.Size([7, 10]) torch.Size([7])\r\n```\r\nyou&#39;ll see that the labels are stored in a singleton tensor. According to [pytorch broadcasting rules][1], to be broadcastable two tensors have to be compatible in all trailing dimensions. In this case, the trailing dimension of the model output (10) is incompatible with that of the label (7).\r\n\r\nTo fix, either add a dummy dimension to the label (assuming you actually want to broadcast the labels to match your ten network outputs), or define a network with scalar outputs. For example:\r\n\r\n```python\r\ny_train = torch.randint(0,10,size=(77,1),dtype=torch.float)\r\n```\r\nresults in\r\n```\r\nprint(outputs.shape, labels.shape)\r\n#out: torch.Size([7, 10]) torch.Size([7,1])\r\n# these are broadcastable\r\n```\r\n\r\n  [1]: https://pytorch.org/docs/stable/notes/broadcasting.html"
    },
    {
        "question_id": "55511857",
        "accepted_answer_id": "55514000",
        "question_title": "how to load the gpu trained model into the cpu?",
        "question_markdown": "I am using PyTorch. I am going to use the already trained model on multiple GPUs with CPU. how to do this task? \r\n\r\nI tried on Anaconda 3 and pytorch with cpu only i dont have gpu \r\n\r\n    model = models.get_pose_net(config, is_train=False)\r\n    gpus = [int(i) for i in config.GPUS.split(&#39;,&#39;)]\r\n    model = torch.nn.DataParallel(model, device_ids=gpus).cuda()\r\n\r\n    print(&#39;Created model...&#39;)\r\n    print(model)\r\n    checkpoint = torch.load(config.MODEL.RESUME)\r\n    model.load_state_dict(checkpoint)\r\n    model.eval()\r\n    print(&#39;Loaded pretrained weights...&#39;)\r\n\r\n\r\nthe error i got is \r\n\r\n        AssertionError                            Traceback (most recent call  last)\r\n    &lt;ipython-input-15-bbfcd201d332&gt; in &lt;module&gt;()\r\n          2 model = models.get_pose_net(config, is_train=False)\r\n          3 gpus = [int(i) for i in config.GPUS.split(&#39;,&#39;)]\r\n    ----&gt; 4 model = torch.nn.DataParallel(model, device_ids=gpus).cuda()\r\n          5 print(&#39;Created model...&#39;)\r\n          6 print(model)\r\n\r\n    C:\\Users\\psl\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py in cuda(self, device)\r\n        258             Module: self\r\n        259         &quot;&quot;&quot;\r\n    --&gt; 260         return self._apply(lambda t: t.cuda(device))\r\n        261 \r\n        262     def cpu(self):\r\n\r\n    C:\\Users\\psl\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py in \r\n   _apply(self, fn)\r\n        185     def _apply(self, fn):\r\n        186         for module in self.children():\r\n    --&gt; 187             module._apply(fn)\r\n        188 \r\n        189         for param in self._parameters.values():\r\n\r\n    C:\\Users\\psl\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py in _apply(self, fn)\r\n        185     def _apply(self, fn):\r\n        186         for module in self.children():\r\n    --&gt; 187             module._apply(fn)\r\n        188 \r\n        189         for param in self._parameters.values():\r\n \r\n    C:\\Users\\psl\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py in _apply(self, fn)\r\n        191                 # Tensors stored in modules are graph leaves, and we don&#39;t\r\n        192                 # want to create copy nodes, so we have to unpack the data.\r\n    --&gt; 193                 param.data = fn(param.data)\r\n        194                 if param._grad is not None:\r\n        195                     param._grad.data = fn(param._grad.data)\r\n\r\n    C:\\Users\\psl\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py in &lt;lambda&gt;(t)\r\n        258             Module: self\r\n        259         &quot;&quot;&quot;\r\n    --&gt; 260         return self._apply(lambda t: t.cuda(device))\r\n        261 \r\n        262     def cpu(self):\r\n\r\n     C:\\Users\\psl\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py in _lazy_init()\r\n        159         raise RuntimeError(\r\n        160             &quot;Cannot re-initialize CUDA in forked subprocess. &quot; + msg)\r\n    --&gt; 161     _check_driver()\r\n        162     torch._C._cuda_init()\r\n        163     _cudart = _load_cudart()\r\n\r\n    C:\\Users\\psl\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py in _check_driver()\r\n         80 Found no NVIDIA driver on your system. Please check that you\r\n         81 have an NVIDIA GPU and installed a driver from\r\n    ---&gt; 82 http://www.nvidia.com/Download/index.aspx&quot;&quot;&quot;)\r\n         83         else:\r\n         84             # TODO: directly link to the alternative bin that needs install\r\n\r\n    AssertionError: \r\n    Found no NVIDIA driver on your system. Please check that you\r\n    have an NVIDIA GPU and installed a driver from\r\n    http://www.nvidia.com/Download/index.aspx",
        "accepted_answer_markdown": "To force load the saved model onto cpu, use the following command.\r\n\r\n    torch.load(&#39;/path/to/saved/model&#39;, map_location=&#39;cpu&#39;)\r\n\r\nIn your case change it to\r\n\r\n    torch.load(config.MODEL.RESUME, map_location=&#39;cpu&#39;)\r\n\r\n"
    },
    {
        "question_id": "55549843",
        "accepted_answer_id": "55549952",
        "question_title": "Pytorch doesn&#39;t support one-hot vector?",
        "question_markdown": "I am very confused by how Pytorch deals with one-hot vectors. In this [tutorial][1], the neural network will generate a one-hot vector as its output. As far as I understand, the schematic structure of the neural network in the tutorial should be like:\r\n\r\n[![enter image description here][2]][2]\r\n\r\nHowever, the `labels` are not in one-hot vector format. I get the following `size`\r\n\r\n    print(labels.size())\r\n    print(outputs.size())\r\n\r\n    output&gt;&gt;&gt; torch.Size([4]) \r\n    output&gt;&gt;&gt; torch.Size([4, 10])\r\nMiraculously, I they pass the `outputs` and `labels` to `criterion=CrossEntropyLoss()`, there&#39;s no error at all.\r\n\r\n    loss = criterion(outputs, labels) # How come it has no error?\r\n\r\nMy hypothesis:\r\n--------------\r\nMaybe pytorch automatically convert the `labels` to one-hot vector form. So, I try to convert labels to one-hot vector before passing it to the loss function.\r\n\r\n    def to_one_hot_vector(num_class, label):\r\n        b = np.zeros((label.shape[0], num_class))\r\n        b[np.arange(label.shape[0]), label] = 1\r\n        \r\n        return b\r\n    \r\n    labels_one_hot = to_one_hot_vector(10,labels)\r\n    labels_one_hot = torch.Tensor(labels_one_hot)\r\n    labels_one_hot = labels_one_hot.type(torch.LongTensor)\r\n    \r\n    loss = criterion(outputs, labels_one_hot) # Now it gives me error\r\n\r\nHowever, I got the following error\r\n\r\n&gt; RuntimeError: multi-target not supported at\r\n&gt; /opt/pytorch/pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15\r\n\r\nSo, one-hot vectors are not supported in `Pytorch`? How does `Pytorch` calculates the `cross entropy` for the two tensor `outputs = [1,0,0],[0,0,1]` and `labels = [0,2]` ? It doesn&#39;t make sense to me at all at the moment.\r\n\r\n  [1]: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\r\n  [2]: https://i.sstatic.net/1v35k.png",
        "accepted_answer_markdown": "PyTorch states in its documentation for [`CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss) that \r\n\r\n&gt; This criterion expects a class index (0 to C-1) as the target for each value of a 1D tensor of size minibatch\r\n\r\nIn other words, it has your `to_one_hot_vector` function conceptually built in `CEL` and does not expose the one-hot API. Notice that one-hot vectors are memory inefficient compared to storing class labels.\r\n\r\nIf you are given one-hot vectors and need to go to class labels format (for instance  to be compatible with `CEL`), you can use `argmax` like below:\r\n\r\n    import torch\r\n     \r\n    labels = torch.tensor([1, 2, 3, 5])\r\n    one_hot = torch.zeros(4, 6)\r\n    one_hot[torch.arange(4), labels] = 1\r\n     \r\n    reverted = torch.argmax(one_hot, dim=1)\r\n    assert (labels == reverted).all().item()"
    },
    {
        "question_id": "55636138",
        "accepted_answer_id": "55649132",
        "question_title": "Issues converting Keras code into PyTorch code (shaping)",
        "question_markdown": "I have some keras code that I need to convert to Pytorch. I am new to pytorch and I am having trouble wrapping my head around how to take in input the same way that I did in keras. I have spent many hours on this any tips or help is very appreciated. \r\n\r\nHere is the keras code I am dealing with. The input shape is (5000,1)\r\n```\r\n    def build(input_shape, classes):\r\n        model = Sequential()\r\n\r\n        filter_num = [&#39;None&#39;,32,64,128,256]\r\n        kernel_size = [&#39;None&#39;,8,8,8,8]\r\n        conv_stride_size = [&#39;None&#39;,1,1,1,1]\r\n        pool_stride_size = [&#39;None&#39;,4,4,4,4]\r\n        pool_size = [&#39;None&#39;,8,8,8,8]\r\n\r\n\r\n        # Block1\r\n        model.add(Conv1D(filters=filter_num[1], kernel_size=kernel_size[1], input_shape=input_shape,\r\n                         strides=conv_stride_size[1], padding=&#39;same&#39;,\r\n                         name=&#39;block1_conv1&#39;))\r\n        model.add(BatchNormalization(axis=-1))\r\n        model.add(ELU(alpha=1.0, name=&#39;block1_adv_act1&#39;))\r\n        model.add(Conv1D(filters=filter_num[1], kernel_size=kernel_size[1],\r\n                         strides=conv_stride_size[1], padding=&#39;same&#39;,\r\n                         name=&#39;block1_conv2&#39;))\r\n        model.add(BatchNormalization(axis=-1))\r\n        model.add(ELU(alpha=1.0, name=&#39;block1_adv_act2&#39;))\r\n        model.add(MaxPooling1D(pool_size=pool_size[1], strides=pool_stride_size[1],\r\n                               padding=&#39;same&#39;, name=&#39;block1_pool&#39;))\r\n        model.add(Dropout(0.1, name=&#39;block1_dropout&#39;))\r\n\r\n\r\n\r\n        # Block 2\r\n        model.add(Conv1D(filters=filter_num[2], kernel_size=kernel_size[2],\r\n                         strides=conv_stride_size[2], padding=&#39;same&#39;,\r\n                         name=&#39;block2_conv1&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;block2_act1&#39;))\r\n\r\n        model.add(Conv1D(filters=filter_num[2], kernel_size=kernel_size[2],\r\n                         strides=conv_stride_size[2], padding=&#39;same&#39;,\r\n                         name=&#39;block2_conv2&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;block2_act2&#39;))\r\n        model.add(MaxPooling1D(pool_size=pool_size[2], strides=pool_stride_size[3],\r\n                               padding=&#39;same&#39;, name=&#39;block2_pool&#39;))\r\n        model.add(Dropout(0.1, name=&#39;block2_dropout&#39;))\r\n\r\n\r\n\r\n        # Block 3\r\n        model.add(Conv1D(filters=filter_num[3], kernel_size=kernel_size[3],\r\n                         strides=conv_stride_size[3], padding=&#39;same&#39;,\r\n                         name=&#39;block3_conv1&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;block3_act1&#39;))\r\n        model.add(Conv1D(filters=filter_num[3], kernel_size=kernel_size[3],\r\n                         strides=conv_stride_size[3], padding=&#39;same&#39;,\r\n                         name=&#39;block3_conv2&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;block3_act2&#39;))\r\n        model.add(MaxPooling1D(pool_size=pool_size[3], strides=pool_stride_size[3],\r\n                               padding=&#39;same&#39;, name=&#39;block3_pool&#39;))\r\n        model.add(Dropout(0.1, name=&#39;block3_dropout&#39;))\r\n\r\n\r\n\r\n        # Block 4\r\n        model.add(Conv1D(filters=filter_num[4], kernel_size=kernel_size[4],\r\n                         strides=conv_stride_size[4], padding=&#39;same&#39;,\r\n                         name=&#39;block4_conv1&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;block4_act1&#39;))\r\n        model.add(Conv1D(filters=filter_num[4], kernel_size=kernel_size[4],\r\n                         strides=conv_stride_size[4], padding=&#39;same&#39;,\r\n                         name=&#39;block4_conv2&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;block4_act2&#39;))\r\n        model.add(MaxPooling1D(pool_size=pool_size[4], strides=pool_stride_size[4],\r\n                               padding=&#39;same&#39;, name=&#39;block4_pool&#39;))\r\n        model.add(Dropout(0.1, name=&#39;block4_dropout&#39;))\r\n\r\n\r\n\r\n\r\n        # FC #1\r\n        model.add(Flatten(name=&#39;flatten&#39;))\r\n        model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name=&#39;fc1&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;fc1_act&#39;))\r\n\r\n        model.add(Dropout(0.7, name=&#39;fc1_dropout&#39;))\r\n\r\n\r\n        #FC #2\r\n        model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name=&#39;fc2&#39;))\r\n        model.add(BatchNormalization())\r\n        model.add(Activation(&#39;relu&#39;, name=&#39;fc2_act&#39;))\r\n\r\n        model.add(Dropout(0.5, name=&#39;fc2_dropout&#39;))\r\n\r\n\r\n        # Classification\r\n        model.add(Dense(classes, kernel_initializer=glorot_uniform(seed=0), name=&#39;fc3&#39;))\r\n        model.add(Activation(&#39;softmax&#39;, name=&quot;softmax&quot;))\r\n        return model\r\n```\r\n\r\nHere are the results of model.summary() from the keras code\r\n```\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nblock1_conv1 (Conv1D)        (None, 5000, 32)          288       \r\n_________________________________________________________________\r\nbatch_normalization_1 (Batch (None, 5000, 32)          128       \r\n_________________________________________________________________\r\nblock1_adv_act1 (ELU)        (None, 5000, 32)          0         \r\n_________________________________________________________________\r\nblock1_conv2 (Conv1D)        (None, 5000, 32)          8224      \r\n_________________________________________________________________\r\nbatch_normalization_2 (Batch (None, 5000, 32)          128       \r\n_________________________________________________________________\r\nblock1_adv_act2 (ELU)        (None, 5000, 32)          0         \r\n_________________________________________________________________\r\nblock1_pool (MaxPooling1D)   (None, 1250, 32)          0         \r\n_________________________________________________________________\r\nblock1_dropout (Dropout)     (None, 1250, 32)          0         \r\n_________________________________________________________________\r\nblock2_conv1 (Conv1D)        (None, 1250, 64)          16448     \r\n_________________________________________________________________\r\nbatch_normalization_3 (Batch (None, 1250, 64)          256       \r\n_________________________________________________________________\r\nblock2_act1 (Activation)     (None, 1250, 64)          0         \r\n_________________________________________________________________\r\nblock2_conv2 (Conv1D)        (None, 1250, 64)          32832     \r\n_________________________________________________________________\r\nbatch_normalization_4 (Batch (None, 1250, 64)          256       \r\n_________________________________________________________________\r\nblock2_act2 (Activation)     (None, 1250, 64)          0         \r\n_________________________________________________________________\r\nblock2_pool (MaxPooling1D)   (None, 313, 64)           0         \r\n_________________________________________________________________\r\nblock2_dropout (Dropout)     (None, 313, 64)           0         \r\n_________________________________________________________________\r\nblock3_conv1 (Conv1D)        (None, 313, 128)          65664     \r\n_________________________________________________________________\r\nbatch_normalization_5 (Batch (None, 313, 128)          512       \r\n_________________________________________________________________\r\nblock3_act1 (Activation)     (None, 313, 128)          0         \r\n_________________________________________________________________\r\nblock3_conv2 (Conv1D)        (None, 313, 128)          131200    \r\n_________________________________________________________________\r\nbatch_normalization_6 (Batch (None, 313, 128)          512       \r\n_________________________________________________________________\r\nblock3_act2 (Activation)     (None, 313, 128)          0         \r\n_________________________________________________________________\r\nblock3_pool (MaxPooling1D)   (None, 79, 128)           0         \r\n_________________________________________________________________\r\nblock3_dropout (Dropout)     (None, 79, 128)           0         \r\n_________________________________________________________________\r\nblock4_conv1 (Conv1D)        (None, 79, 256)           262400    \r\n_________________________________________________________________\r\nbatch_normalization_7 (Batch (None, 79, 256)           1024      \r\n_________________________________________________________________\r\nblock4_act1 (Activation)     (None, 79, 256)           0         \r\n_________________________________________________________________\r\nblock4_conv2 (Conv1D)        (None, 79, 256)           524544    \r\n_________________________________________________________________\r\nbatch_normalization_8 (Batch (None, 79, 256)           1024      \r\n_________________________________________________________________\r\nblock4_act2 (Activation)     (None, 79, 256)           0         \r\n_________________________________________________________________\r\nblock4_pool (MaxPooling1D)   (None, 20, 256)           0         \r\n_________________________________________________________________\r\nblock4_dropout (Dropout)     (None, 20, 256)           0         \r\n_________________________________________________________________\r\nflatten (Flatten)            (None, 5120)              0         \r\n_________________________________________________________________\r\nfc1 (Dense)                  (None, 512)               2621952   \r\n_________________________________________________________________\r\nbatch_normalization_9 (Batch (None, 512)               2048      \r\n_________________________________________________________________\r\nfc1_act (Activation)         (None, 512)               0         \r\n_________________________________________________________________\r\nfc1_dropout (Dropout)        (None, 512)               0         \r\n_________________________________________________________________\r\nfc2 (Dense)                  (None, 512)               262656    \r\n_________________________________________________________________\r\nbatch_normalization_10 (Batc (None, 512)               2048      \r\n_________________________________________________________________\r\nfc2_act (Activation)         (None, 512)               0         \r\n_________________________________________________________________\r\nfc2_dropout (Dropout)        (None, 512)               0         \r\n_________________________________________________________________\r\nfc3 (Dense)                  (None, 101)               51813     \r\n_________________________________________________________________\r\nsoftmax (Activation)         (None, 101)               0         \r\n=================================================================\r\nTotal params: 3,985,957\r\nTrainable params: 3,981,989\r\nNon-trainable params: 3,968\r\n```\r\n\r\n\r\nHere is what I have made in pytorch\r\n```\r\nclass model(torch.nn.Module):\r\n    def __init__(self, input_channels, kernel_size, stride, pool_kernel, pool_stride, dropout_p, dropout_inplace=False):\r\n        super(model, self).__init__()\r\n        self.encoder = nn.Sequential(\r\n            BasicBlock1(input_channels, kernel_size, stride, pool_kernel, pool_stride, dropout_p),\r\n            BasicBlock(input_channels//4, kernel_size, stride, pool_kernel, pool_stride, dropout_p),\r\n            BasicBlock(input_channels//16, kernel_size, stride, pool_kernel, pool_stride, dropout_p),\r\n            BasicBlock(input_channels//16//4, kernel_size, stride, pool_kernel, pool_stride, dropout_p)\r\n        )\r\n\r\n\r\n        self.decoder = nn.Sequential(\r\n            nn.Linear(5120, 512),\r\n            nn.BatchNorm1d(512),\r\n            nn.ReLU(),\r\n            nn.Dropout(p=dropout_p, inplace=dropout_inplace),\r\n            nn.Linear(512, 512),\r\n            nn.BatchNorm1d(512),\r\n            nn.ReLU(),\r\n            nn.Dropout(p=dropout_p, inplace=dropout_inplace),\r\n            nn.Linear(512, 101),\r\n            nn.Softmax(dim=101)\r\n        )\r\n    def forward(self, x):\r\n        x = self.encoder(x)\r\n\r\n        x = x.view(x.size(0), -1)  # flatten\r\n\r\n        x = self.decoder(x)\r\n        return x\r\n\r\n\r\ndef BasicBlock(input_channels, kernel_size, stride, pool_kernel, pool_stride, dropout_p, dropout_inplace=False):\r\n    return nn.Sequential(\r\n        nn.Conv1d(in_channels=input_channels, out_channels=input_channels, kernel_size=kernel_size, stride=stride,\r\n                  padding=get_pad_size(input_channels, input_channels, kernel_size)),\r\n        nn.BatchNorm1d(32),\r\n        nn.ReLU(),\r\n        nn.Conv1d(in_channels=input_channels, out_channels=input_channels, kernel_size=kernel_size, stride=stride,\r\n                  padding=get_pad_size(input_channels, input_channels, kernel_size)),\r\n        nn.BatchNorm1d(32),\r\n        nn.ReLU(),\r\n        nn.MaxPool1d(kernel_size=pool_kernel, stride=pool_stride,\r\n                     padding=get_pad_size(input_channels, input_channels/4, kernel_size)),\r\n        nn.Dropout(p=dropout_p, inplace=dropout_inplace)\r\n    )\r\n\r\n\r\ndef BasicBlock1(input_channels, kernel_size, stride, pool_kernel, pool_stride, dropout_p, dropout_inplace=False):\r\n    return nn.Sequential(\r\n        nn.Conv1d(in_channels=1, out_channels=input_channels, kernel_size=kernel_size, stride=stride,\r\n                  padding=get_pad_size(input_channels, input_channels, kernel_size)),\r\n        nn.BatchNorm1d(32),\r\n        nn.ReLU(),\r\n        nn.Conv1d(in_channels=input_channels, out_channels=input_channels, kernel_size=kernel_size, stride=stride,\r\n                  padding=get_pad_size(input_channels, input_channels, kernel_size)),\r\n        nn.BatchNorm1d(32),\r\n        nn.ReLU(),\r\n        nn.MaxPool1d(kernel_size=pool_kernel, stride=pool_stride,\r\n                     padding=get_pad_size(input_channels, input_channels/4, kernel_size)),\r\n        nn.Dropout(p=dropout_p, inplace=dropout_inplace)\r\n    )\r\n\r\n\r\ndef get_pad_size(input_shape, output_shape, kernel_size, stride=1, dilation=1):\r\n    &quot;&quot;&quot;\r\n    Gets the right padded needed to maintain same shape in the conv layers\r\n    BEWARE: works only on odd size kernel size\r\n    :param input_shape: the input shape to the conv layer\r\n    :param output_shape: the desired output shape of the conv layer\r\n    :param kernel_size: the size of the kernel window, has to be odd\r\n    :param stride: Stride of the convolution\r\n    :param dilation: Spacing between kernel elements\r\n    :return: the appropriate pad size for the needed configuration\r\n    :Author: Aneesh\r\n    &quot;&quot;&quot;\r\n\r\n    if kernel_size % 2 == 0:\r\n        raise ValueError(\r\n            &quot;Kernel size has to be odd for this function to work properly. Current Value is %d.&quot; % kernel_size)\r\n\r\n    return (int((output_shape * stride - stride + kernel_size - input_shape + (kernel_size - 1) * (dilation - 1)) / 2))\r\n```\r\n\r\nLastly here is the model summary for what my pytorch model creates\r\n```\r\nmodel(\r\n  (encoder): Sequential(\r\n    (0): Sequential(\r\n      (0): Conv1d(1, 5000, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (2): ReLU()\r\n      (3): Conv1d(5000, 5000, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (5): ReLU()\r\n      (6): MaxPool1d(kernel_size=8, stride=4, padding=-1872, dilation=1, ceil_mode=False)\r\n      (7): Dropout(p=0.1)\r\n    )\r\n    (1): Sequential(\r\n      (0): Conv1d(1250, 1250, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (2): ReLU()\r\n      (3): Conv1d(1250, 1250, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (5): ReLU()\r\n      (6): MaxPool1d(kernel_size=8, stride=4, padding=-465, dilation=1, ceil_mode=False)\r\n      (7): Dropout(p=0.1)\r\n    )\r\n    (2): Sequential(\r\n      (0): Conv1d(312, 312, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (2): ReLU()\r\n      (3): Conv1d(312, 312, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (5): ReLU()\r\n      (6): MaxPool1d(kernel_size=8, stride=4, padding=-114, dilation=1, ceil_mode=False)\r\n      (7): Dropout(p=0.1)\r\n    )\r\n    (3): Sequential(\r\n      (0): Conv1d(78, 78, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (2): ReLU()\r\n      (3): Conv1d(78, 78, kernel_size=(7,), stride=(1,), padding=(3,))\r\n      (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (5): ReLU()\r\n      (6): MaxPool1d(kernel_size=8, stride=4, padding=-26, dilation=1, ceil_mode=False)\r\n      (7): Dropout(p=0.1)\r\n    )\r\n  )\r\n  (decoder): Sequential(\r\n    (0): Linear(in_features=5120, out_features=512, bias=True)\r\n    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n    (2): ReLU()\r\n    (3): Dropout(p=0.1)\r\n    (4): Linear(in_features=512, out_features=512, bias=True)\r\n    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n    (6): ReLU()\r\n    (7): Dropout(p=0.1)\r\n    (8): Linear(in_features=512, out_features=101, bias=True)\r\n    (9): Softmax()\r\n  )\r\n)\r\n```",
        "accepted_answer_markdown": "I think your fundamental problem is that you confuse `in_channels` and `out_channels` with Keras shapes. Let&#39;s just take the first convolutional layer as an example. In Keras you have:\r\n\r\n    Conv1D(filters=32, kernel_size=8, input_shape=(5000,1), strides=1, padding=&#39;same&#39;)\r\n\r\nThe PyTorch equivalent should be (changing the kernel size to 7 like you did, we&#39;ll come back to it later):\r\n\r\n    nn.Conv1d(in_channels=1, out_channels=32, kernel_size=7, stride=1, padding=3) # different kernel size\r\n\r\nNote that you don&#39;t need to give the shape of your input sequence for pytorch. Now let&#39;s see how it compares to what you did:\r\n\r\n    nn.Conv1d(in_channels=1, out_channels=5000, kernel_size=7, stride=1, padding=0) # note padding\r\n\r\nYou just created a huge network. While the correct implementation produces an output of `[b, 32, 5000]` where b is the batch size, your output is `[b, 5000, 5000]`.\r\n\r\nHope this example helps you to correct the rest of your implementation.\r\n\r\n\r\nFinally, some notes on replicating `same` padding in pytorch. With even kernel sizes, to preserve the size of your input you need asymmetric padding. This I think might not be available when you create the layer. I see you instead changed the kernel size to 7, but it can actually be done with the original kernel size of 8. You can use padding in your `forward()` function to create the required asymmetric padding.\r\n\r\n    layer = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=8, stride=1, padding=0) # layer without padding\r\n    x = torch.empty(1, 1, 5000).normal_()  # random input\r\n    \r\n    # forward run\r\n    x_padded = torch.nn.functional.pad(x, (3,4))\r\n    y = layer(x_padded).shape\r\n    print(y.shape)  # torch.Size([1, 32, 5000])\r\n\r\n\r\n"
    },
    {
        "question_id": "55673412",
        "accepted_answer_id": "55673559",
        "question_title": "Adam optimizer error: one of the variables needed for gradient computation has been modified by an inplace operation",
        "question_markdown": "I am trying to implement **Actor-Critic learning atuomation algorithm** that is not same as basic actor-critic algorithm, it&#39;s little bit changed.\r\n\r\nAnyway, I used Adam optimizer and implemented with pytorch\r\n\r\nwhen i backward TD-error for Critic first, there&#39;s no error.\r\nHowever, i backward loss for Actor, the error occured.\r\n\r\n&gt; --------------------------------------------------------------------------- RuntimeError                              Traceback (most recent call\r\n&gt; last) &lt;ipython-input-27-7c19f0515be7&gt; in &lt;module&gt;\r\n&gt;      46             # update Actor Func\r\n&gt;      47             optimizer_M.zero_grad()\r\n&gt; ---&gt; 48             loss.backward()\r\n&gt;      49             optimizer_M.step()\r\n&gt;      50 \r\n&gt; \r\n&gt; ~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py in backward(self,\r\n&gt; gradient, retain_graph, create_graph)\r\n&gt;     100                 products. Defaults to ``False``.\r\n&gt;     101         &quot;&quot;&quot;\r\n&gt; --&gt; 102         torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n&gt;     103 \r\n&gt;     104     def register_hook(self, hook):\r\n&gt; \r\n&gt; ~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py in\r\n&gt; backward(tensors, grad_tensors, retain_graph, create_graph,\r\n&gt; grad_variables)\r\n&gt;      88     Variable._execution_engine.run_backward(\r\n&gt;      89         tensors, grad_tensors, retain_graph, create_graph,\r\n&gt; ---&gt; 90         allow_unreachable=True)  # allow_unreachable flag\r\n&gt;      91 \r\n&gt;      92 \r\n&gt; \r\n&gt; RuntimeError: one of the variables needed for gradient computation has\r\n&gt; been modified by an inplace operation\r\n\r\n\r\n\r\nabove is the content of error\r\n\r\n\r\nI tried to find inplace operation, but I haven&#39;t found in my written code.\r\nI think i don&#39;t know how to handle optimizer.\r\n\r\n\r\n\r\nHere is main code:\r\n\r\n            for cur_step in range(1):   \r\n            action = M_Agent(state, flag)  \r\n            next_state, r = env.step(action)   \r\n            \r\n            # calculate TD Error\r\n            TD_error = M_Agent.cal_td_error(r, next_state)\r\n            \r\n            # calculate Target\r\n            target = torch.FloatTensor([M_Agent.cal_target(TD_error)])\r\n            logit = M_Agent.cal_logit()\r\n            loss = criterion(logit, target)\r\n            \r\n            # update value Func\r\n            optimizer_M.zero_grad()\r\n            TD_error.backward()\r\n            optimizer_M.step()\r\n            \r\n            # update Actor Func\r\n            loss.backward()\r\n            optimizer_M.step()\r\n\r\n\r\n\r\nHere is the agent network\r\n\r\n\r\n\r\n        # Actor-Critic Agent\r\n        self.act_pipe = nn.Sequential(nn.Linear(state, 128),\r\n                                nn.ReLU(),\r\n                                nn.Dropout(0.5),\r\n                                nn.Linear(128, 256),\r\n                                nn.ReLU(),\r\n                                nn.Dropout(0.5),\r\n                                nn.Linear(256, num_action),\r\n                                nn.Softmax()\r\n                                )\r\n\r\n         self.val_pipe = nn.Sequential(nn.Linear(state, 128),\r\n                                nn.ReLU(),\r\n                                nn.Dropout(0.5),\r\n                                nn.Linear(128, 256),\r\n                                nn.ReLU(),\r\n                                nn.Dropout(0.5),\r\n                                nn.Linear(256, 1)\r\n                                )\r\n        \r\n        \r\n          def forward(self, state, flag, test=None):\r\n      \r\n              temp_action_prob = self.act_pipe(state)\r\n              self.action_prob = self.cal_prob(temp_action_prob, flag)\r\n              self.action = self.get_action(self.action_prob)\r\n              self.value = self.val_pipe(state)\r\n        \r\n              return self.action\r\n\r\nI wanna update each network respectively.\r\n\r\nand I wanna know that Basic **TD Actor-Critic** method uses TD error for loss??\r\nor squared error between r+V(s&#39;) and V(s) ?",
        "accepted_answer_markdown": "I think the problem is that you zero the gradients right before calling backward, after the forward propagation. Note that for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) you need the computation graph and the intermediate results that you produce during your forward pass.\r\n\r\nSo zero the gradients **before** your TD error and target calculations! And not after you are finished your forward propagation.\r\n\r\n\r\n        for cur_step in range(1):   \r\n        action = M_Agent(state, flag)  \r\n        next_state, r = env.step(action)   \r\n\r\n        optimizer_M.zero_grad()  # zero your gradient here\r\n\r\n        # calculate TD Error\r\n        TD_error = M_Agent.cal_td_error(r, next_state)\r\n\r\n        # calculate Target\r\n        target = torch.FloatTensor([M_Agent.cal_target(TD_error)])\r\n        logit = M_Agent.cal_logit()\r\n        loss = criterion(logit, target)\r\n\r\n        # update value Func\r\n        TD_error.backward()\r\n        optimizer_M.step()\r\n\r\n        # update Actor Func\r\n        loss.backward()\r\n        optimizer_M.step()\r\n\r\n\r\nTo answer your second question, the DDPG algorithm for example uses the squared error (see the [paper](https://arxiv.org/pdf/1509.02971v2.pdf)).\r\n\r\nAnother recommendation. In many cases large parts of the value and policy networks are shared in deep actor-critic agents: you have the same layers up to the last hidden layer, and use a single linear output for value prediction and a softmax layer for the action distribution. This is especially useful if you have high dimensional visual inputs, as it act as sort of a multi-task learning, but nevertheless you can try. (As I see you have a low-dimensional state vector)."
    },
    {
        "question_id": "55688645",
        "accepted_answer_id": "55703859",
        "question_title": "How downsample work in ResNet in pytorch code?",
        "question_markdown": "In this pytorch ResNet code example they define downsample as variable in line 44. and line 58 use it as function. How this downsample work here as CNN point of view and as python Code point of view.\r\n\r\ncode example : [pytorch ResNet][1]\r\n\r\ni searched for if downsample is any pytorch inbuilt function. but it is not.\r\n\r\n    class BasicBlock(nn.Module):\r\n        expansion = 1\r\n    \r\n        def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, norm_layer=None):\r\n            super(BasicBlock, self).__init__()\r\n            if norm_layer is None:\r\n                norm_layer = nn.BatchNorm2d\r\n            if groups != 1:\r\n                raise ValueError(&#39;BasicBlock only supports groups=1&#39;)\r\n            # Both self.conv1 and self.downsample layers downsample the input when stride != 1\r\n            self.conv1 = conv3x3(inplanes, planes, stride)\r\n            self.bn1 = norm_layer(planes)\r\n            self.relu = nn.ReLU(inplace=True)\r\n            self.conv2 = conv3x3(planes, planes)\r\n            self.bn2 = norm_layer(planes)\r\n            self.downsample = downsample\r\n            self.stride = stride\r\n    \r\n        def forward(self, x):\r\n            identity = x\r\n    \r\n            out = self.conv1(x)\r\n            out = self.bn1(out)\r\n            out = self.relu(out)\r\n    \r\n            out = self.conv2(out)\r\n            out = self.bn2(out)\r\n    \r\n            if self.downsample is not None:\r\n                identity = self.downsample(x)\r\n    \r\n            out += identity\r\n            out = self.relu(out)\r\n    \r\n    return out\r\n\r\n  [1]: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\r\n",
        "accepted_answer_markdown": "In this ResNet example, Here when we define BasicBlock class we pass downsample as constructor parameter.\r\n\r\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, norm_layer=None):\r\n\r\n if we pass nothing to class then `downsample = None` , as result *identity* will not changed.\r\n\r\nWhen we pass `downsample = &quot;some convolution layer&quot;` as class constructor argument, It will downsample the *identity* via passed convolution layer to sucessfully perform addition. this layer will downsample the identity through code as mentioned\r\n\r\n      if self.downsample is not None:\r\n            identity = self.downsample(x)\r\n\r\n"
    },
    {
        "question_id": "55720464",
        "accepted_answer_id": "55720527",
        "question_title": "Creating a Simple 1D CNN in PyTorch with Multiple Channels",
        "question_markdown": "The dimensionality of the PyTorch inputs are not what the model expects, and I am not sure why.\r\n\r\nTo my understanding...\r\n\r\n`in_channels` is first the number of 1D inputs we would like to pass to the model, and is the previous out_channel for all subsequent layers.\r\n\r\n`out_channels` is the desired number of kernels (filters).\r\n\r\n`kernel_size` is the number of parameters per filter.\r\n\r\nTherefore, we would expect, as data passed to forward, a dataset with 7 1D channels (i.e. a 2D input).\r\n\r\nHowever, the following code throws an error that is not consistent with what I expect, where this code:\r\n\r\n```python\r\nimport numpy\r\nimport torch\r\n\r\nX = numpy.random.uniform(-10, 10, 70).reshape(-1, 7)\r\n# Y = np.random.randint(0, 9, 10).reshape(-1, 1)\r\n\r\nclass Simple1DCNN(torch.nn.Module):\r\n    def __init__(self):\r\n        super(Simple1DCNN, self).__init__()\r\n        self.layer1 = torch.nn.Conv1d(in_channels=7, out_channels=20, kernel_size=5, stride=2)\r\n        self.act1 = torch.nn.ReLU()\r\n        self.layer2 = torch.nn.Conv1d(in_channels=20, out_channels=10, kernel_size=1)\r\n    def forward(self, x):\r\n        x = self.layer1(x)\r\n        x = self.act1(x)\r\n        x = self.layer2(x)\r\n        \r\n        log_probs = torch.nn.functional.log_softmax(x, dim=1)\r\n        \r\n        return log_probs\r\n\r\nmodel = Simple1DCNN()\r\nprint(model(torch.tensor(X)).size)\r\n```\r\n\r\nThrows the following error:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n&lt;ipython-input-5-eca5856a2314&gt; in &lt;module&gt;()\r\n     21 \r\n     22 model = Simple1DCNN()\r\n---&gt; 23 print(model(torch.tensor(X)).size)\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    487             result = self._slow_forward(*input, **kwargs)\r\n    488         else:\r\n--&gt; 489             result = self.forward(*input, **kwargs)\r\n    490         for hook in self._forward_hooks.values():\r\n    491             hook_result = hook(self, input, result)\r\n\r\n&lt;ipython-input-5-eca5856a2314&gt; in forward(self, x)\r\n     12         self.layer2 = torch.nn.Conv1d(in_channels=20, out_channels=10, kernel_size=1)\r\n     13     def forward(self, x):\r\n---&gt; 14         x = self.layer1(x)\r\n     15         x = self.act1(x)\r\n     16         x = self.layer2(x)\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    487             result = self._slow_forward(*input, **kwargs)\r\n    488         else:\r\n--&gt; 489             result = self.forward(*input, **kwargs)\r\n    490         for hook in self._forward_hooks.values():\r\n    491             hook_result = hook(self, input, result)\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py in forward(self, input)\r\n    185     def forward(self, input):\r\n    186         return F.conv1d(input, self.weight, self.bias, self.stride,\r\n--&gt; 187                         self.padding, self.dilation, self.groups)\r\n    188 \r\n    189 \r\n\r\nRuntimeError: Expected 3-dimensional input for 3-dimensional weight [20, 7, 5], but got 2-dimensional input of size [10, 7] instead\r\n```\r\n\r\n**Edit: See below for solution, motivated by Shai.**\r\n\r\n```python\r\nimport numpy\r\nimport torch\r\n\r\nX = numpy.random.uniform(-10, 10, 70).reshape(1, 7, -1)\r\n# Y = np.random.randint(0, 9, 10).reshape(1, 1, -1)\r\n\r\nclass Simple1DCNN(torch.nn.Module):\r\n    def __init__(self):\r\n        super(Simple1DCNN, self).__init__()\r\n        self.layer1 = torch.nn.Conv1d(in_channels=7, out_channels=20, kernel_size=5, stride=2)\r\n        self.act1 = torch.nn.ReLU()\r\n        self.layer2 = torch.nn.Conv1d(in_channels=20, out_channels=10, kernel_size=1)\r\n    def forward(self, x):\r\n        x = self.layer1(x)\r\n        x = self.act1(x)\r\n        x = self.layer2(x)\r\n        \r\n        log_probs = torch.nn.functional.log_softmax(x, dim=1)\r\n        \r\n        return log_probs\r\n\r\nmodel = Simple1DCNN().double()\r\nprint(model(torch.tensor(X)).shape)\r\n```",
        "accepted_answer_markdown": "You are forgetting the &quot;minibatch dimension&quot;, each &quot;1D&quot; sample has indeed two dimensions: the number of channels (7 in your example) and length (10 in your case). However, pytorch expects as input not a single sample, but rather a minibatch of `B` samples stacked together along the &quot;minibatch dimension&quot;.  \r\nSo a &quot;1D&quot; CNN in pytorch expects a 3D tensor as input: `B`x`C`x`T`. If you only have one signal, you can add a singleton dimension:\r\n\r\n     out = model(torch.tensor(X)[None, ...])"
    },
    {
        "question_id": "55762581",
        "accepted_answer_id": "55763110",
        "question_title": "Expected object of scalar type Long but got scalar type Byte for argument #2 &#39;target&#39;",
        "question_markdown": "I am running a nn on colab and came across this error which was not there when i ran the same code on my local system. I have tried with reduced batch size too but the error still persists. \r\n```\r\nLoading dataset\r\nStart training\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n&lt;ipython-input-4-37432f9d142a&gt; in &lt;module&gt;()\r\n     70           start_epoch=start_epoch, log=log_interval,\r\n     71           checkpoint_path=os.path.join(dataset_dir, &quot;cnn_block_frame_flow&quot;),\r\n---&gt; 72           validate=True, resume=False, flow=True, use_cuda=cuda)\r\n     73 \r\n     74     #model = models.model()\r\n\r\n/content/KTH-Action-Recognition/main/train_helper.py in train(model, num_epochs, train_set, dev_set, lr, batch_size, start_epoch, log, checkpoint_path, validate, resume, flow, use_cuda)\r\n    107             outputs = get_outputs(model, samples[&quot;instance&quot;], flow=flow,\r\n    108                                   use_cuda=use_cuda)\r\n--&gt; 109             loss = criterion(outputs, labels)\r\n    110             loss.backward()\r\n    111             optimizer.step()\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    487             result = self._slow_forward(*input, **kwargs)\r\n    488         else:\r\n--&gt; 489             result = self.forward(*input, **kwargs)\r\n    490         for hook in self._forward_hooks.values():\r\n    491             hook_result = hook(self, input, result)\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py in forward(self, input, target)\r\n    902     def forward(self, input, target):\r\n    903         return F.cross_entropy(input, target, weight=self.weight,\r\n--&gt; 904                                ignore_index=self.ignore_index, reduction=self.reduction)\r\n    905 \r\n    906 \r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction)\r\n   1968     if size_average is not None or reduce is not None:\r\n   1969         reduction = _Reduction.legacy_get_string(size_average, reduce)\r\n-&gt; 1970     return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\r\n   1971 \r\n   1972 \r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)\r\n   1788                          .format(input.size(0), target.size(0)))\r\n   1789     if dim == 2:\r\n-&gt; 1790         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\r\n   1791     elif dim == 4:\r\n   1792         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\r\n\r\nRuntimeError: Expected object of scalar type Long but got scalar type Byte for argument #2 &#39;target&#39;\r\n```\r\nCan someone tell me what is causing this error? thank you",
        "accepted_answer_markdown": "The title of your question is telling what is causing this error. The `target` should have type `torch.LongTensor`, but it is instead `torch.ByteTensor`. Before calling `nll_loss` do:\r\n\r\n```python\r\ntarget = target.type(torch.LongTensor)\r\n```"
    },
    {
        "question_id": "55883389",
        "accepted_answer_id": "55890693",
        "question_title": "The `device` argument should be set by using `torch.device` or passing a string as an argument",
        "question_markdown": "My data iterator currently runs on the CPU as ```device=0``` argument is deprecated. But I need it to run on the GPU with the rest of the model etc. \r\n\r\nHere is my code: \r\n```\r\npad_idx = TGT.vocab.stoi[&quot;&lt;blank&gt;&quot;]\r\nmodel = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\r\nmodel = model.to(device)\r\ncriterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1)\r\ncriterion = criterion.to(device)\r\nBATCH_SIZE = 12000\r\ntrain_iter = MyIterator(train, device, batch_size=BATCH_SIZE,\r\n                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\r\n                        batch_size_fn=batch_size_fn, train=True)\r\nvalid_iter = MyIterator(val, device, batch_size=BATCH_SIZE,\r\n                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\r\n                        batch_size_fn=batch_size_fn, train=False)\r\n#model_par = nn.DataParallel(model, device_ids=devices)\r\n```\r\n\r\nThe above code gives this error: \r\n```\r\nThe `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\r\nThe `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\r\n```\r\n\r\nI have tried passing in ```&#39;cuda&#39;``` as an argument instead of ```device=0``` but I receive this error:\r\n ```TypeError                                 Traceback (most recent call last)\r\n&lt;ipython-input-50-da3b1f7ed907&gt; in &lt;module&gt;()\r\n     10     train_iter = MyIterator(train, &#39;cuda&#39;, batch_size=BATCH_SIZE,\r\n     11                             repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\r\n---&gt; 12                             batch_size_fn=batch_size_fn, train=True)\r\n     13     valid_iter = MyIterator(val, &#39;cuda&#39;, batch_size=BATCH_SIZE,\r\n     14                             repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\r\n\r\nTypeError: __init__() got multiple values for argument &#39;batch_size&#39;\r\n```\r\nI have also tried passing in ```device``` as an argument. Device being defined as ```device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)```\r\n\r\nBut receive the same error as just above. \r\n\r\nAny suggestions would be much appreciated, thanks.",
        "accepted_answer_markdown": "```\r\npad_idx = TGT.vocab.stoi[&quot;&lt;blank&gt;&quot;]\r\nmodel = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\r\nmodel = model.to(device)\r\ncriterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1)\r\ncriterion = criterion.to(device)\r\nBATCH_SIZE = 12000\r\ntrain_iter = MyIterator(train, batch_size=BATCH_SIZE, device = torch.device(&#39;cuda&#39;),\r\n                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\r\n                        batch_size_fn=batch_size_fn, train=True)\r\nvalid_iter = MyIterator(val, batch_size=BATCH_SIZE, device = torch.device(&#39;cuda&#39;),\r\n                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\r\n                        batch_size_fn=batch_size_fn, train=False)\r\n```\r\n\r\nAfter lot&#39;s of trial and error I managed to set ```device``` as  ```device = torch.device(&#39;cuda&#39;)``` instead of ```device=0```"
    },
    {
        "question_id": "55914172",
        "accepted_answer_id": "55914346",
        "question_title": "PyTorch: _thnn_nll_loss_forward is not implemented for type torch.LongTensor",
        "question_markdown": "When trying to create a model using PyTorch, when I am trying to implement the loss function `nll_loss`, it is throwing the following error\r\n```python\r\nRuntimeError: _thnn_nll_loss_forward is not implemented for type torch.LongTensor \r\n```\r\nThe fit function I have created is:\r\n```python\r\nfor epoch in tqdm_notebook(range(1, epochs+1)):\r\n    for batch_idx, (data, targets) in enumerate(train_loader):\r\n        optimizer.zero_grad()\r\n        net.float()\r\n        output = net(data)\r\n        output_x = output.argmax(dim=2) #to convert (64,50,43) -&gt; (64, 50)\r\n        loss = F.nll_loss(output_x, targets)\r\n        loss.backward()\r\n        optimizer.step()\r\n        if batch_idx % 100 == 0:\r\n            print(&#39;Train epochs: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}&#39;.format(\r\n                epoch, batch_idx*len(data), len(ds.data),\r\n                100.*batch_idx / len(ds), loss.item()\r\n            ))\r\n```\r\n\r\nWhere the output and targets&#39; shape is _(64, 50)_ and the dtypes are `torch.int64` for both.",
        "accepted_answer_markdown": "Look at the [description][1] of `F.nll_loss`. It expects to get as input not the `argmax` of the prediction (type `torch.long`), but rather the full 64x50x43 prediction vectors (of type `torch.float`). Note that indeed the prediction you provide to `F.nll_loss` has an extra dimension more than the ground truth targets you provide.\r\n\r\nIn your case, simply remove the argmax:\r\n\r\n    loss = F.nll_loss(output, targets)\r\n\r\n [1]: https://pytorch.org/docs/stable/nn.html#torch.nn.functional.nll_loss"
    },
    {
        "question_id": "56010551",
        "accepted_answer_id": "56010862",
        "question_title": "pytorch embedding index out of range",
        "question_markdown": "I&#39;m following this tutorial here https://cs230-stanford.github.io/pytorch-nlp.html. In there a neural model is created, using `nn.Module`, with an embedding layer, which is initialized here\r\n\r\n    self.embedding = nn.Embedding(params[&#39;vocab_size&#39;], params[&#39;embedding_dim&#39;])\r\n\r\n`vocab_size` is the total number of training samples, which is 4000.  `embedding_dim` is 50.  The relevant piece of the `forward` method is below\r\n\r\n    def forward(self, s):\r\n            # apply the embedding layer that maps each token to its embedding\r\n            s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\r\n\r\nI get this exception when passing a batch to the model like so\r\n`model(train_batch)`\r\n`train_batch` is a numpy array of dimension `batch_size`x`batch_max_len`.  Each sample is a sentence, and each sentence is padded so that it has the length of the longest sentence in the batch.\r\n&gt; File\r\n&gt; &quot;/Users/liam_adams/Documents/cs512/research_project/custom/model.py&quot;,\r\n&gt; line 34, in forward\r\n&gt;     s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim   File\r\n&gt; &quot;/Users/liam_adams/Documents/cs512/venv_research/lib/python3.7/site-packages/torch/nn/modules/module.py&quot;,\r\n&gt; line 493, in __call__\r\n&gt;     result = self.forward(*input, **kwargs)   File &quot;/Users/liam_adams/Documents/cs512/venv_research/lib/python3.7/site-packages/torch/nn/modules/sparse.py&quot;,\r\n&gt; line 117, in forward\r\n&gt;     self.norm_type, self.scale_grad_by_freq, self.sparse)   File &quot;/Users/liam_adams/Documents/cs512/venv_research/lib/python3.7/site-packages/torch/nn/functional.py&quot;,\r\n&gt; line 1506, in embedding\r\n&gt;     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse) RuntimeError: index out of range at\r\n&gt; ../aten/src/TH/generic/THTensorEvenMoreMath.cpp:193\r\n\r\nIs the problem here that the embedding is initialized with different dimensions than those of my batch array?  My `batch_size` will be constant but `batch_max_len` will change with every batch. This is how its done in the tutorial.",
        "accepted_answer_markdown": "Found the answer here https://discuss.pytorch.org/t/embeddings-index-out-of-range-error/12582\r\n\r\nI&#39;m converting words to indexes, but I had the indexes based off the total number of words, not `vocab_size` which is a smaller set of the most frequent words."
    },
    {
        "question_id": "64263839",
        "accepted_answer_id": "64264237",
        "question_title": "How to restructure the output tensor of a cnn layer for use by a linear layer in a simple pytorch model",
        "question_markdown": "Given a `pytorch` input dataset  with dimensions:\r\n\r\n    dat.shape = torch.Size([128, 3, 64, 64])\r\n\r\n\r\n[![enter image description here][1]][1]\r\n\r\nThis is a supervised learning problem: we have a separate `labels.txt` file containing one of `C` classes for each input observation.  The value of `C` is calculated by the number of distinct values in the labeles file and is presently in the single digits.\r\n\r\nI could use assistance on how to mesh the layers of a simple mix of convolutional and linear layers network that is performing multiclass classification.  The intent is to pass through:\r\n\r\n*  two cnn layers with maxpooling after each\r\n* a linear &quot;readout&quot; layer\r\n* softmax activation before the output/labels \r\n\r\nHere is the core of my (faulty/broken) network.  I am unable to determine the proper size/shape required of:\r\n\r\n     Output of Convolutional layer -&gt; Input of Linear [Readout] layer\r\n\r\n\r\n```\r\nclass CNNClassifier(torch.nn.Module):\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.conv1 = nn.Conv2d(3, 16, 3)\r\n        self.maxpool = nn.MaxPool2d(kernel_size=3,padding=1)\r\n        self.conv2 = nn.Conv2d(16, 32, 3)\r\n        self.linear1 = nn.Linear(32*16*16, C)\r\n        self.softmax1 = nn.LogSoftmax(dim=1)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.maxpool(F.leaky_relu(x))\r\n        x = self.conv2(x)\r\n        x = self.maxpool(F.leaky_relu(x))\r\n        x = self.linear1(x)  # Size mismatch error HERE \r\n        x = self.softmax1(x)\r\n        return x\r\n```\r\n\r\nTraining of the model is started by : \r\n\r\n            Xout = model(dat)\r\n\r\nThis results in : \r\n\r\n&gt; RuntimeError: size mismatch, m1: [128 x 1568], m2: [8192 x 6] \r\n\r\nat the `linear1` input.  What is needed here ? Note I have seen uses of wildcard input sizes e.g via a `view`:\r\n\r\n        ..\r\n        x = x.view(x.size(0), -1)\r\n        x = self.linear1(x)  # Size mismatch error HERE \r\n\r\nIf that is included then the error changes to \r\n\r\n&gt; RuntimeError: size mismatch, m1: [28672 x 7], m2: [8192 x 6] \r\n\r\nSome pointers on how to think about and calculate the cnn layer / linear layer input/output sizes would be much appreciated.\r\n\r\n\r\n  [1]: https://i.sstatic.net/73aAbs.png",
        "accepted_answer_markdown": "## The error\r\n\r\nYou have miscalculated the output size from convolutional stack. It is actually `[batch, 32, 7, 7]` instead of `[batch, 32, 16, 16]`.\r\n\r\nYou have to use `reshape` (or `view`) as output from `Conv2d` has 4 dimensions (`[batch, channels, width, height]`), while input to `nn.Linear` is required to have 2 dimensions (`[batch, features]`).\r\n\r\nUse this for `nn.Linear`:\r\n\r\n    self.linear1 = nn.Linear(32 * 7 * 7, C)\r\n\r\nAnd this in `forward`:\r\n\r\n    x = self.linear1(x.view(x.shape[0], -1))\r\n\r\n## Other possibilities\r\n\r\nCurrent new architectures use pooling across channels (usually called global pooling). In PyTorch there is an [`torch.nn.AdaptiveAvgPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html) (or `Max` pooling). Using this approach allows you to have variable size of height and width of your input image as only one value per channel is used as input to `nn.Linear`. This is how it looks:\r\n\r\n    class CNNClassifier(torch.nn.Module):\r\n        def __init__(self, C=10):\r\n            super().__init__()\r\n            self.conv1 = nn.Conv2d(3, 16, 3)\r\n            self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1)\r\n            self.conv2 = nn.Conv2d(16, 32, 3)\r\n            self.pooling = torch.nn.AdaptiveAvgPool2d(output_size=1)\r\n            self.linear1 = nn.Linear(32, C)\r\n            self.softmax1 = nn.LogSoftmax(dim=1)\r\n    \r\n        def forward(self, x):\r\n            x = self.conv1(x)\r\n            x = self.maxpool(F.leaky_relu(x))\r\n            x = self.conv2(x)\r\n            x = self.maxpool(F.leaky_relu(x))\r\n            x = self.linear1(self.pooling(x).view(x.shape[0], -1))\r\n            x = self.softmax1(x)\r\n            return x\r\n\r\nSo now images of `torch.Size([128, 3, 64, 64])` and `torch.Size([128, 3, 128, 128])` can be passed to the network.\r\n\r\n"
    },
    {
        "question_id": "64355112",
        "accepted_answer_id": "64365751",
        "question_title": "retain_graph problem with GRU in Pytorch 1.6",
        "question_markdown": "I am aware that, while employing `loss.backward()` we need to specify `retain_graph=True` if there are multiple networks and multiple loss functions to optimize each network separately. But even with (or without) specifying this parameter I am getting errors. Following is an MWE to reproduce the issue (on PyTorch 1.6).\r\n\r\n```\r\nimport torch\r\nfrom torch import nn\r\nfrom torch import optim\r\ntorch.autograd.set_detect_anomaly(True)\r\n\r\n\r\nclass GRU1(nn.Module):\r\n    def __init__(self):\r\n        super(GRU1, self).__init__()\r\n        self.brnn = nn.GRU(input_size=2, bidirectional=True, num_layers=1, hidden_size=100)\r\n\r\n    def forward(self, x):\r\n        return self.brnn(x)\r\n\r\n\r\nclass GRU2(nn.Module):\r\n    def __init__(self):\r\n        super(GRU2, self).__init__()\r\n        self.brnn = nn.GRU(input_size=200, bidirectional=True, num_layers=1, hidden_size=1)\r\n\r\n    def forward(self, x):\r\n        return self.brnn(x)\r\n\r\ngru1 = GRU1()\r\ngru2 = GRU2()\r\ngru1_opt = optim.Adam(gru1.parameters())\r\ngru2_opt = optim.Adam(gru2.parameters())\r\ncriterion = nn.MSELoss()\r\n\r\n\r\nfor i in range(100):\r\n    gru1_opt.zero_grad()\r\n    gru2_opt.zero_grad()\r\n    vector = torch.randn((15, 100, 2))\r\n    gru1_output, _ = gru1(vector)  # (15, 100, 200)\r\n    loss_gru1 = criterion(gru1_output, torch.randn((15, 100, 200)))\r\n    loss_gru1.backward(retain_graph=True)\r\n    gru1_opt.step()\r\n    gru1_output, _ = gru1(vector)  # (15, 100, 200)\r\n    gru2_output, _ = gru2(gru1_output)  # (15, 100, 2)\r\n    loss_gru2 = criterion(gru2_output, torch.randn((15, 100, 2)))\r\n    loss_gru2.backward(retain_graph=True)\r\n    gru2_opt.step()\r\n    print(f&quot;GRU1 loss: {loss_gru1.item()}, GRU2 loss: {loss_gru2.item()}&quot;)\r\n```\r\nWith `retain_graph` set to `True` I get the error\r\n\r\n```\r\nRuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [100, 300]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!\r\n```\r\n\r\nThe error without the parameter is\r\n\r\n```\r\nRuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.\r\n```\r\nwhich is expected.\r\n\r\nPlease point at what needs to be changed in the above code for it to begin training. Any help is appreciated.",
        "accepted_answer_markdown": "In such a case, one can detach the computation graph to exclude the parameters that don&#39;t need to be optimized. In this case, the computation graph should be detached after the second forward pass with `gru1` i.e. \r\n\r\n    ....\r\n    gru1_opt.step()\r\n    gru1_output, _ = gru1(vector)\r\n    gru1_output = gru1_output.detach()\r\n    ....\r\nThis way, you won&#39;t &quot;try to backward through the graph a second time&quot; as the error mentioned."
    },
    {
        "question_id": "64483065",
        "accepted_answer_id": "64526192",
        "question_title": "No module named &#39;parse_config&#39; while tryhing to load checkpoint in PyTorch",
        "question_markdown": "I have a checkpoint file saved after training a model in Pytorch. I have to inspect it in a different module so I tried to load the checkpoint using the following code.\r\n\r\n\r\n\r\n    map_location = lambda storage, loc: storage\r\n    checkpoint = torch.load(&quot;model.pt&quot;, map_location=map_location)\r\n\r\n\r\nBut it is raising `ModuleNotFoundError` issue, which I couldn&#39;t find a way to resolve.\r\n\r\nThe error traceback  :\r\n\r\n    Traceback (most recent call last):\r\n      File &quot;main.py&quot;, line 11, in &lt;module&gt;\r\n        model = loadmodel(hook_feature)\r\n      File &quot;/home/../model_loader.py&quot;, line 21, in loadmodel\r\n        checkpoint = torch.load(settings.MODEL_FILE, map_location=map_location)\r\n      File &quot;/home/../.conda/envs/envreporting/lib/python3.6/site-packages/torch/serialization.py&quot;, line 584, in load\r\n        return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\n      File &quot;/home/../.conda/envs/envreporting/lib/python3.6/site-packages/torch/serialization.py&quot;, line 842, in _load\r\n        result = unpickler.load()\r\n    ModuleNotFoundError: No module named &#39;parse_config&#39;\r\n\r\n\r\nI couldn&#39;t find an already existing issue relevant to this one. \r\n",
        "accepted_answer_markdown": "Is it possible that you have used https://github.com/victoresque/pytorch-template for training the model ? In that case, the project also saves its config in the checkpoint and you also need to import `parse_config.py` file in order to load it."
    },
    {
        "question_id": "64635630",
        "accepted_answer_id": "64638044",
        "question_title": "Pytorch RuntimeError: expected scalar type Float but found Byte",
        "question_markdown": "I am working on the classic example with digits. I want to create a my first neural network that predict the labels of digit images {0,1,2,3,4,5,6,7,8,9}. So the first column of `train.txt` has the labels and all the other columns are the features of each label. I have defined a class to import my data:\r\n\r\n\r\n    class DigitDataset(Dataset):\r\n    \t&quot;&quot;&quot;Digit dataset.&quot;&quot;&quot;\r\n\r\n    \tdef __init__(self, file_path, transform=None):\r\n\t\t    &quot;&quot;&quot;\r\n\t\t    Args:\r\n\t\t\t    csv_file (string): Path to the csv file with annotations.\r\n\t\t\t    root_dir (string): Directory with all the images.\r\n\t\t\t    transform (callable, optional): Optional transform to be applied\r\n\t\t\t    \ton a sample.\r\n\t\t    &quot;&quot;&quot;\r\n\t\t    self.data = pd.read_csv(file_path, header = None, sep =&quot; &quot;)\r\n\t\t    self.transform = transform\r\n    \r\n\t    def __len__(self):\r\n\t\t    return len(self.data)\r\n\r\n\t    def __getitem__(self, idx):\r\n\t\t    if torch.is_tensor(idx):\r\n\t\t\t    idx = idx.tolist()\r\n\r\n\t\t    labels = self.data.iloc[idx,0]\r\n\t\t    images = self.data.iloc[idx,1:-1].values.astype(np.uint8).reshape((1,16,16))\r\n\r\n\t\t    if self.transform is not None:\r\n\t\t     \tsample = self.transform(sample)\r\n\t\t    return images, labels\r\n\r\nAnd then I am running these commands to split my dataset into batches, to define a model and a loss:\r\n\r\n    train_dataset = DigitDataset(&quot;train.txt&quot;)\r\n    train_loader = DataLoader(train_dataset, batch_size=64,\r\n                            shuffle=True, num_workers=4)\r\n\r\n    # Model creation with neural net Sequential model\r\n    model=nn.Sequential(nn.Linear(256, 128), # 1 layer:- 256 input 128 o/p\r\n                        nn.ReLU(),          # Defining Regular linear unit as activation\r\n                        nn.Linear(128,64),  # 2 Layer:- 128 Input and 64 O/p\r\n                        nn.Tanh(),          # Defining Regular linear unit as activation\r\n                        nn.Linear(64,10),   # 3 Layer:- 64 Input and 10 O/P as (0-9)\r\n                        nn.LogSoftmax(dim=1) # Defining the log softmax to find the probablities \r\n    for the last output unit \r\n                      ) \r\n    \r\n    # defining the negative log-likelihood loss for calculating loss\r\n    criterion = nn.NLLLoss()\r\n\r\n    images, labels = next(iter(train_loader))\r\n    images = images.view(images.shape[0], -1)\r\n    \r\n    logps = model(images) #log probabilities\r\n    loss = criterion(logps, labels) #calculate the NLL-loss\r\n\r\nAnd I take the error:\r\n\r\n    ---------------------------------------------------------------------------\r\n       RuntimeError                              Traceback (most recent call last) \r\n        &lt;ipython-input-2-7f4160c1f086&gt; in &lt;module&gt;\r\n         47 images = images.view(images.shape[0], -1)\r\n         48 \r\n    ---&gt; 49 logps = model(images) #log probabilities\r\n         50 loss = criterion(logps, labels) #calculate the NLL-loss\r\n    \r\n    ~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, \r\n    *input, **kwargs)\r\n        725             result = self._slow_forward(*input, **kwargs)\r\n        726         else:\r\n    --&gt; 727             result = self.forward(*input, **kwargs)\r\n        728         for hook in itertools.chain(\r\n        729                 _global_forward_hooks.values(),\r\n    \r\n    ~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py in forward(self, input)\r\n        115     def forward(self, input):\r\n        116         for module in self:\r\n    --&gt; 117             input = module(input)\r\n        118         return input\r\n        119 \r\n\r\n    ~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, \r\n    *input, **kwargs)\r\n        725             result = self._slow_forward(*input, **kwargs)\r\n        726         else:\r\n    --&gt; 727             result = self.forward(*input, **kwargs)\r\n        728         for hook in itertools.chain(\r\n        729                 _global_forward_hooks.values(),\r\n\r\n     ~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py in forward(self, input)\r\n         91 \r\n         92     def forward(self, input: Tensor) -&gt; Tensor:\r\n    ---&gt; 93         return F.linear(input, self.weight, self.bias)\r\n         94 \r\n         95     def extra_repr(self) -&gt; str:\r\n\r\n     ~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py in linear(input, weight, bias)\r\n       1688     if input.dim() == 2 and bias is not None:\r\n       1689         # fused op is marginally faster\r\n    -&gt; 1690         ret = torch.addmm(bias, input, weight.t())\r\n       1691     else:\r\n       1692         output = input.matmul(weight.t())\r\n\r\n    RuntimeError: expected scalar type Float but found Byte\r\n\r\nDo you know what is wrong? Thank you for your patience and help!",
        "accepted_answer_markdown": "This line is the cause of your error:\r\n\r\n    images = self.data.iloc[idx, 1:-1].values.astype(np.uint8).reshape((1, 16, 16))\r\n\r\n`images` are `uint8` (`byte`) while the neural network needs inputs as floating point in order to calculate gradients (you can&#39;t calculate gradients for backprop using integers as those are not continuous and non-differentiable). \r\n\r\nYou can use `torchvision.transforms.functional.to_tensor` to convert the image into `float` and into `[0, 1]` like this:\r\n\r\n    import torchvision\r\n    \r\n    images = torchvision.transforms.functional.to_tensor(\r\n        self.data.iloc[idx, 1:-1].values.astype(np.uint8).reshape((1, 16, 16))\r\n    )\r\n\r\nor simply divide by `255` to get values into `[0, 1]`.\r\n\r\n\r\n"
    },
    {
        "question_id": "64948852",
        "accepted_answer_id": "65047753",
        "question_title": "How to solve the ValueError importing torch in python",
        "question_markdown": "After installing pytorch package, I have tried to import pytorch with\r\n\r\n    import torch\r\n\r\nbut got the error\r\n\r\n    Traceback (most recent call last):\r\n      File &quot;&lt;console&gt;&quot;, line 1, in &lt;module&gt;\r\n      File &quot;c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\__init__.py&quot;, line 190, in &lt;module&gt;\r\n        from torch._C import *\r\n    ValueError: module functions cannot set METH_CLASS or METH_STATIC\r\n\r\nfrom searching, I have read that this could be about numpy. So I have tried uninstalling and installing with those\r\n\r\n    pip uninstall numpy\r\n    pip install numpy -I\r\n    pip install numpy -U\r\n\r\nIt didn&#39;t work.\r\n\r\nI would be happy to hear from you if you have any idea why such an error occurs and how to correct it?\r\n\r\n\r\nin case needed: Python version 3.8.6 ,\r\ntorch version 1.7.0 ,\r\nnumpy version 1.19.4",
        "accepted_answer_markdown": "The latest version of numpy for the moment is 1.19.4\r\n\r\nI have uninstalled numpy and installed 1.19.3 version. After a complete restart of the system. The error does not show anymore. Thanks."
    },
    {
        "question_id": "65023526",
        "accepted_answer_id": "65052927",
        "question_title": "RuntimeError: The size of tensor a (4000) must match the size of tensor b (512) at non-singleton dimension 1",
        "question_markdown": "I&#39;m trying to build a model for document classification. I&#39;m using `BERT` with `PyTorch`.\r\n\r\nI got the bert model with below code.\r\n\r\n    bert = AutoModel.from_pretrained(&#39;bert-base-uncased&#39;)\r\n\r\nThis is the code for training.\r\n\r\n    for epoch in range(epochs):\r\n     \r\n        print(&#39;\\n Epoch {:} / {:}&#39;.format(epoch + 1, epochs))\r\n    \r\n        #train model\r\n        train_loss, _ = modhelper.train(proc.train_dataloader)\r\n    \r\n        #evaluate model\r\n        valid_loss, _ = modhelper.evaluate()\r\n    \r\n        #save the best model\r\n        if valid_loss &lt; best_valid_loss:\r\n            best_valid_loss = valid_loss\r\n            torch.save(modhelper.model.state_dict(), &#39;saved_weights.pt&#39;)\r\n    \r\n        # append training and validation loss\r\n        train_losses.append(train_loss)\r\n        valid_losses.append(valid_loss)\r\n    \r\n        print(f&#39;\\nTraining Loss: {train_loss:.3f}&#39;)\r\n        print(f&#39;Validation Loss: {valid_loss:.3f}&#39;)\r\n\r\nthis is my train method, accessible with the object `modhelper`. \r\n\r\n    def train(self, train_dataloader):\r\n        self.model.train()\r\n        total_loss, total_accuracy = 0, 0\r\n        \r\n        # empty list to save model predictions\r\n        total_preds=[]\r\n        \r\n            # iterate over batches\r\n        for step, batch in enumerate(train_dataloader):\r\n            \r\n            # progress update after every 50 batches.\r\n            if step % 50 == 0 and not step == 0:\r\n                print(&#39;  Batch {:&gt;5,}  of  {:&gt;5,}.&#39;.format(step, len(train_dataloader)))\r\n            \r\n            # push the batch to gpu\r\n            #batch = [r.to(device) for r in batch]\r\n            \r\n            sent_id, mask, labels = batch\r\n            \r\n            # clear previously calculated gradients \r\n            self.model.zero_grad()        \r\n\r\n            print(sent_id.size(), mask.size())\r\n            # get model predictions for the current batch\r\n            preds = self.model(sent_id, mask) #This line throws the error\r\n            \r\n            # compute the loss between actual and predicted values\r\n            self.loss = self.cross_entropy(preds, labels)\r\n            \r\n            # add on to the total loss\r\n            total_loss = total_loss + self.loss.item()\r\n            \r\n            # backward pass to calculate the gradients\r\n            self.loss.backward()\r\n            \r\n            # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\r\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\r\n            \r\n            # update parameters\r\n            self.optimizer.step()\r\n            \r\n            # model predictions are stored on GPU. So, push it to CPU\r\n            #preds=preds.detach().cpu().numpy()\r\n            \r\n            # append the model predictions\r\n            total_preds.append(preds)\r\n          \r\n        # compute the training loss of the epoch\r\n        avg_loss = total_loss / len(train_dataloader)\r\n        \r\n        # predictions are in the form of (no. of batches, size of batch, no. of classes).\r\n        # reshape the predictions in form of (number of samples, no. of classes)\r\n        total_preds  = np.concatenate(total_preds, axis=0)\r\n          \r\n        #returns the loss and predictions\r\n        return avg_loss, total_preds\r\n\r\n`preds = self.model(sent_id, mask)` this line throws the following error(including full traceback).\r\n\r\n     Epoch 1 / 1\r\n    torch.Size([32, 4000]) torch.Size([32, 4000])\r\n    Traceback (most recent call last):\r\n\r\n    File &quot;&lt;ipython-input-39-17211d5a107c&gt;&quot;, line 8, in &lt;module&gt;\r\n    train_loss, _ = modhelper.train(proc.train_dataloader)\r\n\r\n    File &quot;E:\\BertTorch\\model.py&quot;, line 71, in train\r\n    preds = self.model(sent_id, mask)\r\n\r\n    File &quot;E:\\BertTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n\r\n    File &quot;E:\\BertTorch\\model.py&quot;, line 181, in forward\r\n    #pass the inputs to the model\r\n\r\n    File &quot;E:\\BertTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n\r\n    File &quot;E:\\BertTorch\\venv\\lib\\site-packages\\transformers\\modeling_bert.py&quot;, line 837, in forward\r\n    embedding_output = self.embeddings(\r\n\r\n    File &quot;E:\\BertTorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py&quot;, line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n\r\n    File &quot;E:\\BertTorch\\venv\\lib\\site-packages\\transformers\\modeling_bert.py&quot;, line 201, in forward\r\n    embeddings = inputs_embeds + position_embeddings + token_type_embeddings\r\n\r\n    RuntimeError: The size of tensor a (4000) must match the size of tensor b (512) at non-singleton dimension 1\r\n\r\nIf you observe I&#39;ve printed the torch size in the code.\r\n`print(sent_id.size(), mask.size())`\r\n\r\nThe output of that line of code is `torch.Size([32, 4000]) torch.Size([32, 4000])`.\r\n\r\nas we can see that size is the same but it throws the error. Please put your thoughts. Really appreciate it.\r\n\r\nplease comment if you need further information. I&#39;ll be quick to add whatever is required.\r\n",
        "accepted_answer_markdown": "The issue is regarding the BERT&#39;s limitation with the word count. I&#39;ve passed the word count as 4000 where the maximum supported is 512(have to give up 2 more for &#39;[cls]&#39; &amp; &#39;[Sep]&#39; at the beginning and the end of the string, so it is 510 only). Reduce the word count or use some other model for your promlem. something like [Longformers][1] as suggested by @cronoik in the comments above.\r\n\r\nThanks.\r\n\r\n\r\n  [1]: https://medium.com/dair-ai/longformer-what-bert-should-have-been-78f4cd595be9"
    },
    {
        "question_id": "65066981",
        "accepted_answer_id": "65077272",
        "question_title": "Pytorch ValueError: Expected target size (2, 13), got torch.Size([2]) when calling CrossEntropyLoss",
        "question_markdown": "I am trying to train a Pytorch LSTM network, but I&#39;m getting ```ValueError: Expected target size (2, 13), got torch.Size([2])``` when I try to calculate CrossEntropyLoss. I think I need to change the shape somewhere, but I can&#39;t figure out where.\r\n\r\nHere is my network definition:\r\n```\r\nclass LSTM(nn.Module):\r\n\r\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.2):\r\n        super(LSTM, self).__init__()\r\n\r\n        # network size parameters\r\n        self.n_layers = n_layers\r\n        self.hidden_dim = hidden_dim\r\n        self.vocab_size = vocab_size\r\n        self.embedding_dim = embedding_dim\r\n\r\n\r\n        # the layers of the network\r\n        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\r\n        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim, self.n_layers, dropout=drop_prob, batch_first=True)\r\n        self.dropout = nn.Dropout(drop_prob)\r\n        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\r\n\r\n\r\n\r\n    def forward(self, input, hidden):\r\n        # Perform a forward pass of the model on some input and hidden state.\r\n        batch_size = input.size(0)\r\n        print(f&#39;batch_size: {batch_size}&#39;)\r\n\r\n        print(Input shape: {input.shape}&#39;)\r\n\r\n        # pass through embeddings layer\r\n        embeddings_out = self.embedding(input)\r\n        print(f&#39;Shape after Embedding: {embeddings_out.shape}&#39;)\r\n\r\n\r\n        # pass through LSTM layers\r\n        lstm_out, hidden = self.lstm(embeddings_out, hidden)\r\n        print(f&#39;Shape after LSTM: {lstm_out.shape}&#39;)\r\n\r\n\r\n        # pass through dropout layer\r\n        dropout_out = self.dropout(lstm_out)\r\n        print(f&#39;Shape after Dropout: {dropout_out.shape}&#39;)\r\n\r\n\r\n        #pass through fully connected layer\r\n        fc_out = self.fc(dropout_out)\r\n        print(f&#39;Shape after FC: {fc_out.shape}&#39;)\r\n\r\n        # return output and hidden state\r\n        return fc_out, hidden\r\n\r\n\r\n    def init_hidden(self, batch_size):\r\n        #Initializes hidden state\r\n        # Create two new tensors `with sizes n_layers x batch_size x hidden_dim,\r\n        # initialized to zero, for hidden state and cell state of LSTM\r\n\r\n\r\n        hidden = (torch.zeros(self.n_layers, batch_size, self.hidden_dim), torch.zeros(self.n_layers, batch_size, self.hidden_dim))\r\n        return hidden\r\n```\r\nI added comments stating the shape of the network at each spot. My data is in a TensorDataset called training_dataset with two attributes, features and labels. Features has shape torch.Size([97, 3]), and \r\nlabels has shape: torch.Size([97]).\r\n\r\nThis is the code for the network training:\r\n```\r\n# Size parameters\r\nvocab_size = 13\r\nembedding_dim = 256\r\nhidden_dim = 256       \r\nn_layers = 2     \r\n\r\n# Training parameters\r\nepochs = 3\r\nlearning_rate = 0.001\r\nclip = 1\r\nbatch_size = 2\r\n\r\n\r\ntraining_loader = DataLoader(training_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\r\n\r\nnet = LSTM(vocab_size, embedding_dim, hidden_dim, n_layers)\r\noptimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\r\nloss_func = torch.nn.CrossEntropyLoss()\r\n\r\nnet.train()\r\nfor e in range(epochs):\r\n    print(f&#39;Epoch {e}&#39;)\r\n    print(batch_size)\r\n    hidden = net.init_hidden(batch_size)\r\n\r\n    # loops through each batch\r\n    for features, labels in training_loader:\r\n\r\n        # resets training history\r\n        hidden = tuple([each.data for each in hidden])\r\n        net.zero_grad()\r\n\r\n        # computes gradient of loss from backprop\r\n        output, hidden = net.forward(features, hidden)\r\n        loss = loss_func(output, labels)\r\n        loss.backward()\r\n\r\n        # using clipping to avoid exploding gradient\r\n        nn.utils.clip_grad_norm_(net.parameters(), clip)\r\n        optimizer.step()\r\n ```\r\nWhen I try to run the training I get the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File &quot;train.py&quot;, line 75, in &lt;module&gt;\r\n    loss = loss_func(output, labels)\r\n  File &quot;/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File &quot;/usr/local/lib/python3.8/site-packages/torch/nn/modules/loss.py&quot;, line 947, in forward\r\n    return F.cross_entropy(input, target, weight=self.weight,\r\n  File &quot;/usr/local/lib/python3.8/site-packages/torch/nn/functional.py&quot;, line 2422, in cross_entropy\r\n    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\r\n  File &quot;/usr/local/lib/python3.8/site-packages/torch/nn/functional.py&quot;, line 2227, in nll_loss\r\n    raise ValueError(&#39;Expected target size {}, got {}&#39;.format(\r\nValueError: Expected target size (2, 13), got torch.Size([2])\r\n```\r\nAlso here is the result of the print statements:\r\n```\r\nbatch_size: 2\r\nInput shape: torch.Size([2, 3])\r\nShape after Embedding: torch.Size([2, 3, 256])\r\nShape after LSTM: torch.Size([2, 3, 256])\r\nShape after Dropout: torch.Size([2, 3, 256])\r\nShape after FC: torch.Size([2, 3, 13])\r\n```\r\n\r\nThere is some kind of shape error happening, but I can&#39;t figure out where. Any help would be appreciated. If relevant I&#39;m using Python 3.8.5 and Pytorch 1.6.0.",
        "accepted_answer_markdown": "To anyone coming across this in the future, I asked this same question on the pytorch forums and got a great answer thanks to ptrblock, found [here](https://discuss.pytorch.org/t/crossentropyloss-valueerror-expected-target-size-2-13-got-torch-size-2/104580/2?u=christian-doucette).\r\n\r\nThe issue is that my LSTM layer had batch_first=True, which means that it returns the outputs of every member of the input sequence (size of (batch_size, sequence_size, vocab_size)). But, I only want the output of the last member of the input sequence (size of (batch_size, vocab_size). \r\n\r\nSo, in my forward function, instead of\r\n```\r\n# pass through LSTM layers\r\nlstm_out, hidden = self.lstm(embeddings_out, hidden)\r\n```\r\nit should be\r\n```\r\n# pass through LSTM layers\r\nlstm_out, hidden = self.lstm(embeddings_out, hidden)\r\n\r\n# slice lstm_out to just get output of last element of the input sequence\r\nlstm_out = lstm_out[:, -1]\r\n```\r\n\r\nThis solved the shape issue. The error message was kind of misleading since it said that the target was the wrong shape, when really the output was the wrong shape."
    },
    {
        "question_id": "65144346",
        "accepted_answer_id": "65620603",
        "question_title": "Feeding Multiple Inputs to LSTM for Time-Series Forecasting using PyTorch",
        "question_markdown": "I&#39;m currently working on building an LSTM network to forecast time-series data using PyTorch. Following [Roman&#39;s blog post](https://romanorac.github.io/machine/learning/2019/09/27/time-series-prediction-with-lstm.html), I implemented a simple LSTM for univariate time-series data, please see the class definitions below. However, it&#39;s been a few days since I ground to a halt on adding more features to the input data, say an hour of the day, day of the week, week of the year, and sorts.\r\n\r\n```\r\nclass Model(nn.Module):\r\n    def __init__(self, input_size, hidden_size, output_size):\r\n        super(Model, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.output_size = output_size\r\n        self.lstm = nn.LSTMCell(self.input_size, self.hidden_size)\r\n        self.linear = nn.Linear(self.hidden_size, self.output_size)\r\n\r\n    def forward(self, input, future=0, y=None):\r\n        outputs = []\r\n\r\n        # reset the state of LSTM\r\n        # the state is kept till the end of the sequence\r\n        h_t = torch.zeros(input.size(0), self.hidden_size, dtype=torch.float32)\r\n        c_t = torch.zeros(input.size(0), self.hidden_size, dtype=torch.float32)\r\n\r\n        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\r\n            h_t, c_t = self.lstm(input_t, (h_t, c_t))\r\n            output = self.linear(h_t)\r\n            outputs += [output]\r\n\r\n        for i in range(future):\r\n            if y is not None and random.random() &gt; 0.5:\r\n                output = y[:, [i]]  # teacher forcing\r\n            h_t, c_t = self.lstm(output, (h_t, c_t))\r\n            output = self.linear(h_t)\r\n            outputs += [output]\r\n        outputs = torch.stack(outputs, 1).squeeze(2)\r\n        return outputs\r\n\r\n\r\nclass Optimization:\r\n    &quot;A helper class to train, test and diagnose the LSTM&quot;\r\n\r\n    def __init__(self, model, loss_fn, optimizer, scheduler):\r\n        self.model = model\r\n        self.loss_fn = loss_fn\r\n        self.optimizer = optimizer\r\n        self.scheduler = scheduler\r\n        self.train_losses = []\r\n        self.val_losses = []\r\n        self.futures = []\r\n\r\n    @staticmethod\r\n    def generate_batch_data(x, y, batch_size):\r\n        for batch, i in enumerate(range(0, len(x) - batch_size, batch_size)):\r\n            x_batch = x[i : i + batch_size]\r\n            y_batch = y[i : i + batch_size]\r\n            yield x_batch, y_batch, batch\r\n\r\n    def train(\r\n        self,\r\n        x_train,\r\n        y_train,\r\n        x_val=None,\r\n        y_val=None,\r\n        batch_size=100,\r\n        n_epochs=20,\r\n        dropout=0.2,\r\n        do_teacher_forcing=None,\r\n    ):\r\n        seq_len = x_train.shape[1]\r\n        for epoch in range(n_epochs):\r\n            start_time = time.time()\r\n            self.futures = []\r\n\r\n            train_loss = 0\r\n            for x_batch, y_batch, batch in self.generate_batch_data(x_train, y_train, batch_size):\r\n                y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing)\r\n                self.optimizer.zero_grad()\r\n                loss = self.loss_fn(y_pred, y_batch)\r\n                loss.backward()\r\n                self.optimizer.step()\r\n                train_loss += loss.item()\r\n            self.scheduler.step()\r\n            train_loss /= batch\r\n            self.train_losses.append(train_loss)\r\n\r\n            self._validation(x_val, y_val, batch_size)\r\n\r\n            elapsed = time.time() - start_time\r\n            print(\r\n                &quot;Epoch %d Train loss: %.2f. Validation loss: %.2f. Avg future: %.2f. Elapsed time: %.2fs.&quot;\r\n                % (epoch + 1, train_loss, self.val_losses[-1], np.average(self.futures), elapsed)\r\n            )\r\n\r\n    def _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing):\r\n        if do_teacher_forcing:\r\n            future = random.randint(1, int(seq_len) / 2)\r\n            limit = x_batch.size(1) - future\r\n            y_pred = self.model(x_batch[:, :limit], future=future, y=y_batch[:, limit:])\r\n        else:\r\n            future = 0\r\n            y_pred = self.model(x_batch)\r\n        self.futures.append(future)\r\n        return y_pred\r\n\r\n    def _validation(self, x_val, y_val, batch_size):\r\n        if x_val is None or y_val is None:\r\n            return\r\n        with torch.no_grad():\r\n            val_loss = 0\r\n            batch = 1\r\n            for x_batch, y_batch, batch in self.generate_batch_data(x_val, y_val, batch_size):\r\n                y_pred = self.model(x_batch)\r\n                loss = self.loss_fn(y_pred, y_batch)\r\n                val_loss += loss.item()\r\n            val_loss /= batch\r\n            self.val_losses.append(val_loss)\r\n\r\n    def evaluate(self, x_test, y_test, batch_size, future=1):\r\n        with torch.no_grad():\r\n            test_loss = 0\r\n            actual, predicted = [], []\r\n            for x_batch, y_batch, batch in self.generate_batch_data(x_test, y_test, batch_size):\r\n                y_pred = self.model(x_batch, future=future)\r\n                y_pred = (\r\n                    y_pred[:, -len(y_batch) :] if y_pred.shape[1] &gt; y_batch.shape[1] else y_pred\r\n                )\r\n                loss = self.loss_fn(y_pred, y_batch)\r\n                test_loss += loss.item()\r\n                actual += torch.squeeze(y_batch[:, -1]).data.cpu().numpy().tolist()\r\n                predicted += torch.squeeze(y_pred[:, -1]).data.cpu().numpy().tolist()\r\n            test_loss /= batch\r\n            return actual, predicted, test_loss\r\n\r\n    def plot_losses(self):\r\n        plt.plot(self.train_losses, label=&quot;Training loss&quot;)\r\n        plt.plot(self.val_losses, label=&quot;Validation loss&quot;)\r\n        plt.legend()\r\n        plt.title(&quot;Losses&quot;)\r\n\r\n```\r\n\r\nYou can find some of the helper functions that help me split and format data before feeding it to my LSTM network.\r\n\r\n\r\n\r\n```\r\ndef to_dataframe(actual, predicted):\r\n    return pd.DataFrame({&quot;value&quot;: actual, &quot;prediction&quot;: predicted})\r\n\r\ndef inverse_transform(scaler, df, columns):\r\n    for col in columns:\r\n        df[col] = scaler.inverse_transform(df[col])\r\n    return df\r\n\r\ndef split_sequences(sequences, n_steps):\r\n    X, y = list(), list()\r\n    for i in range(len(sequences)):\r\n        # find the end of this pattern\r\n        end_ix = i + n_steps\r\n        # check if we are beyond the dataset\r\n        if end_ix &gt; len(sequences):\r\n            break\r\n        # gather input and output parts of the pattern\r\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\r\n        X.append(seq_x)\r\n        y.append(seq_y)\r\n    return array(X), array(y)\r\n\r\n\r\ndef train_val_test_split_new(df, test_ratio=0.2, seq_len = 100):\r\n    y = df[&#39;value&#39;]\r\n    X = df.drop(columns = [&#39;value&#39;])\r\n    tarin_ratio = 1 - test_ratio\r\n    val_ratio = 1 - ((train_ratio - test_ratio) / train_ratio)\r\n\r\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio)\r\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio)\r\n\r\n    return X_train, y_train, X_val, y_val, X_test, y_test\r\n```\r\n\r\nI use the following data frames to train my model.\r\n```\r\n# df_train \r\nvalue\tweekday\tmonthday\thour\r\ntimestamp\t\t\t\t\r\n2014-07-01 00:00:00\t10844\t1\t1\t0\r\n2014-07-01 00:30:00\t8127\t1\t1\t0\r\n2014-07-01 01:00:00\t6210\t1\t1\t1\r\n2014-07-01 01:30:00\t4656\t1\t1\t1\r\n2014-07-01 02:00:00\t3820\t1\t1\t2\r\n...\t...\t...\t...\t...\r\n2015-01-31 21:30:00\t24670\t5\t31\t21\r\n2015-01-31 22:00:00\t25721\t5\t31\t22\r\n2015-01-31 22:30:00\t27309\t5\t31\t22\r\n2015-01-31 23:00:00\t26591\t5\t31\t23\r\n2015-01-31 23:30:00\t26288\t5\t31\t23\r\n10320 rows &#215; 4 columns\r\n\r\n# x_train \r\nweekday\tmonthday\thour\r\ntimestamp\t\t\t\r\n2014-08-26 16:30:00\t1\t26\t16\r\n2014-08-18 16:30:00\t0\t18\t16\r\n2014-10-22 20:00:00\t2\t22\t20\r\n2014-12-10 08:00:00\t2\t10\t8\r\n2014-07-27 22:00:00\t6\t27\t22\r\n...\t...\t...\t...\r\n2014-08-24 05:30:00\t6\t24\t5\r\n2014-11-24 12:00:00\t0\t24\t12\r\n2014-12-18 06:00:00\t3\t18\t6\r\n2014-07-27 17:00:00\t6\t27\t17\r\n2014-12-05 21:00:00\t4\t5\t21\r\n6192 rows &#215; 3 columns\r\n\r\n# y_train \r\ntimestamp\r\n2014-08-26 16:30:00    14083\r\n2014-08-18 16:30:00    14465\r\n2014-10-22 20:00:00    25195\r\n2014-12-10 08:00:00    21348\r\n2014-07-27 22:00:00    16356\r\n                       ...  \r\n2014-08-24 05:30:00     2948\r\n2014-11-24 12:00:00    16292\r\n2014-12-18 06:00:00     7029\r\n2014-07-27 17:00:00    18883\r\n2014-12-05 21:00:00    26284\r\nName: value, Length: 6192, dtype: int64\r\n```\r\n\r\nAfter transforming and splitting time-series data into smaller batches, the training data set for X and y becomes as follows: \r\n\r\n```\r\nX_data shape is (6093, 100, 3)\r\ny_data shape is (6093,)\r\ntensor([[[-1.0097,  1.1510,  0.6508],\r\n         [-1.5126,  0.2492,  0.6508],\r\n         [-0.5069,  0.7001,  1.2238],\r\n         ...,\r\n         [ 1.5044, -1.4417, -1.6413],\r\n         [ 1.0016, -0.0890,  0.7941],\r\n         [ 1.5044, -0.9908, -0.2087]],\r\n\r\n        [[-1.5126,  0.2492,  0.6508],\r\n         [-0.5069,  0.7001,  1.2238],\r\n         [-0.5069, -0.6526, -0.4952],\r\n         ...,\r\n         [ 1.0016, -0.0890,  0.7941],\r\n         [ 1.5044, -0.9908, -0.2087],\r\n         [ 0.4988,  0.5874,  0.5076]],\r\n\r\n        [[-0.5069,  0.7001,  1.2238],\r\n         [-0.5069, -0.6526, -0.4952],\r\n         [ 1.5044,  1.2637,  1.5104],\r\n         ...,\r\n         [ 1.5044, -0.9908, -0.2087],\r\n         [ 0.4988,  0.5874,  0.5076],\r\n         [ 0.4988,  0.5874, -0.6385]],\r\n\r\n        ...,\r\n\r\n        [[ 1.0016,  0.9255, -1.2115],\r\n         [-1.0097, -0.9908,  1.0806],\r\n         [-0.0041,  0.8128,  0.3643],\r\n         ...,\r\n         [ 1.5044,  0.9255, -0.9250],\r\n         [-1.5126,  0.9255,  0.0778],\r\n         [-0.0041,  0.2492, -0.7818]],\r\n\r\n        [[-1.0097, -0.9908,  1.0806],\r\n         [-0.0041,  0.8128,  0.3643],\r\n         [-0.5069,  1.3765, -0.0655],\r\n         ...,\r\n         [-1.5126,  0.9255,  0.0778],\r\n         [-0.0041,  0.2492, -0.7818],\r\n         [ 1.5044,  1.2637,  0.7941]],\r\n\r\n        [[-0.0041,  0.8128,  0.3643],\r\n         [-0.5069,  1.3765, -0.0655],\r\n         [-0.0041, -1.6672, -0.4952],\r\n         ...,\r\n         [-0.0041,  0.2492, -0.7818],\r\n         [ 1.5044,  1.2637,  0.7941],\r\n         [ 0.4988, -1.2163,  1.3671]]])\r\ntensor([ 0.4424,  0.1169,  0.0148,  ..., -1.1653,  0.5394,  1.6037])\r\n```\r\nFinally, just to check if the dimensions of all these training, validation, and test datasets are correct, I print out their shapes.\r\n\r\n```\r\ntrain shape is: torch.Size([6093, 100, 3])\r\ntrain label shape is: torch.Size([6093])\r\nval shape is: torch.Size([1965, 100, 3])\r\nval label shape is: torch.Size([1965])\r\ntest shape is: torch.Size([1965, 100, 3])\r\ntest label shape is: torch.Size([1965])\r\n```\r\n\r\nWhen I try to build the model as follows, I end up getting a RuntimeError pointing at inconsistent input sizes. \r\n\r\n```\r\nmodel_params = {&#39;train_ratio&#39;: 0.8, \r\n                &#39;validation_ratio&#39;: 0.2,\r\n                &#39;sequence_length&#39;: 100,\r\n                &#39;teacher_forcing&#39;: False,\r\n                &#39;dropout_rate&#39;: 0.2,\r\n                &#39;batch_size&#39;: 100,\r\n                &#39;num_of_epochs&#39;: 5,\r\n                &#39;hidden_size&#39;: 24,\r\n                &#39;n_features&#39;: 3,\r\n                &#39;learning_rate&#39;: 1e-3\r\n               }\r\n\r\ntrain_ratio = model_params[&#39;train_ratio&#39;]\r\nval_ratio = model_params[&#39;validation_ratio&#39;]\r\nseq_len = model_params[&#39;sequence_length&#39;]\r\nteacher_forcing = model_params[&#39;teacher_forcing&#39;]\r\ndropout_rate = model_params[&#39;dropout_rate&#39;]\r\nbatch_size = model_params[&#39;batch_size&#39;]\r\nn_epochs = model_params[&#39;num_of_epochs&#39;]\r\nhidden_size = model_params[&#39;hidden_size&#39;]\r\nn_features = model_params[&#39;n_features&#39;]\r\nlr = model_params[&#39;learning_rate&#39;]\r\n\r\n\r\nmodel = Model(input_size=n_features, hidden_size=hidden_size, output_size=1)\r\nloss_fn = nn.MSELoss()\r\noptimizer = optim.Adam(model.parameters(), lr=lr)\r\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\r\noptimization = Optimization(model, loss_fn, optimizer, scheduler)\r\n\r\nstart_time = datetime.now()\r\noptimization.train(x_train, y_train, x_val, y_val, \r\n                     batch_size=batch_size, \r\n                     n_epochs=n_epochs,\r\n                     dropout=dropout_rate, \r\n                     do_teacher_forcing=teacher_forcing)\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n&lt;ipython-input-192-6fc406c0113d&gt; in &lt;module&gt;\r\n      6 \r\n      7 start_time = datetime.now()\r\n----&gt; 8 optimization.train(x_train, y_train, x_val, y_val, \r\n      9                      batch_size=batch_size,\r\n     10                      n_epochs=n_epochs,\r\n\r\n&lt;ipython-input-189-c18d20430910&gt; in train(self, x_train, y_train, x_val, y_val, batch_size, n_epochs, dropout, do_teacher_forcing)\r\n     68             train_loss = 0\r\n     69             for x_batch, y_batch, batch in self.generate_batch_data(x_train, y_train, batch_size):\r\n---&gt; 70                 y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing)\r\n     71                 self.optimizer.zero_grad()\r\n     72                 loss = self.loss_fn(y_pred, y_batch)\r\n\r\n&lt;ipython-input-189-c18d20430910&gt; in _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing)\r\n     93         else:\r\n     94             future = 0\r\n---&gt; 95             y_pred = self.model(x_batch)\r\n     96         self.futures.append(future)\r\n     97         return y_pred\r\n\r\n~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py in _call_impl(self, *input, **kwargs)\r\n    725             result = self._slow_forward(*input, **kwargs)\r\n    726         else:\r\n--&gt; 727             result = self.forward(*input, **kwargs)\r\n    728         for hook in itertools.chain(\r\n    729                 _global_forward_hooks.values(),\r\n\r\n&lt;ipython-input-189-c18d20430910&gt; in forward(self, input, future, y)\r\n     17 \r\n     18         for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\r\n---&gt; 19             h_t, c_t = self.lstm(input_t, (h_t, c_t))\r\n     20             output = self.linear(h_t)\r\n     21             outputs += [output]\r\n\r\n~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py in _call_impl(self, *input, **kwargs)\r\n    725             result = self._slow_forward(*input, **kwargs)\r\n    726         else:\r\n--&gt; 727             result = self.forward(*input, **kwargs)\r\n    728         for hook in itertools.chain(\r\n    729                 _global_forward_hooks.values(),\r\n\r\n~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py in forward(self, input, hx)\r\n    963 \r\n    964     def forward(self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None) -&gt; Tuple[Tensor, Tensor]:\r\n--&gt; 965         self.check_forward_input(input)\r\n    966         if hx is None:\r\n    967             zeros = torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py in check_forward_input(self, input)\r\n    789     def check_forward_input(self, input: Tensor) -&gt; None:\r\n    790         if input.size(1) != self.input_size:\r\n--&gt; 791             raise RuntimeError(\r\n    792                 &quot;input has inconsistent input_size: got {}, expected {}&quot;.format(\r\n    793                     input.size(1), self.input_size))\r\n\r\nRuntimeError: input has inconsistent input_size: got 1, expected 3\r\n```\r\nI suspect my current LSTM model class does not support data with multiple features, and I&#39;ve been trying out different approaches lately with no luck so far. Feel free to share your thoughts or point me in the right direction that could help me solve this problem. \r\n\r\nAs suggested by @stackoverflowuser2010, I printed out the shapes of the tensors input_t, h_t and c_t that is fed into the forward step before the error is thrown.\r\n\r\n```\r\ninput_t\r\ntorch.Size([100, 1, 3])\r\nh_t\r\ntorch.Size([100, 24])\r\nc_t\r\ntorch.Size([100, 24])\r\n```",
        "accepted_answer_markdown": "After muddling through for a couple of weeks, I solved the issue. This has been a fruitful journey for me, so I&#39;d like to share what I have discovered. If you&#39;d like to have a look at the complete walk-through with code, please check out [my Medium post][1] on the matter.\r\n\r\nJust as in Pandas, I found that things tend to work faster and smoother when I stick to the PyTorch way. Both libraries rely on NumPy, and I&#39;m sure one can do pretty much all the table and matrix operations explicitly with NumPy arrays and functions. However, doing so does eliminate all the nice abstractions and performance improvements these libraries provide and turn each step into a CS exercise. It&#39;s fun until it isn&#39;t.\r\n\r\nRather than shaping all the training and validation sets manually to pass them to the model, PyTorch&#39;s TensorDataset and DataLoaders classes have immensely helped me. Scaling the feature and target sets for training and validation, we then have NumPy arrays. We can transform these arrays into Tensors and use these Tensors to create our TensorDataset, or a custom Dataset depending on your requirements. Finally, DataLoaders allow us to iterate over such datasets with much less hassle than otherwise as they already provide built-in batching, shuffling, and dropping the last batch options.\r\n\r\n```\r\ntrain_features = torch.Tensor(X_train_arr)\r\ntrain_targets = torch.Tensor(y_train_arr)\r\n\r\nval_features = torch.Tensor(X_val_arr)\r\nval_targets = torch.Tensor(y_val_arr)\r\n\r\ntrain = TensorDataset(train_features, train_targets)\r\ntrain_loader = DataLoader(train, batch_size=64, shuffle=False, drop_last=True)\r\n\r\nval = TensorDataset(val_features, val_targets)\r\nval_loader = DataLoader(val, batch_size=64, shuffle=False, drop_last=True)\r\n```\r\n\r\nAfter transforming our data into iterable datasets, they can later be used to do mini-batch training. Instead of explicitly defining batches or wrestling with matrix operations, we can easily iterate over them via DataLoaders as follows. \r\n\r\n```\r\nmodel = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\r\n\r\ncriterion = nn.MSELoss(reduction=&#39;mean&#39;)\r\noptimizer = optim.Adam(model.parameters(), lr=1e-2)\r\n\r\ntrain_losses = []\r\nval_losses = []\r\ntrain_step = make_train_step(model, criterion, optimizer)\r\ndevice = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;\r\n\r\nfor epoch in range(n_epochs):\r\n    batch_losses = []\r\n    for x_batch, y_batch in train_loader:\r\n        x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\r\n        y_batch = y_batch.to(device)\r\n        loss = train_step(x_batch, y_batch)\r\n        batch_losses.append(loss)\r\n    training_loss = np.mean(batch_losses)\r\n    train_losses.append(training_loss)    \r\n    with torch.no_grad():\r\n        batch_val_losses = []\r\n        for x_val, y_val in val_loader:\r\n            x_val = x_val.view([batch_size, -1, n_features]).to(device)\r\n            y_val = y_val.to(device)        \r\n            model.eval()\r\n            yhat = model(x_val)\r\n            val_loss = criterion(y_val, yhat).item()\r\n            batch_val_losses.append(val_loss)\r\n        validation_loss = np.mean(batch_val_losses)\r\n        val_losses.append(validation_loss)\r\n    \r\n    print(f&quot;[{epoch+1}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}&quot;)\r\n```\r\nAnother cool feature that PyTorch provides is the ```view()``` function, which allows faster and memory-efficient reshaping of tensors. Since I earlier defined my LSTM model with ```batch_first = True```, the batch tensor for the feature set must have the shape of (batch size, time steps, number of features). The line in the code above ```x_batch = x_batch.view([batch_size, -1, n_features]).to(device)``` just does that.\r\n\r\nI hope this answer helps those dealing with similar problems or at least gives an idea of which direction to take. I had changed a lot in the code shared in the original post, but I&#39;ll not put them all here for the sake of simplicity. Feel free to check out the rest of it in my other SO post [here][2].\r\n\r\n\r\n  [1]: https://bkaankuguoglu.medium.com/building-rnn-lstm-and-gru-for-time-series-using-pytorch-a46e5b094e7b\r\n  [2]: https://stackoverflow.com/questions/65596522/lstm-for-time-series-prediction-failing-to-learn-pytorch"
    },
    {
        "question_id": "65205506",
        "accepted_answer_id": "65314347",
        "question_title": "LSTM Autoencoder problems",
        "question_markdown": "### TLDR: \r\nAutoencoder underfits timeseries reconstruction and just predicts average value. \r\n\r\n### Question Set-up:\r\n\r\nHere is a summary of my attempt at a sequence-to-sequence autoencoder. This image was taken from this paper: https://arxiv.org/pdf/1607.00148.pdf\r\n[![enter image description here][1]][1]\r\n\r\n**Encoder:** Standard LSTM layer. Input sequence is encoded in the final hidden state.\r\n\r\n**Decoder:** LSTM Cell (I think!). Reconstruct the sequence one element at a time, starting with the last element `x[N]`. \r\n\r\nDecoder algorithm is as follows for a sequence of length `N`:\r\n1. Get Decoder initial hidden state `hs[N]`: Just use encoder final hidden state.\r\n2. Reconstruct last element in the sequence: `x[N]= w.dot(hs[N]) + b`.\r\n2. Same pattern for other elements: `x[i]= w.dot(hs[i]) + b`\r\n3. use `x[i]` and `hs[i]` as inputs to `LSTMCell` to get `x[i-1]` and `hs[i-1]`\r\n\r\n### Minimum Working Example:\r\n\r\nHere is my implementation, starting with the encoder:\r\n\r\n```\r\nclass SeqEncoderLSTM(nn.Module):\r\n    def __init__(self, n_features, latent_size):\r\n        super(SeqEncoderLSTM, self).__init__()\r\n        \r\n        self.lstm = nn.LSTM(\r\n            n_features, \r\n            latent_size, \r\n            batch_first=True)\r\n        \r\n    def forward(self, x):\r\n        _, hs = self.lstm(x)\r\n        return hs\r\n```\r\nDecoder class:\r\n```\r\nclass SeqDecoderLSTM(nn.Module):\r\n    def __init__(self, emb_size, n_features):\r\n        super(SeqDecoderLSTM, self).__init__()\r\n        \r\n        self.cell = nn.LSTMCell(n_features, emb_size)\r\n        self.dense = nn.Linear(emb_size, n_features)\r\n        \r\n    def forward(self, hs_0, seq_len):\r\n        \r\n        x = torch.tensor([])\r\n        \r\n        # Final hidden and cell state from encoder\r\n        hs_i, cs_i = hs_0\r\n        \r\n        # reconstruct first element with encoder output\r\n        x_i = self.dense(hs_i)\r\n        x = torch.cat([x, x_i])\r\n        \r\n        # reconstruct remaining elements\r\n        for i in range(1, seq_len):\r\n            hs_i, cs_i = self.cell(x_i, (hs_i, cs_i))\r\n            x_i = self.dense(hs_i)\r\n            x = torch.cat([x, x_i])\r\n        return x\r\n```\r\nBringing the two together:\r\n```\r\nclass LSTMEncoderDecoder(nn.Module):\r\n    def __init__(self, n_features, emb_size):\r\n        super(LSTMEncoderDecoder, self).__init__()\r\n        self.n_features = n_features\r\n        self.hidden_size = emb_size\r\n\r\n        self.encoder = SeqEncoderLSTM(n_features, emb_size)\r\n        self.decoder = SeqDecoderLSTM(emb_size, n_features)\r\n    \r\n    def forward(self, x):\r\n        seq_len = x.shape[1]\r\n        hs = self.encoder(x)\r\n        hs = tuple([h.squeeze(0) for h in hs])\r\n        out = self.decoder(hs, seq_len)\r\n        return out.unsqueeze(0)        \r\n```\r\n\r\nAnd here&#39;s my training function:\r\n```\r\ndef train_encoder(model, epochs, trainload, testload=None, criterion=nn.MSELoss(), optimizer=optim.Adam, lr=1e-6,  reverse=False):\r\n\r\n    device = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;\r\n    print(f&#39;Training model on {device}&#39;)\r\n    model = model.to(device)\r\n    opt = optimizer(model.parameters(), lr)\r\n\r\n    train_loss = []\r\n    valid_loss = []\r\n\r\n    for e in tqdm(range(epochs)):\r\n        running_tl = 0\r\n        running_vl = 0\r\n        for x in trainload:\r\n            x = x.to(device).float()\r\n            opt.zero_grad()\r\n            x_hat = model(x)\r\n            if reverse:\r\n                x = torch.flip(x, [1])\r\n            loss = criterion(x_hat, x)\r\n            loss.backward()\r\n            opt.step()\r\n            running_tl += loss.item()\r\n\r\n        if testload is not None:\r\n            model.eval()\r\n            with torch.no_grad():\r\n                for x in testload:\r\n                    x = x.to(device).float()\r\n                    loss = criterion(model(x), x)\r\n                    running_vl += loss.item()\r\n                valid_loss.append(running_vl / len(testload))\r\n            model.train()\r\n            \r\n        train_loss.append(running_tl / len(trainload))\r\n    \r\n    return train_loss, valid_loss\r\n```\r\n### Data:\r\nLarge dataset of events scraped from the news (ICEWS). Various categories exist that describe each event. I initially one-hot encoded these variables, expanding the data to 274 dimensions. However, in order to debug the model, I&#39;ve cut it down to a single sequence that is 14 timesteps long and only contains 5 variables. Here is the sequence I&#39;m trying to overfit:\r\n\r\n```\r\ntensor([[0.5122, 0.0360, 0.7027, 0.0721, 0.1892],\r\n        [0.5177, 0.0833, 0.6574, 0.1204, 0.1389],\r\n        [0.4643, 0.0364, 0.6242, 0.1576, 0.1818],\r\n        [0.4375, 0.0133, 0.5733, 0.1867, 0.2267],\r\n        [0.4838, 0.0625, 0.6042, 0.1771, 0.1562],\r\n        [0.4804, 0.0175, 0.6798, 0.1053, 0.1974],\r\n        [0.5030, 0.0445, 0.6712, 0.1438, 0.1404],\r\n        [0.4987, 0.0490, 0.6699, 0.1536, 0.1275],\r\n        [0.4898, 0.0388, 0.6704, 0.1330, 0.1579],\r\n        [0.4711, 0.0390, 0.5877, 0.1532, 0.2201],\r\n        [0.4627, 0.0484, 0.5269, 0.1882, 0.2366],\r\n        [0.5043, 0.0807, 0.6646, 0.1429, 0.1118],\r\n        [0.4852, 0.0606, 0.6364, 0.1515, 0.1515],\r\n        [0.5279, 0.0629, 0.6886, 0.1514, 0.0971]], dtype=torch.float64)\r\n```\r\n\r\nAnd here is the custom `Dataset` class: \r\n\r\n```\r\nclass TimeseriesDataSet(Dataset):\r\n    def __init__(self, data, window, n_features, overlap=0):\r\n        super().__init__()\r\n        if isinstance(data, (np.ndarray)):\r\n            data = torch.tensor(data)\r\n        elif isinstance(data, (pd.Series, pd.DataFrame)):\r\n            data = torch.tensor(data.copy().to_numpy())\r\n        else: \r\n            raise TypeError(f&quot;Data should be ndarray, series or dataframe. Found {type(data)}.&quot;)\r\n        \r\n        self.n_features = n_features\r\n        self.seqs = torch.split(data, window)\r\n        \r\n    def __len__(self):\r\n        return len(self.seqs)\r\n    \r\n    def __getitem__(self, idx):\r\n        try:    \r\n            return self.seqs[idx].view(-1, self.n_features)\r\n        except TypeError:\r\n            raise TypeError(&quot;Dataset only accepts integer index/slices, not lists/arrays.&quot;)\r\n```\r\n\r\n### Problem:\r\nThe model only learns the average, no matter how complex I make the model or now long I train it. \r\n\r\nPredicted/Reconstruction:\r\n[![enter image description here][2]][2]\r\n\r\nActual:\r\n\r\n[![enter image description here][3]][3]\r\n\r\n### My research:\r\nThis problem is identical to the one discussed in this question: https://stackoverflow.com/questions/54411662/lstm-autoencoder-always-returns-the-average-of-the-input-sequence\r\n\r\nThe problem in that case ended up being that the objective function was averaging the target timeseries before calculating loss. This was due to some broadcasting errors because the author didn&#39;t have the right sized inputs to the objective function. \r\n\r\nIn my case, I do not see this being the issue. I have checked and double checked that all of my dimensions/sizes line up. I am at a loss.\r\n\r\n### Other Things I&#39;ve Tried\r\n1. I&#39;ve tried this with varied sequence lengths from 7 timesteps to 100 time steps.\r\n2. I&#39;ve tried with varied number of variables in the time series. I&#39;ve tried with univariate all the way to all 274 variables that the data contains. \r\n3. I&#39;ve tried with various `reduction` parameters on the `nn.MSELoss` module. The paper calls for `sum`, but I&#39;ve tried both `sum` and `mean`. No difference.\r\n4. The paper calls for reconstructing the sequence in reverse order (see graphic above). I have tried this method using the `flipud` on the original input (after training but before calculating loss). This makes no difference. \r\n5. I tried making the model more complex by adding an extra LSTM layer in the encoder. \r\n6. I&#39;ve tried playing with the latent space. I&#39;ve tried from 50% of the input number of features to 150%. \r\n7. I&#39;ve tried overfitting a single sequence (provided in the **Data** section above). \r\n\r\n### Question:\r\n\r\nWhat is causing my model to predict the average and how do I fix it?\r\n\r\n\r\n  [1]: https://i.sstatic.net/RbmCF.png\r\n  [2]: https://i.sstatic.net/vVCJS.png\r\n  [3]: https://i.sstatic.net/7Z1cB.png",
        "accepted_answer_markdown": "Okay, after some debugging I think I know the reasons.\r\n\r\n# TLDR\r\n\r\n- You try to predict next timestep value __instead of difference between current timestep and the previous one__\r\n- Your `hidden_features` number is too small making the model unable to fit even a single sample\r\n\r\n# Analysis\r\n\r\n## Code used\r\n\r\nLet&#39;s start with the code (model is the same):\r\n\r\n    import seaborn as sns\r\n    import matplotlib.pyplot as plt\r\n\r\n    def get_data(subtract: bool = False):\r\n        # (1, 14, 5)\r\n        input_tensor = torch.tensor(\r\n            [\r\n                [0.5122, 0.0360, 0.7027, 0.0721, 0.1892],\r\n                [0.5177, 0.0833, 0.6574, 0.1204, 0.1389],\r\n                [0.4643, 0.0364, 0.6242, 0.1576, 0.1818],\r\n                [0.4375, 0.0133, 0.5733, 0.1867, 0.2267],\r\n                [0.4838, 0.0625, 0.6042, 0.1771, 0.1562],\r\n                [0.4804, 0.0175, 0.6798, 0.1053, 0.1974],\r\n                [0.5030, 0.0445, 0.6712, 0.1438, 0.1404],\r\n                [0.4987, 0.0490, 0.6699, 0.1536, 0.1275],\r\n                [0.4898, 0.0388, 0.6704, 0.1330, 0.1579],\r\n                [0.4711, 0.0390, 0.5877, 0.1532, 0.2201],\r\n                [0.4627, 0.0484, 0.5269, 0.1882, 0.2366],\r\n                [0.5043, 0.0807, 0.6646, 0.1429, 0.1118],\r\n                [0.4852, 0.0606, 0.6364, 0.1515, 0.1515],\r\n                [0.5279, 0.0629, 0.6886, 0.1514, 0.0971],\r\n            ]\r\n        ).unsqueeze(0)\r\n    \r\n        if subtract:\r\n            initial_values = input_tensor[:, 0, :]\r\n            input_tensor -= torch.roll(input_tensor, 1, 1)\r\n            input_tensor[:, 0, :] = initial_values\r\n        return input_tensor\r\n    \r\n    \r\n    if __name__ == &quot;__main__&quot;:\r\n        torch.manual_seed(0)\r\n\r\n        HIDDEN_SIZE = 10\r\n        SUBTRACT = False\r\n    \r\n        input_tensor = get_data(SUBTRACT)\r\n        model = LSTMEncoderDecoder(input_tensor.shape[-1], HIDDEN_SIZE)\r\n        optimizer = torch.optim.Adam(model.parameters())\r\n        criterion = torch.nn.MSELoss()\r\n        for i in range(1000):\r\n            outputs = model(input_tensor)\r\n            loss = criterion(outputs, input_tensor)\r\n            loss.backward()\r\n            optimizer.step()\r\n            optimizer.zero_grad()\r\n            print(f&quot;{i}: {loss}&quot;)\r\n            if loss &lt; 1e-4:\r\n                break\r\n    \r\n        # Plotting\r\n        sns.lineplot(data=outputs.detach().numpy().squeeze())\r\n        sns.lineplot(data=input_tensor.detach().numpy().squeeze())\r\n        plt.show()\r\n\r\nWhat it does:\r\n- `get_data` either works on the data your provided if `subtract=False` or (if `subtract=True`) it subtracts value of __the previous timestep__ from the current timestep\r\n- Rest of the code optimizes the model until `1e-4` loss reached (so we can compare how model&#39;s capacity and it&#39;s increase helps and what happens when we use the difference of timesteps instead of timesteps)\r\n\r\n__We will only vary `HIDDEN_SIZE` and `SUBTRACT` parameters!__\r\n\r\n## NO SUBTRACT, SMALL MODEL\r\n\r\n- `HIDDEN_SIZE=5`\r\n- `SUBTRACT=False`\r\n\r\nIn this case we get a straight line. Model is unable to fit and grasp the phenomena presented in the data (hence flat lines you mentioned).\r\n\r\n[![enter image description here][1]][1]\r\n\r\n__1000 iterations limit reached__\r\n\r\n## SUBTRACT, SMALL MODEL\r\n\r\n- `HIDDEN_SIZE=5`\r\n- `SUBTRACT=True`\r\n\r\nTargets are now __far from flat lines__, but model is unable to fit due to too small capacity.\r\n\r\n[![enter image description here][2]][2]\r\n\r\n__1000 iterations limit reached__\r\n\r\n## NO SUBTRACT, LARGER MODEL\r\n\r\n- `HIDDEN_SIZE=100`\r\n- `SUBTRACT=False`\r\n\r\nIt got a lot better and our target was hit after `942` steps. No more flat lines, model capacity seems quite fine (for this single example!)\r\n\r\n[![enter image description here][3]][3]\r\n\r\n## SUBTRACT, LARGER MODEL\r\n\r\n- `HIDDEN_SIZE=100`\r\n- `SUBTRACT=True`\r\n\r\nAlthough the graph does not look that pretty, we got to desired loss after only `215` iterations.\r\n\r\n[![enter image description here][4]][4]\r\n\r\n# Finally\r\n\r\n- Usually use difference of timesteps instead of timesteps (or some other transformation, see [here](https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/) for more info about that). In other cases, neural network will try to simply... copy output from the previous step (as that&#39;s the easiest thing to do). Some minima will be found this way and going out of it will require more capacity.\r\n- When you use the difference between timesteps there is no way to &quot;extrapolate&quot; the trend from previous timestep; neural network has to learn how the function actually varies\r\n- Use larger model (for the whole dataset you should try something like `300` I think), but you can simply tune that one.\r\n- Don&#39;t use `flipud`. Use bidirectional LSTMs, in this way you can get info from forward and backward pass of LSTM (not to confuse with backprop!). This also should boost your score\r\n\r\n## Questions\r\n\r\n&gt; Okay, question 1: You are saying that for variable x in the time\r\n&gt; series, I should train the model to learn x[i] - x[i-1] rather than\r\n&gt; the value of x[i]? Am I correctly interpreting?\r\n\r\nYes, exactly. Difference removes the urge of the neural network to base it&#39;s predictions on the past timestep too much (by simply getting last value and maybe changing it a little)\r\n\r\n&gt; Question 2: You said my calculations for zero bottleneck were\r\n&gt; incorrect. But, for example, let&#39;s say I&#39;m using a simple dense\r\n&gt; network as an auto encoder. Getting the right bottleneck indeed\r\n&gt; depends on the data. But if you make the bottleneck the same size as\r\n&gt; the input, you get the identity function.\r\n\r\nYes, assuming that __there is no non-linearity involved__ which makes the thing harder (see [here](https://stats.stackexchange.com/questions/424558/why-is-it-hard-for-a-neural-network-to-learn-the-identity-function) for similar case). In case of LSTMs there are non-linearites, that&#39;s one point.\r\n\r\nAnother one is that we are accumulating `timesteps` into single encoder state. So essentially we would have to accumulate `timesteps` identities into a single hidden and cell states which is highly unlikely.\r\n\r\nOne last point, depending on the length of sequence, LSTMs are prone to forgetting some of the least relevant information (that&#39;s what they were designed to do, not only to remember everything), hence even more unlikely.\r\n\r\n&gt; Is num_features * num_timesteps not a bottle neck of the same size as\r\n&gt; the input, and therefore shouldn&#39;t it facilitate the model learning\r\n&gt; the identity?\r\n\r\nIt is, but it assumes you have `num_timesteps` for each data point, which is rarely the case, might be here. About the identity and why it is hard to do with non-linearities for the network it was answered above.\r\n\r\nOne last point, about identity functions; if they were actually easy to learn, `ResNet`s architectures would be unlikely to succeed. Network could converge to identity and make &quot;small fixes&quot; to the output without it, which is not the case.\r\n\r\n&gt; I&#39;m curious about the statement : &quot;always use difference of timesteps\r\n&gt; instead of timesteps&quot; It seem to have some normalizing effect by\r\n&gt; bringing all the features closer together but I don&#39;t understand why\r\n&gt; this is key ? Having a larger model seemed to be the solution and the\r\n&gt; substract is just helping.\r\n\r\nKey here was, indeed, increasing model capacity. Subtraction trick depends on the data really. Let&#39;s imagine an extreme situation:\r\n- We have `100` timesteps, single feature\r\n- Initial timestep value is `10000`\r\n- Other timestep values vary by `1` at most\r\n\r\nWhat the neural network would do (what is the easiest here)? It would, probably, discard this `1` or smaller change as noise and just predict `1000` for all of them (especially if some regularization is in place), as being off by `1/1000` is not much.\r\n\r\nWhat if we subtract? Whole neural network loss is in the `[0, 1]` margin for each timestep instead of `[0, 1001]`, hence it is more severe to be wrong.\r\n\r\nAnd yes, it is connected to normalization in some sense come to think about it.\r\n\r\n\r\n\r\n\r\n\r\n\r\n  [1]: https://i.sstatic.net/k0PoE.png\r\n  [2]: https://i.sstatic.net/K1olM.png\r\n  [3]: https://i.sstatic.net/1vltN.png\r\n  [4]: https://i.sstatic.net/lFwow.png"
    }
]